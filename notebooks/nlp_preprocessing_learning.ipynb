{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word / sentence tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word tokenization using nltk and spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = 'Product Allocation (PAL) in advanced Available-to-Promise (aATP) is a mechanism in SAP S/4HANA that helps avoid critical situations in demand and procurement. It allows the allocation of materials in short supply to specific regions and customers for a specific time period. This ensures that the entire available quantity of a material is not allocated to a single customer, enabling subsequent order requirements from other customers to be confirmed. PAL helps in precise planning and control of material delivery to meet customer demands.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/I748920/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Product',\n",
       " 'Allocation',\n",
       " '(',\n",
       " 'PAL',\n",
       " ')',\n",
       " 'in',\n",
       " 'advanced',\n",
       " 'Available-to-Promise',\n",
       " '(',\n",
       " 'aATP',\n",
       " ')',\n",
       " 'is',\n",
       " 'a',\n",
       " 'mechanism',\n",
       " 'in',\n",
       " 'SAP',\n",
       " 'S/4HANA',\n",
       " 'that',\n",
       " 'helps',\n",
       " 'avoid',\n",
       " 'critical',\n",
       " 'situations',\n",
       " 'in',\n",
       " 'demand',\n",
       " 'and',\n",
       " 'procurement',\n",
       " '.',\n",
       " 'It',\n",
       " 'allows',\n",
       " 'the',\n",
       " 'allocation',\n",
       " 'of',\n",
       " 'materials',\n",
       " 'in',\n",
       " 'short',\n",
       " 'supply',\n",
       " 'to',\n",
       " 'specific',\n",
       " 'regions',\n",
       " 'and',\n",
       " 'customers',\n",
       " 'for',\n",
       " 'a',\n",
       " 'specific',\n",
       " 'time',\n",
       " 'period',\n",
       " '.',\n",
       " 'This',\n",
       " 'ensures',\n",
       " 'that',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'available',\n",
       " 'quantity',\n",
       " 'of',\n",
       " 'a',\n",
       " 'material',\n",
       " 'is',\n",
       " 'not',\n",
       " 'allocated',\n",
       " 'to',\n",
       " 'a',\n",
       " 'single',\n",
       " 'customer',\n",
       " ',',\n",
       " 'enabling',\n",
       " 'subsequent',\n",
       " 'order',\n",
       " 'requirements',\n",
       " 'from',\n",
       " 'other',\n",
       " 'customers',\n",
       " 'to',\n",
       " 'be',\n",
       " 'confirmed',\n",
       " '.',\n",
       " 'PAL',\n",
       " 'helps',\n",
       " 'in',\n",
       " 'precise',\n",
       " 'planning',\n",
       " 'and',\n",
       " 'control',\n",
       " 'of',\n",
       " 'material',\n",
       " 'delivery',\n",
       " 'to',\n",
       " 'meet',\n",
       " 'customer',\n",
       " 'demands',\n",
       " '.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk - word tokenization\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "word_tokenize(sample_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/I748920/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product\n",
      "Allocation\n",
      "(\n",
      "PAL\n",
      ")\n",
      "in\n",
      "advanced\n",
      "Available\n",
      "-\n",
      "to\n",
      "-\n",
      "Promise\n",
      "(\n",
      "aATP\n",
      ")\n",
      "is\n",
      "a\n",
      "mechanism\n",
      "in\n",
      "SAP\n",
      "S/4HANA\n",
      "that\n",
      "helps\n",
      "avoid\n",
      "critical\n",
      "situations\n",
      "in\n",
      "demand\n",
      "and\n",
      "procurement\n",
      ".\n",
      "It\n",
      "allows\n",
      "the\n",
      "allocation\n",
      "of\n",
      "materials\n",
      "in\n",
      "short\n",
      "supply\n",
      "to\n",
      "specific\n",
      "regions\n",
      "and\n",
      "customers\n",
      "for\n",
      "a\n",
      "specific\n",
      "time\n",
      "period\n",
      ".\n",
      "This\n",
      "ensures\n",
      "that\n",
      "the\n",
      "entire\n",
      "available\n",
      "quantity\n",
      "of\n",
      "a\n",
      "material\n",
      "is\n",
      "not\n",
      "allocated\n",
      "to\n",
      "a\n",
      "single\n",
      "customer\n",
      ",\n",
      "enabling\n",
      "subsequent\n",
      "order\n",
      "requirements\n",
      "from\n",
      "other\n",
      "customers\n",
      "to\n",
      "be\n",
      "confirmed\n",
      ".\n",
      "PAL\n",
      "helps\n",
      "in\n",
      "precise\n",
      "planning\n",
      "and\n",
      "control\n",
      "of\n",
      "material\n",
      "delivery\n",
      "to\n",
      "meet\n",
      "customer\n",
      "demands\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# spacy - word tokenization\n",
    "\n",
    "import spacy\n",
    "# run this first\n",
    "# !python3 -m spacy download en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "for i in nlp(sample_text):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nlp(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Product, Allocation, (, PAL)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(sample_text)[0],nlp(sample_text)[1],nlp(sample_text)[2],nlp(sample_text)[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for word tokenization, either nltk or spacy libraries work fine "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sentence tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Product Allocation (PAL) in advanced Available-to-Promise (aATP) is a mechanism in SAP S/4HANA that helps avoid critical situations in demand and procurement.',\n",
       " 'It allows the allocation of materials in short supply to specific regions and customers for a specific time period.',\n",
       " 'This ensures that the entire available quantity of a material is not allocated to a single customer, enabling subsequent order requirements from other customers to be confirmed.',\n",
       " 'PAL helps in precise planning and control of material delivery to meet customer demands.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk - sentence tokenization\n",
    "\n",
    "nltk_sentence_tokens = nltk.sent_tokenize(sample_text)\n",
    "nltk_sentence_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Allocation (PAL) in advanced Available-to-Promise (aATP) is a mechanism in SAP S/4HANA that helps avoid critical situations in demand and procurement. \n",
      "\n",
      "It allows the allocation of materials in short supply to specific regions and customers for a specific time period. \n",
      "\n",
      "This ensures that the entire available quantity of a material is not allocated to a single customer, enabling subsequent order requirements from other customers to be confirmed. \n",
      "\n",
      "PAL helps in precise planning and control of material delivery to meet customer demands. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# nltk - sentence tokenization\n",
    "\n",
    "spacy_sentence_tokens = nlp(sample_text).sents\n",
    "for i in spacy_sentence_tokens:\n",
    "    print(i,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for sentence tokenization\n",
    "Sentence tokenization takes a text and splits it into individual sentences. For literature, journalism, and formal documents the tokenization algorithms built into spaCy perform well, since the tokenizer is trained on a corpus of formal English text. The sentence tokenizer shows poor performance for electronic health records featuring abbreviations, medical terms, spatial measurements, and other forms not present in standard written English.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk seems to be better for this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Stop Words:\n",
    "StopWords are English words that do not add much meaning to a sentence, so we can remove all the stop words from the text. E.g. “a”, ”the”, ”have”, ”an” etc…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NLTK data package includes a pre-trained Punkt tokenizer for English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Product Allocation (PAL) in advanced Available-to-Promise (aATP) is a mechanism in SAP S/4HANA that helps avoid critical situations in demand and procurement. It allows the allocation of materials in short supply to specific regions and customers for a specific time period. This ensures that the entire available quantity of a material is not allocated to a single customer, enabling subsequent order requirements from other customers to be confirmed. PAL helps in precise planning and control of material delivery to meet customer demands.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/I748920/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/I748920/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk - stop words\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Product',\n",
       " 'Allocation',\n",
       " '(PAL)',\n",
       " 'advanced',\n",
       " 'Available-to-Promise',\n",
       " '(aATP)',\n",
       " 'mechanism',\n",
       " 'SAP',\n",
       " 'S/4HANA',\n",
       " 'helps',\n",
       " 'avoid',\n",
       " 'critical',\n",
       " 'situations',\n",
       " 'demand',\n",
       " 'procurement.',\n",
       " 'It',\n",
       " 'allows',\n",
       " 'allocation',\n",
       " 'materials',\n",
       " 'short',\n",
       " 'supply',\n",
       " 'specific',\n",
       " 'regions',\n",
       " 'customers',\n",
       " 'specific',\n",
       " 'time',\n",
       " 'period.',\n",
       " 'This',\n",
       " 'ensures',\n",
       " 'entire',\n",
       " 'available',\n",
       " 'quantity',\n",
       " 'material',\n",
       " 'allocated',\n",
       " 'single',\n",
       " 'customer,',\n",
       " 'enabling',\n",
       " 'subsequent',\n",
       " 'order',\n",
       " 'requirements',\n",
       " 'customers',\n",
       " 'confirmed.',\n",
       " 'PAL',\n",
       " 'helps',\n",
       " 'precise',\n",
       " 'planning',\n",
       " 'control',\n",
       " 'material',\n",
       " 'delivery',\n",
       " 'meet',\n",
       " 'customer',\n",
       " 'demands.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=[]\n",
    "for i in sample_text.split():\n",
    "    if i not in stopwords.words('english'):\n",
    "        x.append(i)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"'d\",\n",
       " \"'ll\",\n",
       " \"'m\",\n",
       " \"'re\",\n",
       " \"'s\",\n",
       " \"'ve\",\n",
       " 'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'across',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amount',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anyhow',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'are',\n",
       " 'around',\n",
       " 'as',\n",
       " 'at',\n",
       " 'back',\n",
       " 'be',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beforehand',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'below',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'both',\n",
       " 'bottom',\n",
       " 'but',\n",
       " 'by',\n",
       " 'ca',\n",
       " 'call',\n",
       " 'can',\n",
       " 'cannot',\n",
       " 'could',\n",
       " 'did',\n",
       " 'do',\n",
       " 'does',\n",
       " 'doing',\n",
       " 'done',\n",
       " 'down',\n",
       " 'due',\n",
       " 'during',\n",
       " 'each',\n",
       " 'eight',\n",
       " 'either',\n",
       " 'eleven',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'empty',\n",
       " 'enough',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'except',\n",
       " 'few',\n",
       " 'fifteen',\n",
       " 'fifty',\n",
       " 'first',\n",
       " 'five',\n",
       " 'for',\n",
       " 'former',\n",
       " 'formerly',\n",
       " 'forty',\n",
       " 'four',\n",
       " 'from',\n",
       " 'front',\n",
       " 'full',\n",
       " 'further',\n",
       " 'get',\n",
       " 'give',\n",
       " 'go',\n",
       " 'had',\n",
       " 'has',\n",
       " 'have',\n",
       " 'he',\n",
       " 'hence',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hereafter',\n",
       " 'hereby',\n",
       " 'herein',\n",
       " 'hereupon',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'however',\n",
       " 'hundred',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'indeed',\n",
       " 'into',\n",
       " 'is',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'keep',\n",
       " 'last',\n",
       " 'latter',\n",
       " 'latterly',\n",
       " 'least',\n",
       " 'less',\n",
       " 'made',\n",
       " 'make',\n",
       " 'many',\n",
       " 'may',\n",
       " 'me',\n",
       " 'meanwhile',\n",
       " 'might',\n",
       " 'mine',\n",
       " 'more',\n",
       " 'moreover',\n",
       " 'most',\n",
       " 'mostly',\n",
       " 'move',\n",
       " 'much',\n",
       " 'must',\n",
       " 'my',\n",
       " 'myself',\n",
       " \"n't\",\n",
       " 'name',\n",
       " 'namely',\n",
       " 'neither',\n",
       " 'never',\n",
       " 'nevertheless',\n",
       " 'next',\n",
       " 'nine',\n",
       " 'no',\n",
       " 'nobody',\n",
       " 'none',\n",
       " 'noone',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'now',\n",
       " 'nowhere',\n",
       " 'n‘t',\n",
       " 'n’t',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'only',\n",
       " 'onto',\n",
       " 'or',\n",
       " 'other',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 'part',\n",
       " 'per',\n",
       " 'perhaps',\n",
       " 'please',\n",
       " 'put',\n",
       " 'quite',\n",
       " 'rather',\n",
       " 're',\n",
       " 'really',\n",
       " 'regarding',\n",
       " 'same',\n",
       " 'say',\n",
       " 'see',\n",
       " 'seem',\n",
       " 'seemed',\n",
       " 'seeming',\n",
       " 'seems',\n",
       " 'serious',\n",
       " 'several',\n",
       " 'she',\n",
       " 'should',\n",
       " 'show',\n",
       " 'side',\n",
       " 'since',\n",
       " 'six',\n",
       " 'sixty',\n",
       " 'so',\n",
       " 'some',\n",
       " 'somehow',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'sometime',\n",
       " 'sometimes',\n",
       " 'somewhere',\n",
       " 'still',\n",
       " 'such',\n",
       " 'take',\n",
       " 'ten',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'thence',\n",
       " 'there',\n",
       " 'thereafter',\n",
       " 'thereby',\n",
       " 'therefore',\n",
       " 'therein',\n",
       " 'thereupon',\n",
       " 'these',\n",
       " 'they',\n",
       " 'third',\n",
       " 'this',\n",
       " 'those',\n",
       " 'though',\n",
       " 'three',\n",
       " 'through',\n",
       " 'throughout',\n",
       " 'thru',\n",
       " 'thus',\n",
       " 'to',\n",
       " 'together',\n",
       " 'too',\n",
       " 'top',\n",
       " 'toward',\n",
       " 'towards',\n",
       " 'twelve',\n",
       " 'twenty',\n",
       " 'two',\n",
       " 'under',\n",
       " 'unless',\n",
       " 'until',\n",
       " 'up',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'used',\n",
       " 'using',\n",
       " 'various',\n",
       " 'very',\n",
       " 'via',\n",
       " 'was',\n",
       " 'we',\n",
       " 'well',\n",
       " 'were',\n",
       " 'what',\n",
       " 'whatever',\n",
       " 'when',\n",
       " 'whence',\n",
       " 'whenever',\n",
       " 'where',\n",
       " 'whereafter',\n",
       " 'whereas',\n",
       " 'whereby',\n",
       " 'wherein',\n",
       " 'whereupon',\n",
       " 'wherever',\n",
       " 'whether',\n",
       " 'which',\n",
       " 'while',\n",
       " 'whither',\n",
       " 'who',\n",
       " 'whoever',\n",
       " 'whole',\n",
       " 'whom',\n",
       " 'whose',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'within',\n",
       " 'without',\n",
       " 'would',\n",
       " 'yet',\n",
       " 'you',\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " '‘d',\n",
       " '‘ll',\n",
       " '‘m',\n",
       " '‘re',\n",
       " '‘s',\n",
       " '‘ve',\n",
       " '’d',\n",
       " '’ll',\n",
       " '’m',\n",
       " '’re',\n",
       " '’s',\n",
       " '’ve'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spacy - stop words\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "spacy_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Product',\n",
       " 'Allocation',\n",
       " '(PAL)',\n",
       " 'advanced',\n",
       " 'Available-to-Promise',\n",
       " '(aATP)',\n",
       " 'mechanism',\n",
       " 'SAP',\n",
       " 'S/4HANA',\n",
       " 'helps',\n",
       " 'avoid',\n",
       " 'critical',\n",
       " 'situations',\n",
       " 'demand',\n",
       " 'procurement.',\n",
       " 'It',\n",
       " 'allows',\n",
       " 'allocation',\n",
       " 'materials',\n",
       " 'short',\n",
       " 'supply',\n",
       " 'specific',\n",
       " 'regions',\n",
       " 'customers',\n",
       " 'specific',\n",
       " 'time',\n",
       " 'period.',\n",
       " 'This',\n",
       " 'ensures',\n",
       " 'entire',\n",
       " 'available',\n",
       " 'quantity',\n",
       " 'material',\n",
       " 'allocated',\n",
       " 'single',\n",
       " 'customer,',\n",
       " 'enabling',\n",
       " 'subsequent',\n",
       " 'order',\n",
       " 'requirements',\n",
       " 'customers',\n",
       " 'confirmed.',\n",
       " 'PAL',\n",
       " 'helps',\n",
       " 'precise',\n",
       " 'planning',\n",
       " 'control',\n",
       " 'material',\n",
       " 'delivery',\n",
       " 'meet',\n",
       " 'customer',\n",
       " 'demands.']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=[]\n",
    "for i in sample_text.split():\n",
    "    if i not in spacy_stopwords:\n",
    "        x.append(i)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the libraries, spaCy and NLTK have done a decent job in removing the stop words from the paragraph. Both can get your task done quite efficiently. However, to pick a winner, spaCy has done better in the segment which is quite accurate. Moreover, NLTK requires downloading the required package to perform the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization:\n",
    "Lemmatization is the text normalization technique for spaCy, that will remove words having the same meaning. It is a process of getting the base word of a given word i.e. “counter”, ”count”, so here the base word is “count”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization seeks to distill words to their foundational forms. In this linguistic refinement, the resultant base word is referred to as a “lemma.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization techniques in natural language processing (NLP) involve methods to identify and transform words into their base or root forms, known as lemmas. These approaches contribute to text normalization, facilitating more accurate language analysis and processing in various NLP applications. Three types of lemmatization techniques are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(spacy.tokens.token.Token, spacy.tokens.doc.Doc)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process the text using spaCy\n",
    "type(nlp(sample_text)[0]),type(nlp(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Product\n",
      "Allocation Allocation\n",
      "( (\n",
      "PAL PAL\n",
      ") )\n",
      "in in\n",
      "advanced advanced\n",
      "Available Available\n",
      "- -\n",
      "to to\n",
      "- -\n",
      "Promise promise\n",
      "( (\n",
      "aATP aATP\n",
      ") )\n",
      "is be\n",
      "a a\n",
      "mechanism mechanism\n",
      "in in\n",
      "SAP SAP\n",
      "S/4HANA S/4HANA\n",
      "that that\n",
      "helps help\n",
      "avoid avoid\n",
      "critical critical\n",
      "situations situation\n",
      "in in\n",
      "demand demand\n",
      "and and\n",
      "procurement procurement\n",
      ". .\n",
      "It it\n",
      "allows allow\n",
      "the the\n",
      "allocation allocation\n",
      "of of\n",
      "materials material\n",
      "in in\n",
      "short short\n",
      "supply supply\n",
      "to to\n",
      "specific specific\n",
      "regions region\n",
      "and and\n",
      "customers customer\n",
      "for for\n",
      "a a\n",
      "specific specific\n",
      "time time\n",
      "period period\n",
      ". .\n",
      "This this\n",
      "ensures ensure\n",
      "that that\n",
      "the the\n",
      "entire entire\n",
      "available available\n",
      "quantity quantity\n",
      "of of\n",
      "a a\n",
      "material material\n",
      "is be\n",
      "not not\n",
      "allocated allocate\n",
      "to to\n",
      "a a\n",
      "single single\n",
      "customer customer\n",
      ", ,\n",
      "enabling enable\n",
      "subsequent subsequent\n",
      "order order\n",
      "requirements requirement\n",
      "from from\n",
      "other other\n",
      "customers customer\n",
      "to to\n",
      "be be\n",
      "confirmed confirm\n",
      ". .\n",
      "PAL pal\n",
      "helps help\n",
      "in in\n",
      "precise precise\n",
      "planning planning\n",
      "and and\n",
      "control control\n",
      "of of\n",
      "material material\n",
      "delivery delivery\n",
      "to to\n",
      "meet meet\n",
      "customer customer\n",
      "demands demand\n",
      ". .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Product',\n",
       " 'Allocation',\n",
       " '(',\n",
       " 'PAL',\n",
       " ')',\n",
       " 'in',\n",
       " 'advanced',\n",
       " 'Available',\n",
       " '-',\n",
       " 'to',\n",
       " '-',\n",
       " 'promise',\n",
       " '(',\n",
       " 'aATP',\n",
       " ')',\n",
       " 'be',\n",
       " 'a',\n",
       " 'mechanism',\n",
       " 'in',\n",
       " 'SAP',\n",
       " 'S/4HANA',\n",
       " 'that',\n",
       " 'help',\n",
       " 'avoid',\n",
       " 'critical',\n",
       " 'situation',\n",
       " 'in',\n",
       " 'demand',\n",
       " 'and',\n",
       " 'procurement',\n",
       " '.',\n",
       " 'it',\n",
       " 'allow',\n",
       " 'the',\n",
       " 'allocation',\n",
       " 'of',\n",
       " 'material',\n",
       " 'in',\n",
       " 'short',\n",
       " 'supply',\n",
       " 'to',\n",
       " 'specific',\n",
       " 'region',\n",
       " 'and',\n",
       " 'customer',\n",
       " 'for',\n",
       " 'a',\n",
       " 'specific',\n",
       " 'time',\n",
       " 'period',\n",
       " '.',\n",
       " 'this',\n",
       " 'ensure',\n",
       " 'that',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'available',\n",
       " 'quantity',\n",
       " 'of',\n",
       " 'a',\n",
       " 'material',\n",
       " 'be',\n",
       " 'not',\n",
       " 'allocate',\n",
       " 'to',\n",
       " 'a',\n",
       " 'single',\n",
       " 'customer',\n",
       " ',',\n",
       " 'enable',\n",
       " 'subsequent',\n",
       " 'order',\n",
       " 'requirement',\n",
       " 'from',\n",
       " 'other',\n",
       " 'customer',\n",
       " 'to',\n",
       " 'be',\n",
       " 'confirm',\n",
       " '.',\n",
       " 'pal',\n",
       " 'help',\n",
       " 'in',\n",
       " 'precise',\n",
       " 'planning',\n",
       " 'and',\n",
       " 'control',\n",
       " 'of',\n",
       " 'material',\n",
       " 'delivery',\n",
       " 'to',\n",
       " 'meet',\n",
       " 'customer',\n",
       " 'demand',\n",
       " '.']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spacy - lemmatization\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "x=[]\n",
    "# for spacy need to do nlp(text) to create spacy doc / token objects\n",
    "for i in nlp(sample_text):\n",
    "    x.append(i.lemma_)\n",
    "    print(i,i.lemma_)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/I748920/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks : rock\n",
      "corpora : corpus\n",
      "better : good\n"
     ]
    }
   ],
   "source": [
    "# nltk - lemmatization\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\"))\n",
    "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\"))\n",
    "# a denotes adjective in \"pos\"\n",
    "print(\"better :\", lemmatizer.lemmatize(\"better\", pos=\"a\"))\n",
    "# indicates that the word \"better\" has been lemmatized to its base form, which is \"good,\" when treated as an adjective (denoted by pos=\"a\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming is the process of producing morphological variants of a root/base word. Stemming programs are commonly referred to as stemming algorithms or stemmers. A stemming algorithm reduces the words “chocolates”, “chocolatey”, and “choco” to the root word, “chocolate” and “retrieval”, “retrieved”, “retrieves” reduce to the stem “retrieve”.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming: Faster, but may create unrecognizable words and lose meaning. This is known as “over stemming.” Lemmatization: More accurate, preserves meaning and grammatical function, but slower. It is often used to maintain related words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lemmatization vs stemming\n",
    "\n",
    "https://stackoverflow.com/questions/49354665/should-i-perform-both-lemmatization-and-stemming\n",
    "https://www.datacamp.com/tutorial/stemming-lemmatization-python\n",
    "* think for now stick to lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product product\n",
      "Allocation alloc\n",
      "(PAL) (pal)\n",
      "in in\n",
      "advanced advanc\n",
      "Available-to-Promise available-to-promis\n",
      "(aATP) (aatp)\n",
      "is is\n",
      "a a\n",
      "mechanism mechan\n",
      "in in\n",
      "SAP sap\n",
      "S/4HANA s/4hana\n",
      "that that\n",
      "helps help\n",
      "avoid avoid\n",
      "critical critic\n",
      "situations situat\n",
      "in in\n",
      "demand demand\n",
      "and and\n",
      "procurement. procurement.\n",
      "It it\n",
      "allows allow\n",
      "the the\n",
      "allocation alloc\n",
      "of of\n",
      "materials materi\n",
      "in in\n",
      "short short\n",
      "supply suppli\n",
      "to to\n",
      "specific specif\n",
      "regions region\n",
      "and and\n",
      "customers custom\n",
      "for for\n",
      "a a\n",
      "specific specif\n",
      "time time\n",
      "period. period.\n",
      "This thi\n",
      "ensures ensur\n",
      "that that\n",
      "the the\n",
      "entire entir\n",
      "available avail\n",
      "quantity quantiti\n",
      "of of\n",
      "a a\n",
      "material materi\n",
      "is is\n",
      "not not\n",
      "allocated alloc\n",
      "to to\n",
      "a a\n",
      "single singl\n",
      "customer, customer,\n",
      "enabling enabl\n",
      "subsequent subsequ\n",
      "order order\n",
      "requirements requir\n",
      "from from\n",
      "other other\n",
      "customers custom\n",
      "to to\n",
      "be be\n",
      "confirmed. confirmed.\n",
      "PAL pal\n",
      "helps help\n",
      "in in\n",
      "precise precis\n",
      "planning plan\n",
      "and and\n",
      "control control\n",
      "of of\n",
      "material materi\n",
      "delivery deliveri\n",
      "to to\n",
      "meet meet\n",
      "customer custom\n",
      "demands. demands.\n"
     ]
    }
   ],
   "source": [
    "# nltk - stemming\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "for word in sample_text.split():\n",
    "    print(word,ps.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " programm program with program languag\n"
     ]
    }
   ],
   "source": [
    "# second nltk method\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from functools import reduce\n",
    " \n",
    "ps = PorterStemmer()\n",
    " \n",
    "sentence = \"Programmers program with programming languages\"\n",
    "words = word_tokenize(sentence)\n",
    " \n",
    "# using reduce to apply stemmer to each word and join them back into a string\n",
    "stemmed_sentence = reduce(lambda x, y: x + \" \" + ps.stem(y), words, \"\")\n",
    " \n",
    "print(stemmed_sentence)\n",
    "#This code is contrinuted by Pushpa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n",
      "happi\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "print(ps.stem(\"running\"))  # Output: run\n",
    "print(ps.stem(\"happiness\"))  # Output: happi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy - stemming\n",
    "\n",
    "# - It might be surprising to you but spaCy doesn't contain any function for stemming as it relies on lemmatization only. Therefore, in this section, we will use NLTK for stemming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regex exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally, Python uses backslashes as escape characters. Prefacing the string definition with 'r' is a useful way to define a string where you need the backslash to be an actual backslash and not part of an escape code that means something else in the string.22 Feb 2022\n",
    "- usually \\n means newline \\t is tab, but rawstring will make everything compiled as it is\n",
    "\n",
    "F-string is a way to format strings in Python. It was introduced in Python 3.6 and aims to make it easier for users to add variables, comma separators, do padding with zeros and date format. Python String. | Image: Frank Andrade. F-string was introduced in Python 3.6 and provides a better way to format strings.14 Mar 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['support@example.com', 'sales@example.com']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "text1 = \"Contact us at support@example.com or sales@example.com\"\n",
    "text = \"\"\"\n",
    "RegExr was created by gskinner.com.\n",
    "\n",
    "Edit the Expression & Text to see matches. Roll over matches or the expression for details. PCRE & JavaScript flavors of RegEx are supported. Validate your expression with Tests mode.\n",
    "\n",
    "The side bar includes a Cheatsheet, full Reference, and Help. You can also Save & Share with the Community and view patterns you create or favorite in My Patterns.\n",
    "\n",
    "Explore results with the Tools below. Replace & List output custom results. Details lists capture groups. Explain describes your expression in plain English.\n",
    "\"\"\"\n",
    "emails = re.findall(r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\", text1)\n",
    "print(emails)  # Output: ['support@example.com', 'sales@example.com']\n",
    "\n",
    "regex_test = re.findall(r\"/the/\",text)\n",
    "print(regex_test)\n",
    "\n",
    "# alternative is to do things like looks for @ and .com but others might be included like home address or websites, so regex is a more powerful way to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = '''\n",
    "abcdefghijklmnopqurtuvwxyz\n",
    "ABCDEFGHIJKLMNOPQRSTUVWXYZ\n",
    "1234567890\n",
    "\n",
    "Ha HaHa\n",
    "\n",
    "MetaCharacters (Need to be escaped):\n",
    ". ^ $ * + ? { } [ ] \\ | ( )\n",
    "\n",
    "coreyms.com\n",
    "\n",
    "321-555-4321\n",
    "123.555.1234\n",
    "123*555*1234\n",
    "800-555-1234\n",
    "900-555-1234\n",
    "\n",
    "Mr. Schafer\n",
    "Mr Smith\n",
    "Ms Davis\n",
    "Mrs. Robinson\n",
    "Mr. T\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(1, 4), match='abc'>\n"
     ]
    }
   ],
   "source": [
    "pattern = re.compile(r'abc')\n",
    "matches = pattern.finditer(text2)\n",
    "for m in matches:\n",
    "    print(m) # span tells you which index of the string gives that match, this is why finditer is useful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!! use regex to find patterns, exact match can just use regualr python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pattern.findall just returns all the actual string matches in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r'cba')\n",
    "matches = pattern.finditer(text2)\n",
    "for m in matches:\n",
    "    print(m) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(67, 69), match='Ha'>\n",
      "<re.Match object; span=(70, 72), match='Ha'>\n"
     ]
    }
   ],
   "source": [
    "pattern = re.compile(r'\\bHa')\n",
    "matches = pattern.finditer(text2)\n",
    "for m in matches:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(72, 74), match='Ha'>\n"
     ]
    }
   ],
   "source": [
    "pattern = re.compile(r'\\BHa')\n",
    "matches = pattern.finditer(text2)\n",
    "for m in matches:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321-555-432\n",
      "123.555.123\n",
      "123*555*123\n",
      "800-555-123\n",
      "900-555-123\n"
     ]
    }
   ],
   "source": [
    "pattern = re.compile(r'\\d\\d\\d\\D\\d\\d\\d\\D\\d\\d\\d')\n",
    "matches = pattern.findall(text2)\n",
    "for m in matches:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or use . -> . in regex matches any char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321-555-432\n",
      "123.555.123\n",
      "123*555*123\n",
      "800-555-123\n",
      "900-555-123\n"
     ]
    }
   ],
   "source": [
    "pattern = re.compile(r'\\d\\d\\d.\\d\\d\\d.\\d\\d\\d')\n",
    "matches = pattern.findall(text2)\n",
    "for m in matches:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if only want to match those with - in number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321-555-432\n",
      "800-555-123\n",
      "900-555-123\n",
      "\n",
      "123*555*123\n",
      "\n",
      "321-555-432\n",
      "123.555.123\n",
      "123*555*123\n",
      "800-555-123\n",
      "900-555-123\n"
     ]
    }
   ],
   "source": [
    "pattern = re.compile(r'\\d\\d\\d[-]\\d\\d\\d[-]\\d\\d\\d')\n",
    "matches = pattern.findall(text2)\n",
    "for m in matches:\n",
    "    print(m)\n",
    "print()\n",
    "\n",
    "pattern = re.compile(r'\\d\\d\\d[*]\\d\\d\\d[*]\\d\\d\\d')\n",
    "matches = pattern.findall(text2)\n",
    "for m in matches:\n",
    "    print(m)\n",
    "print()\n",
    "\n",
    "pattern = re.compile(r'\\d\\d\\d[-*.]\\d\\d\\d[-*.]\\d\\d\\d')\n",
    "# matches any char in []\n",
    "matches = pattern.findall(text2)\n",
    "for m in matches:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note that in pattern = re.compile(r'\\d\\d\\d[-*.]\\d\\d\\d[-*.]\\d\\d\\d')\n",
    "the [-*.] still only matches one char, even if you have\n",
    "[A-Za-z0-9.] it still only matches one char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing tutorial\n",
    "* follow this series: https://medium.com/@erhan_arslan/understanding-natural-language-processing-nlp-step-1-bd5030c5a1b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MT proj preprocessing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Product Allocation (PAL) in advanced Available-to-Promise (aATP) is a mechanism in SAP S/4HANA that helps avoid critical situations in demand and procurement. It allows the allocation of materials in short supply to specific regions and customers for a specific time period. This ensures that the entire available quantity of a material is not allocated to a single customer, enabling subsequent order requirements from other customers to be confirmed. PAL helps in precise planning and control of material delivery to meet customer demands.'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.strip()\n",
    "\n",
    "    tokens = word_tokenize(text, preserve_line=True)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [i for i in tokens if not i in stop_words]\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(i) for i in tokens]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'product allocation (pal) in advanced available-to-promise (aatp) is a mechanism in sap s/hana that helps avoid critical situations in demand and procurement. it allows the allocation of materials in short supply to specific regions and customers for a specific time period. this ensures that the entire available quantity of a material is not allocated to a single customer, enabling subsequent order requirements from other customers to be confirmed. pal helps in precise planning and control of material delivery to meet customer demands.'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_text(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_links_df = pd.read_csv('../sample_links_eval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_index</th>\n",
       "      <th>Product/Area</th>\n",
       "      <th>Question Category</th>\n",
       "      <th>Question</th>\n",
       "      <th>Golden Answer</th>\n",
       "      <th>Links provided to Model</th>\n",
       "      <th>Answer based on information retrieval content generated</th>\n",
       "      <th>Links provided in answer</th>\n",
       "      <th>test_response_answers</th>\n",
       "      <th>test_response_sources</th>\n",
       "      <th>golden_links</th>\n",
       "      <th>test_links</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>jaccard_similarities_score</th>\n",
       "      <th>reciprocal_ranks_score</th>\n",
       "      <th>reciprocal_rank_at_n_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>S4H private cloud</td>\n",
       "      <td>Direct</td>\n",
       "      <td>What does product allocation mean?</td>\n",
       "      <td>Product Allocation (PAL) in advanced Available...</td>\n",
       "      <td>APIs for Availability Checks \\nhttps://help.sa...</td>\n",
       "      <td>Product Allocation (CA-ATP-PAL)\\nhttps://help....</td>\n",
       "      <td>Product Allocation (CA-ATP-PAL).\\nhttps://help...</td>\n",
       "      <td>Product allocation refers to the system of dis...</td>\n",
       "      <td>[{'id': None, 'metadata': {'document_url': '/d...</td>\n",
       "      <td>['https://help.sap.com/docs/SAP_S4HANA_ON-PREM...</td>\n",
       "      <td>['https://help.sap.com/docs/SAP_S4HANA_CLOUD/3...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>S4H private cloud</td>\n",
       "      <td>Direct</td>\n",
       "      <td>What is a product allocation object?</td>\n",
       "      <td>A product allocation object is the main busine...</td>\n",
       "      <td>\"Product Allocation Sequence\",\\n      \"documen...</td>\n",
       "      <td>Key Concepts in Product Allocation\",\\n        ...</td>\n",
       "      <td>Key Concepts in Product Allocation\\nhttps://he...</td>\n",
       "      <td>A product allocation object is a critical comp...</td>\n",
       "      <td>[{'id': None, 'metadata': {'document_url': '/d...</td>\n",
       "      <td>['https://help.sap.com/docs/SAP_S4HANA_ON-PREM...</td>\n",
       "      <td>['https://help.sap.com/docs/SAP_S4HANA_CLOUD/3...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>S4H private cloud</td>\n",
       "      <td>Direct</td>\n",
       "      <td>What is an allocation quantity unit in aATP pr...</td>\n",
       "      <td>An allocation quantity unit in aATP product al...</td>\n",
       "      <td>\"Key Concepts in Product Allocation\",\\n      \"...</td>\n",
       "      <td>\"Key Concepts in Product Allocation\",\\n       ...</td>\n",
       "      <td>Key Concepts in Product Allocation\\nhttps://he...</td>\n",
       "      <td>An allocation quantity unit in Advanced Availa...</td>\n",
       "      <td>[{'id': None, 'metadata': {'document_url': '/d...</td>\n",
       "      <td>['https://help.sap.com/docs/SAP_S4HANA_ON-PREM...</td>\n",
       "      <td>['https://help.sap.com/docs/SAP_S4HANA_CLOUD/3...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>S4H private cloud</td>\n",
       "      <td>Consistency</td>\n",
       "      <td>Where can I maintain authorizations for produc...</td>\n",
       "      <td>You can maintain authorizations for product al...</td>\n",
       "      <td>\"document_title\": \"Authorizations Based on Cha...</td>\n",
       "      <td>\"Authorizations Based on Characteristics\",\\n  ...</td>\n",
       "      <td>Authorizations Based on Characteristics\\nhttps...</td>\n",
       "      <td>You can maintain authorizations for product al...</td>\n",
       "      <td>[{'id': None, 'metadata': {'document_url': '/d...</td>\n",
       "      <td>['https://help.sap.com/docs/SAP_S4HANA_ON-PREM...</td>\n",
       "      <td>['https://help.sap.com/docs/SAP_S4HANA_CLOUD/3...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>S4H private cloud</td>\n",
       "      <td>Consistency</td>\n",
       "      <td>How can I access the characteristic catalog?</td>\n",
       "      <td>To access the characteristic catalog, you can ...</td>\n",
       "      <td>\"Characteristic Name\",\\n      \"document_url\": ...</td>\n",
       "      <td>\"Manage Characteristic Catalogs\",\\n          \"...</td>\n",
       "      <td>Manage Characteristics Catalogs\\nhttps://help....</td>\n",
       "      <td>To access the characteristic catalog, you woul...</td>\n",
       "      <td>[{'id': None, 'metadata': {'document_url': '/d...</td>\n",
       "      <td>['https://help.sap.com/docs/SAP_S4HANA_ON-PREM...</td>\n",
       "      <td>['https://help.sap.com/docs/SAP_S4HANA_CLOUD/c...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original_index       Product/Area Question Category  \\\n",
       "0               0  S4H private cloud            Direct   \n",
       "1               1  S4H private cloud            Direct   \n",
       "2               2  S4H private cloud            Direct   \n",
       "3               3  S4H private cloud       Consistency   \n",
       "4               4  S4H private cloud       Consistency   \n",
       "\n",
       "                                           Question   \\\n",
       "0                 What does product allocation mean?   \n",
       "1               What is a product allocation object?   \n",
       "2  What is an allocation quantity unit in aATP pr...   \n",
       "3  Where can I maintain authorizations for produc...   \n",
       "4       How can I access the characteristic catalog?   \n",
       "\n",
       "                                       Golden Answer  \\\n",
       "0  Product Allocation (PAL) in advanced Available...   \n",
       "1  A product allocation object is the main busine...   \n",
       "2  An allocation quantity unit in aATP product al...   \n",
       "3  You can maintain authorizations for product al...   \n",
       "4  To access the characteristic catalog, you can ...   \n",
       "\n",
       "                             Links provided to Model  \\\n",
       "0  APIs for Availability Checks \\nhttps://help.sa...   \n",
       "1  \"Product Allocation Sequence\",\\n      \"documen...   \n",
       "2  \"Key Concepts in Product Allocation\",\\n      \"...   \n",
       "3  \"document_title\": \"Authorizations Based on Cha...   \n",
       "4  \"Characteristic Name\",\\n      \"document_url\": ...   \n",
       "\n",
       "  Answer based on information retrieval content generated  \\\n",
       "0  Product Allocation (CA-ATP-PAL)\\nhttps://help....        \n",
       "1  Key Concepts in Product Allocation\",\\n        ...        \n",
       "2  \"Key Concepts in Product Allocation\",\\n       ...        \n",
       "3  \"Authorizations Based on Characteristics\",\\n  ...        \n",
       "4  \"Manage Characteristic Catalogs\",\\n          \"...        \n",
       "\n",
       "                            Links provided in answer  \\\n",
       "0  Product Allocation (CA-ATP-PAL).\\nhttps://help...   \n",
       "1  Key Concepts in Product Allocation\\nhttps://he...   \n",
       "2  Key Concepts in Product Allocation\\nhttps://he...   \n",
       "3  Authorizations Based on Characteristics\\nhttps...   \n",
       "4  Manage Characteristics Catalogs\\nhttps://help....   \n",
       "\n",
       "                               test_response_answers  \\\n",
       "0  Product allocation refers to the system of dis...   \n",
       "1  A product allocation object is a critical comp...   \n",
       "2  An allocation quantity unit in Advanced Availa...   \n",
       "3  You can maintain authorizations for product al...   \n",
       "4  To access the characteristic catalog, you woul...   \n",
       "\n",
       "                               test_response_sources  \\\n",
       "0  [{'id': None, 'metadata': {'document_url': '/d...   \n",
       "1  [{'id': None, 'metadata': {'document_url': '/d...   \n",
       "2  [{'id': None, 'metadata': {'document_url': '/d...   \n",
       "3  [{'id': None, 'metadata': {'document_url': '/d...   \n",
       "4  [{'id': None, 'metadata': {'document_url': '/d...   \n",
       "\n",
       "                                        golden_links  \\\n",
       "0  ['https://help.sap.com/docs/SAP_S4HANA_ON-PREM...   \n",
       "1  ['https://help.sap.com/docs/SAP_S4HANA_ON-PREM...   \n",
       "2  ['https://help.sap.com/docs/SAP_S4HANA_ON-PREM...   \n",
       "3  ['https://help.sap.com/docs/SAP_S4HANA_ON-PREM...   \n",
       "4  ['https://help.sap.com/docs/SAP_S4HANA_ON-PREM...   \n",
       "\n",
       "                                          test_links  recall_score  \\\n",
       "0  ['https://help.sap.com/docs/SAP_S4HANA_CLOUD/3...      1.000000   \n",
       "1  ['https://help.sap.com/docs/SAP_S4HANA_CLOUD/3...      0.666667   \n",
       "2  ['https://help.sap.com/docs/SAP_S4HANA_CLOUD/3...      0.500000   \n",
       "3  ['https://help.sap.com/docs/SAP_S4HANA_CLOUD/3...      0.750000   \n",
       "4  ['https://help.sap.com/docs/SAP_S4HANA_CLOUD/c...      0.200000   \n",
       "\n",
       "   jaccard_similarities_score  reciprocal_ranks_score  \\\n",
       "0                    0.750000                     1.0   \n",
       "1                    0.500000                     1.0   \n",
       "2                    0.333333                     1.0   \n",
       "3                    0.600000                     1.0   \n",
       "4                    0.111111                     0.2   \n",
       "\n",
       "   reciprocal_rank_at_n_score  \n",
       "0                    0.916667  \n",
       "1                    0.916667  \n",
       "2                    0.500000  \n",
       "3                    1.000000  \n",
       "4                    0.040000  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_links_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_index</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>jaccard_similarities_score</th>\n",
       "      <th>reciprocal_ranks_score</th>\n",
       "      <th>reciprocal_rank_at_n_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31.454545</td>\n",
       "      <td>0.341212</td>\n",
       "      <td>0.244149</td>\n",
       "      <td>0.545152</td>\n",
       "      <td>0.325389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.922282</td>\n",
       "      <td>0.292549</td>\n",
       "      <td>0.229740</td>\n",
       "      <td>0.446000</td>\n",
       "      <td>0.335981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>45.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.521667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>59.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       original_index  recall_score  jaccard_similarities_score  \\\n",
       "count       55.000000     55.000000                   55.000000   \n",
       "mean        31.454545      0.341212                    0.244149   \n",
       "std         16.922282      0.292549                    0.229740   \n",
       "min          0.000000      0.000000                    0.000000   \n",
       "25%         18.500000      0.000000                    0.000000   \n",
       "50%         32.000000      0.400000                    0.250000   \n",
       "75%         45.500000      0.500000                    0.400000   \n",
       "max         59.000000      1.000000                    0.800000   \n",
       "\n",
       "       reciprocal_ranks_score  reciprocal_rank_at_n_score  \n",
       "count               55.000000                   55.000000  \n",
       "mean                 0.545152                    0.325389  \n",
       "std                  0.446000                    0.335981  \n",
       "min                  0.000000                    0.000000  \n",
       "25%                  0.000000                    0.000000  \n",
       "50%                  0.500000                    0.200000  \n",
       "75%                  1.000000                    0.521667  \n",
       "max                  1.000000                    1.000000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_links_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_texts_df = pd.read_csv('../sample_texts_eval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['original_index', 'Product/Area', 'Question Category', 'Question ',\n",
       "       'Golden Answer', 'Links provided to Model',\n",
       "       'Answer based on information retrieval content generated',\n",
       "       'Links provided in answer', 'test_response_answers',\n",
       "       'test_response_sources', 'cosine_similarity', 'bert_scores'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_texts_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_index</th>\n",
       "      <th>cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.853902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.400617</td>\n",
       "      <td>0.069326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.770486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.250000</td>\n",
       "      <td>0.795087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.852594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.750000</td>\n",
       "      <td>0.912074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.954958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       original_index  cosine_similarity\n",
       "count       10.000000          10.000000\n",
       "mean         6.500000           0.853902\n",
       "std          5.400617           0.069326\n",
       "min          0.000000           0.770486\n",
       "25%          2.250000           0.795087\n",
       "50%          4.500000           0.852594\n",
       "75%         11.750000           0.912074\n",
       "max         14.000000           0.954958"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_texts_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_scores = [eval(x) for x in sample_texts_df['bert_scores']]\n",
    "pre,rec,f1 = [],[],[]\n",
    "for d in bert_scores:\n",
    "    pre.append(d['precision'][0])\n",
    "    rec.append(d['recall'][0])\n",
    "    f1.append(d['f1'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.78, 0.88, 0.83)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "round(np.mean(pre),2),round(np.mean(rec),2),round(np.mean(f1),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
