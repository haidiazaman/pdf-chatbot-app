{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84ce970c-abd4-4b49-aa3c-66c0b2ae25a7",
   "metadata": {},
   "source": [
    "# generate embeddings using HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae40df88-2b31-4b81-9409-0975048e41f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "files_paths = glob.glob(\"/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/*.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ebed80d3-7173-4325-a2b6-03b6130c51bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pdfs into dict of key file_path, value list of document objects split by page number\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_pdfs(file_paths):\n",
    "    \"\"\"\n",
    "    file_paths must end with .pdf\n",
    "    PyPDFLoader auto splits the pdf into pages, each page is 1 Document object\n",
    "\n",
    "    returns a dict of key: file_path and value: list of document objects\n",
    "    \"\"\"\n",
    "    documents_dict = {}   \n",
    "    for f in tqdm(file_paths):\n",
    "        loader = PyPDFLoader(file_path = f)\n",
    "        documents = loader.load()\n",
    "        documents_dict[f] = documents\n",
    "    return documents_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc79fcec-0595-4d22-b228-938a7488d230",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/22 [00:00<?, ?it/s]/Users/I748920/Library/Python/3.9/lib/python/site-packages/pypdf/_crypt_providers/_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from this module in 48.0.0.\n",
      "  from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4\n",
      "100%|██████████| 22/22 [00:33<00:00,  1.51s/it]\n"
     ]
    }
   ],
   "source": [
    "documents_dict = load_pdfs(file_paths=files_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "93f8db4d-2ac5-481e-a59d-59c1e4bd626a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(len(documents_dict) == len(files_paths), len(documents_dict))\n",
    "\n",
    "# # print all the keys\n",
    "\n",
    "# from pprint import pprint\n",
    "\n",
    "# for k in documents_dict.keys():\n",
    "#     print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e62db443-bdb4-4ee3-a430-0ae2f1cd5cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "1413\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "\n",
    "print(len(documents_dict['/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap10.pdf']))\n",
    "d = documents_dict['/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap10.pdf']\n",
    "print(len(d[0].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c4f070b5-4c1a-4beb-8bd0-37b2dd218258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk the pdfs\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def chunk_list_of_documents(documents):\n",
    "    \"\"\"\n",
    "    input a list of documents as Document objects\n",
    "\n",
    "    output a list of chunks as Document objects\n",
    "    \"\"\"\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 500,\n",
    "        chunk_overlap = 100, # using 20% is a good start\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "        add_start_index=True\n",
    "    )\n",
    "\n",
    "    chunks = text_splitter.split_documents(documents)    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1a6fd1-f69a-47d3-89ea-991707c3f849",
   "metadata": {},
   "source": [
    "use only chap 16-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6463f919-1fa3-4877-87bc-b3b553f2e914",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\n",
    "    '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap16.pdf',\n",
    "    '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap17.pdf',\n",
    "    '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ca4f072b-c671-4b63-811f-9a617cd6d366",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 129.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "528"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_chunks = []\n",
    "\n",
    "for key in tqdm(keys):\n",
    "    documents = documents_dict[key]\n",
    "    chunks = chunk_list_of_documents(documents=documents)\n",
    "    all_chunks.extend(chunks)\n",
    "\n",
    "len(all_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0ab93158-3cdf-42ac-9879-986b4de35f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 0, 'start_index': 0}, page_content='This is page 649\\nPrinter: Opaque this\\n18\\nHigh-Dimensional Problems: p≫N\\n18.1 When pis Much Bigger than N\\nIn this chapter we discuss prediction problems in which the n umber of\\nfeaturespis much larger than the number of observations N, often written\\np≫N. Such problems have become of increasing importance, espec ially in\\ngenomics and other areas of computational biology. We will s ee that high\\nvariance and overﬁtting are a major concern in this setting. As a result,')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check \n",
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d0ac09b6-8681-4a8d-b74e-1295eb7e9e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup embedding model\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "\n",
    "hf_embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6ee51c6e-bb5d-44d0-b1f8-5b50fe99a9e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken:  15.72 s\n"
     ]
    }
   ],
   "source": [
    "# setup vectordb, using HF embedding model\n",
    "\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "start_time=time.time()\n",
    "vectorstore_hf = InMemoryVectorStore.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=hf_embedding_model\n",
    ")\n",
    "\n",
    "print(\"time taken: \",round(time.time()-start_time,2),\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "660d08bc-9830-4b5a-a016-2e07067e62da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for high-dimensional problems, with regards to p and N, in what cases can ridge regression exploit the correlation in the features of the dataset?\n",
      "using the optimal ridge parameter in each of the three cases, the median\n",
      "value of|tj|was 2.0, 0.6 and 0.2, and the average number of |tj|values\n",
      "exceeding 2 was equal to 9.8, 1.2 and 0.0.\n",
      "Ridge regression with λ= 0.001 successfully exploits the correlation in\n",
      "the features when p<N, but cannot do so when p≫N. In the latter case\n",
      "there is not enough information in the relatively small numb er of samples\n",
      "to eﬃciently estimate the high-dimensional covariance mat rix. In that case,\n"
     ]
    }
   ],
   "source": [
    "# setup retrieval and test with a query and gt_context\n",
    "\n",
    "retriever_hf = vectorstore_hf.as_retriever(\n",
    "    search_type='similarity',\n",
    "    search_kwargs = {'k':6 }\n",
    ")\n",
    "\n",
    "sample_query = \"for high-dimensional problems, with regards to p and N, in what \\\n",
    "cases can ridge regression exploit the correlation in the features of the dataset?\"\n",
    "sample_gt_context_start_index = 397\n",
    "sample_gt_context = [c for c in chunks if c.metadata['start_index']==sample_gt_context_start_index][0]\n",
    "\n",
    "print(sample_query)\n",
    "print(sample_gt_context.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "92af90d2-2b9d-4bc7-bf06-122bd8744e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs_hf = retriever_hf.invoke(input=sample_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2d68a965-0f1c-4bc6-955d-124ba4b0fe01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='0bdfb511-497a-44a7-a808-15f7dc4cb02e', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 2, 'start_index': 397}, page_content='using the optimal ridge parameter in each of the three cases, the median\\nvalue of|tj|was 2.0, 0.6 and 0.2, and the average number of |tj|values\\nexceeding 2 was equal to 9.8, 1.2 and 0.0.\\nRidge regression with λ= 0.001 successfully exploits the correlation in\\nthe features when p<N, but cannot do so when p≫N. In the latter case\\nthere is not enough information in the relatively small numb er of samples\\nto eﬃciently estimate the high-dimensional covariance mat rix. In that case,'),\n",
       " Document(id='07cf95bb-ef63-4ba4-9514-02161fe5cccb', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 1, 'start_index': 760}, page_content='over the 100 simulation runs. The p= 1000 case is designed to mimic the\\nkind of data that we might see in a high-dimensional genomic o r proteomic\\ndataset, for example.\\nWe ﬁt a ridge regression to the data, with three diﬀerent valu es for the\\nregularization parameter λ: 0.001, 100, and 1000. When λ= 0.001, this\\nis nearly the same as least squares regression, with a little regularization\\njust to ensure that the problem is non-singular when p > N. Figure 18.1'),\n",
       " Document(id='985cd759-7665-47ad-8cd5-45255d6c4080', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 1, 'start_index': 1150}, page_content='just to ensure that the problem is non-singular when p > N. Figure 18.1\\nshows boxplots oftherelative testerrorachieved bythediﬀ erentestimators\\nin each scenario. The corresponding average degrees of free dom used in\\neach ridge-regression ﬁt is indicated (computed using form ula (3.50) on\\npage 682). The degrees of freedom is a more interpretable parameter t han\\nλ. We see that ridge regression with λ= 0.001 (20 df) wins when p= 20;\\nλ= 100 (35 df) wins when p= 100, and λ= 1000 (43 df) wins when'),\n",
       " Document(id='73ae4254-512b-40ff-8774-6ccf1a436ed4', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 10, 'start_index': 1944}, page_content='shown to equal\\nˆβ=V(RTR+λI)−1RTy (18.15)\\n(Exercise 18.4). Thus ˆβ=Vˆθ, where ˆθis the ridge-regression estimate\\nusing theNobservations ( ri,yi),i= 1,2,...,N. In other words, we can\\nsimply reduce the data matrix from XtoR, and work with the rows of\\nR. This trick reduces the computational cost from O(p3) toO(pN2) when\\np>N.'),\n",
       " Document(id='ae44aefa-6114-4af1-921e-20c04dfe717f', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 2, 'start_index': 800}, page_content='to eﬃciently estimate the high-dimensional covariance mat rix. In that case,\\nmore regularization leads to superior prediction performa nce.\\nThus it is not surprising that the analysis of high-dimensio nal data re-\\nquires either modiﬁcation of procedures designed for the N >pscenario, or\\nentirely new procedures. In this chapter we discuss example s of both kinds\\nofapproachesforhighdimensionalclassiﬁcationandregre ssion;thesemeth-'),\n",
       " Document(id='507f89a3-02fd-4334-9bd4-20bc4cbac8cd', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 13, 'start_index': 1190}, page_content='variables; genes tend to operate in molecular pathways. The lasso penalty\\nis somewhat indiﬀerent to the choice among a set of strong but corre-\\nlated variables (Exercise 3.28). The ridge penalty, on the o ther hand, tends\\nto shrink the coeﬃcients of correlated variables toward eac h other (Exer-\\ncise 3.29 on page 99). The elastic net penalty (Zou and Hastie, 2005) is a\\ncompromise, and has the form\\np∑\\nj=1(\\nα|βj|+(1−α)β2\\nj)\\n. (18.20)')]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "95a80138-bda7-4d38-a8d1-33d6b81dde16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs_hf[0].page_content==sample_gt_context.page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7eeca9-d6f2-4972-84cf-1f2788cb88da",
   "metadata": {},
   "source": [
    "retriever works fine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2e60fe-12b4-4e5e-92da-888a732da66f",
   "metadata": {},
   "source": [
    "# setup RAG chain without memory, using Ollama LLM and HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0e08c5aa-adf4-4b43-bb72-25a9e31b0e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup ollama-llm\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm_model = ChatOllama(\n",
    "    model='llama3.1',\n",
    "    temperature=0 # increase temp for more creative answers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "81d730c1-ee2f-4979-bb4f-29df81f17a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 1.41s\n"
     ]
    }
   ],
   "source": [
    "# test sentence\n",
    "\n",
    "start_time = time.time()\n",
    "llm_model.invoke('explain gravity in 1 sentence')\n",
    "print(f'time taken: {round(time.time()-start_time,2)}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8266a2b2-3a5d-45d2-983a-aadf49fd0310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup rag prompt\n",
    "\n",
    "from langchain import hub\n",
    "\n",
    "rag_prompt_template = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7759b64e-ca27-494f-a0bc-667f5ae138c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['context', 'question']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_prompt_template.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "13344da2-3425-4cf3-80d0-a5ea9ca4ebf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_prompt_template.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "dc52dc02-ca4d-474e-b51f-90093ff7c703",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "message_input = {\"question\": RunnablePassthrough(), \"context\": retriever_hf}\n",
    "\n",
    "rag_chain = message_input| rag_prompt_template | llm_model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "cac64f9d-ce37-464e-8658-8290bc4251c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ridge regression can exploit the correlation in features when p < N, but not when p ≫ N, as there is not enough information to efficiently estimate the high-dimensional covariance matrix. In the latter case, more regularization leads to superior prediction performance. This is because ridge regression relies on estimating a high-dimensional covariance matrix, which becomes increasingly difficult with many features compared to samples.'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(input=sample_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba753791-6963-4f1e-874a-d4ebc7f5ae47",
   "metadata": {},
   "source": [
    "this is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d2f9d1aa-048c-4b24-88dd-933c640f59e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 2, 'start_index': 397}, page_content='using the optimal ridge parameter in each of the three cases, the median\\nvalue of|tj|was 2.0, 0.6 and 0.2, and the average number of |tj|values\\nexceeding 2 was equal to 9.8, 1.2 and 0.0.\\nRidge regression with λ= 0.001 successfully exploits the correlation in\\nthe features when p<N, but cannot do so when p≫N. In the latter case\\nthere is not enough information in the relatively small numb er of samples\\nto eﬃciently estimate the high-dimensional covariance mat rix. In that case,')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_gt_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "dd029038-3f95-434b-b242-ec6db9e753c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup chain to check context retrieved\n",
    "\n",
    "# to view the contexts retrieved can use a Runnable lambda\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def inspect(state):\n",
    "    return state\n",
    "\n",
    "message_input = {\"question\": RunnablePassthrough(), \"context\": retriever_hf}\n",
    "context_chain = message_input| RunnableLambda(inspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bf97d1e1-f3fe-4129-9c6e-f904ed0baa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_retrieved = context_chain.invoke(input=sample_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d3847edd-e9f1-497a-afdf-d232f774a3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,\n",
       " Document(id='0bdfb511-497a-44a7-a808-15f7dc4cb02e', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 2, 'start_index': 397}, page_content='using the optimal ridge parameter in each of the three cases, the median\\nvalue of|tj|was 2.0, 0.6 and 0.2, and the average number of |tj|values\\nexceeding 2 was equal to 9.8, 1.2 and 0.0.\\nRidge regression with λ= 0.001 successfully exploits the correlation in\\nthe features when p<N, but cannot do so when p≫N. In the latter case\\nthere is not enough information in the relatively small numb er of samples\\nto eﬃciently estimate the high-dimensional covariance mat rix. In that case,'))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(context_retrieved['context']),context_retrieved['context'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "06644621-6307-4969-b0e2-354bca4d65d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# integrate together context chain and rag chain\n",
    "\n",
    "import time\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def get_current_chain_state(state):\n",
    "    \"\"\"\n",
    "    returns the current state of the chain, in dict format, following message_input format.\n",
    "    \"\"\"\n",
    "    return state\n",
    "    \n",
    "def setup_rag_context_chains(retriever,prompt_template,model):\n",
    "    \"\"\"\n",
    "    must ensure that the prompt_template has the same input variables \n",
    "    as the keys in the message input in the function.\n",
    "    \"\"\"\n",
    "    message_input = {\"question\": RunnablePassthrough(), \"context\": retriever}\n",
    "\n",
    "    context_chain = message_input| RunnableLambda(get_current_chain_state)\n",
    "    rag_chain = message_input| prompt_template | model | StrOutputParser()\n",
    "\n",
    "    return context_chain, rag_chain\n",
    "\n",
    "def query_llm(rag_chain,query):\n",
    "    \"\"\"\n",
    "    query is type str and will be passed into message input under question input variable.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    response = rag_chain.invoke(input=query)\n",
    "    time_taken = round(time.time()-start_time,2)\n",
    "    \n",
    "    print(f'time taken: {time_taken}s')\n",
    "    return response\n",
    "\n",
    "def get_query_contexts_retrieved(context_chain,query):\n",
    "    \"\"\"\n",
    "    query is type str and will be passed into message input under question input variable.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    state = context_chain.invoke(input=query)\n",
    "    contexts_retrieved = state['context']\n",
    "    time_taken = round(time.time()-start_time,2)\n",
    "    \n",
    "    print(f'time taken: {time_taken}s')\n",
    "    return contexts_retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "afc3d79f-04bf-41e4-bb33-b09647698804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for high-dimensional problems, with regards to p and N, in what cases can ridge regression exploit the correlation in the features of the dataset?'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a64c32e3-04f5-4406-ae00-9e245bf21176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 2, 'start_index': 397}, page_content='using the optimal ridge parameter in each of the three cases, the median\\nvalue of|tj|was 2.0, 0.6 and 0.2, and the average number of |tj|values\\nexceeding 2 was equal to 9.8, 1.2 and 0.0.\\nRidge regression with λ= 0.001 successfully exploits the correlation in\\nthe features when p<N, but cannot do so when p≫N. In the latter case\\nthere is not enough information in the relatively small numb er of samples\\nto eﬃciently estimate the high-dimensional covariance mat rix. In that case,')"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_gt_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "9065cb9f-eb18-433f-949a-a6d217c07b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_chain, rag_chain = setup_rag_context_chains(retriever_hf,rag_prompt_template,llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "be3637ce-45a0-4b8c-94a7-69a693fc717d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 3.37s\n"
     ]
    }
   ],
   "source": [
    "response = query_llm(rag_chain,sample_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "b152203e-867a-43aa-8fc1-23b0d3dfe329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ridge regression can exploit the correlation in features when p < N, but not when p ≫ N, as there is not enough information to efficiently estimate the high-dimensional covariance matrix. In the latter case, more regularization leads to superior prediction performance. This is because ridge regression relies on estimating a high-dimensional covariance matrix, which becomes increasingly difficult with many features compared to samples.'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "b253fe02-d251-4bb8-b696-9622245666ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 0.11s\n"
     ]
    }
   ],
   "source": [
    "contexts_retrieved = get_query_contexts_retrieved(context_chain,sample_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a63b0fe6-8693-4134-be3f-8146b4670a9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='0bdfb511-497a-44a7-a808-15f7dc4cb02e', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 2, 'start_index': 397}, page_content='using the optimal ridge parameter in each of the three cases, the median\\nvalue of|tj|was 2.0, 0.6 and 0.2, and the average number of |tj|values\\nexceeding 2 was equal to 9.8, 1.2 and 0.0.\\nRidge regression with λ= 0.001 successfully exploits the correlation in\\nthe features when p<N, but cannot do so when p≫N. In the latter case\\nthere is not enough information in the relatively small numb er of samples\\nto eﬃciently estimate the high-dimensional covariance mat rix. In that case,'),\n",
       " Document(id='07cf95bb-ef63-4ba4-9514-02161fe5cccb', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 1, 'start_index': 760}, page_content='over the 100 simulation runs. The p= 1000 case is designed to mimic the\\nkind of data that we might see in a high-dimensional genomic o r proteomic\\ndataset, for example.\\nWe ﬁt a ridge regression to the data, with three diﬀerent valu es for the\\nregularization parameter λ: 0.001, 100, and 1000. When λ= 0.001, this\\nis nearly the same as least squares regression, with a little regularization\\njust to ensure that the problem is non-singular when p > N. Figure 18.1'),\n",
       " Document(id='985cd759-7665-47ad-8cd5-45255d6c4080', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 1, 'start_index': 1150}, page_content='just to ensure that the problem is non-singular when p > N. Figure 18.1\\nshows boxplots oftherelative testerrorachieved bythediﬀ erentestimators\\nin each scenario. The corresponding average degrees of free dom used in\\neach ridge-regression ﬁt is indicated (computed using form ula (3.50) on\\npage 682). The degrees of freedom is a more interpretable parameter t han\\nλ. We see that ridge regression with λ= 0.001 (20 df) wins when p= 20;\\nλ= 100 (35 df) wins when p= 100, and λ= 1000 (43 df) wins when'),\n",
       " Document(id='73ae4254-512b-40ff-8774-6ccf1a436ed4', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 10, 'start_index': 1944}, page_content='shown to equal\\nˆβ=V(RTR+λI)−1RTy (18.15)\\n(Exercise 18.4). Thus ˆβ=Vˆθ, where ˆθis the ridge-regression estimate\\nusing theNobservations ( ri,yi),i= 1,2,...,N. In other words, we can\\nsimply reduce the data matrix from XtoR, and work with the rows of\\nR. This trick reduces the computational cost from O(p3) toO(pN2) when\\np>N.'),\n",
       " Document(id='ae44aefa-6114-4af1-921e-20c04dfe717f', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 2, 'start_index': 800}, page_content='to eﬃciently estimate the high-dimensional covariance mat rix. In that case,\\nmore regularization leads to superior prediction performa nce.\\nThus it is not surprising that the analysis of high-dimensio nal data re-\\nquires either modiﬁcation of procedures designed for the N >pscenario, or\\nentirely new procedures. In this chapter we discuss example s of both kinds\\nofapproachesforhighdimensionalclassiﬁcationandregre ssion;thesemeth-'),\n",
       " Document(id='507f89a3-02fd-4334-9bd4-20bc4cbac8cd', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 13, 'start_index': 1190}, page_content='variables; genes tend to operate in molecular pathways. The lasso penalty\\nis somewhat indiﬀerent to the choice among a set of strong but corre-\\nlated variables (Exercise 3.28). The ridge penalty, on the o ther hand, tends\\nto shrink the coeﬃcients of correlated variables toward eac h other (Exer-\\ncise 3.29 on page 99). The elastic net penalty (Zou and Hastie, 2005) is a\\ncompromise, and has the form\\np∑\\nj=1(\\nα|βj|+(1−α)β2\\nj)\\n. (18.20)')]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts_retrieved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd619aa-7e5d-472a-890d-b80b099276d5",
   "metadata": {},
   "source": [
    "# setup memory and integrate into rag chain\n",
    "\n",
    "* https://python.langchain.com/v0.2/docs/how_to/qa_chat_history_how_to/\n",
    "* https://medium.com/@eric_vaillancourt/mastering-langchain-rag-integrating-chat-history-part-2-4c80eae11b43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "66a73b99-9910-4d63-990b-2fc81bbb1b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['InMemoryVectorStore', 'HuggingFaceEmbeddings'], vectorstore=<langchain_core.vectorstores.in_memory.InMemoryVectorStore object at 0x3df1e9cd0>, search_kwargs={'k': 6})"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_hf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76620523-4dfa-40a2-883e-f686942ba431",
   "metadata": {},
   "source": [
    "Prompt using MessagePlaceHolder to pass the entire conversation to the LLM before the actual current query\n",
    "\n",
    "We'll use a prompt that includes a MessagesPlaceholder variable under the name \"chat_history\". This allows us to pass in a list of Messages to the prompt using the \"chat_history\" input key, and these messages will be inserted after the system message and before the human message containing the latest question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "04b921a7-6416-4cf9-8b13-73f1bd0aac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "system_contextualise_input_prompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"formulate a standalone question which can be understood \"\n",
    "    \"without the chat history. Do NOT answer the question, \"\n",
    "    \"just reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "\n",
    "system_input_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_contextualise_input_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e142a7-0328-462b-a169-13b4b2967272",
   "metadata": {},
   "source": [
    "purpose of system instruction is to:\n",
    "The goal is to contextualize or disambiguate user questions based on previous chat history. In multi-turn conversations, users often refer to earlier parts of the conversation (e.g., \"What about that?\" or \"Can you clarify?\"). To handle these cases, you need to reformulate the question to make it self-contained so that the underlying system (like a retriever or LLM) can process it without needing the full conversation context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33270ca1-865f-4ad2-8fd7-7bc99b3cda2d",
   "metadata": {},
   "source": [
    "example:\n",
    "In a chatbot, users might ask follow-up questions that rely on previous answers:\n",
    "\n",
    "Example 1:\n",
    "\n",
    "Chat history: \"What’s the capital of France?\"\n",
    "User input: \"And what’s its population?\"\n",
    "The AI needs to reformulate this as: \"What’s the population of Paris?\" for further processing or retrieval.\n",
    "Example 2:\n",
    "\n",
    "Chat history: \"Can you tell me about the Tesla Model 3?\"\n",
    "User input: \"What are its key features?\"\n",
    "The reformulated question should be: \"What are the key features of the Tesla Model 3?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfd8e70-46c9-42b8-a435-292ca83ccb48",
   "metadata": {},
   "source": [
    "Why is this Important?\n",
    "Disambiguation: In a multi-turn conversation, users often ask incomplete or context-dependent questions. This setup makes the question standalone so it can be processed correctly without needing to recall the entire conversation.\n",
    "\n",
    "Improving Retrieval: If you're using a retriever (e.g., for document search), a well-formulated query leads to better results. Incomplete questions can return irrelevant information, while self-contained questions ensure that the retriever fetches the most accurate data.\n",
    "\n",
    "Efficiency: It allows you to keep the conversation flowing smoothly without requiring constant reference to the full history, saving computational resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "2ac8a5b0-59b7-4dec-b668-8f11350d63e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the history-aware retriever:\n",
    "\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm=llm_model,\n",
    "    retriever=retriever_hf,\n",
    "    prompt=system_input_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6724e0-dbfb-4e3e-9e7d-ff392c91ffa0",
   "metadata": {},
   "source": [
    "1. system_instruction_prompt\n",
    "- Disambiguation (Standalone Question Formulation):\n",
    "The block of code that creates the system_instruction_prompt is responsible for reformulating or disambiguating the user’s question based on the chat history. The purpose of this is to:\n",
    "\n",
    "Ensure that incomplete or ambiguous user questions are rephrased into a standalone question.\n",
    "The system does not answer the question but simply reformulates it so that it makes sense without requiring the full chat history.\n",
    "\n",
    "2. history_aware_retriever\n",
    "- Improving Retrieval:\n",
    "By combining the disambiguation mechanism with the history-aware retriever, you're ensuring that the reformulated (standalone) question can be used for better retrieval of relevant information from an external knowledge base.\n",
    "- this retrieval part is same as normal retrieval part of RAG chain\n",
    "- except it does not do retrieval only on the query like retrieval.invoke but does retrieval.invoke on the output of the system_instruction_prompt to generate better prompt for retrieval\n",
    "- history_aware_retriever: Create a chain that takes conversation history and returns documents.\n",
    "\n",
    "If there is no chat_history, then the input is just passed directly to the retriever. If there is chat_history, then the prompt and LLM will be used to generate a search query. That search query is then passed to the retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "ee9c2903-93e5-49ac-a7d2-e5f4160b1cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBranch(branches=[(RunnableLambda(lambda x: not x.get('chat_history', False)), RunnableLambda(lambda x: x['input'])\n",
       "| VectorStoreRetriever(tags=['InMemoryVectorStore', 'HuggingFaceEmbeddings'], vectorstore=<langchain_core.vectorstores.in_memory.InMemoryVectorStore object at 0x3df1e9cd0>, search_kwargs={'k': 6}))], default=ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Given a chat history and the latest user question which might reference context in the chat history, formulate a standalone question which can be understood without the chat history. Do NOT answer the question, just reformulate it if needed and otherwise return it as is.')), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])\n",
       "| ChatOllama(model='llama3.1', temperature=0.0, _client=<ollama._client.Client object at 0x3f6f8f6d0>, _async_client=<ollama._client.AsyncClient object at 0x3f6f8fee0>)\n",
       "| StrOutputParser()\n",
       "| VectorStoreRetriever(tags=['InMemoryVectorStore', 'HuggingFaceEmbeddings'], vectorstore=<langchain_core.vectorstores.in_memory.InMemoryVectorStore object at 0x3df1e9cd0>, search_kwargs={'k': 6})), config={'run_name': 'chat_retriever_chain'})"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_aware_retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573ce509-1b30-429c-b4e3-912d0fca6447",
   "metadata": {},
   "source": [
    "This chain prepends a rephrasing of the input query to our retriever, so that the retrieval incorporates the context of the conversation.\n",
    "- prepends as in append but at the start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f40d49f-4e84-4598-bbe4-28416ca80a46",
   "metadata": {},
   "source": [
    "idea behind this is\n",
    "1. prompt the LLM to use the conversation history to generate a complete question. e.g. if the user input is \"explain it\", then the LLM will look at the conversation history and figure out what \"it\" refers to and then generate a new complete standalone question --> \"explain the Poisson distribution\"\n",
    "2. the new complete question will then be used for the RAG chain and the RAG chain is used as per usual\n",
    "3. history_aware_retriever takes care of the conversation_history+question_input part + retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "4086d7f2-6522-48bf-be0e-12a319ab4947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "system_rag_qna_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "system_rag_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system',system_rag_qna_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        ('human',\"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "05b9db82-b3dd-4c2b-bf6c-02d37a416c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate qna_chain\n",
    "\n",
    "qna_chain = create_stuff_documents_chain(llm=llm_model,prompt=system_rag_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "e06470ba-e943-4ff3-9483-488c377f2b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), config={'run_name': 'format_inputs'})\n",
       "| ChatPromptTemplate(input_variables=['chat_history', 'context', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, say that you don't know. Use three sentences maximum and keep the answer concise.\\n\\n{context}\")), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])\n",
       "| ChatOllama(model='llama3.1', temperature=0.0, _client=<ollama._client.Client object at 0x3f6f8f6d0>, _async_client=<ollama._client.AsyncClient object at 0x3f6f8fee0>)\n",
       "| StrOutputParser(), config={'run_name': 'stuff_documents_chain'})"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90db6466-a125-4f8e-a6a7-45adba434a9f",
   "metadata": {},
   "source": [
    "use create_stuff_documents_chain to generate a question_answer_chain, with input keys context, chat_history, and input-- it accepts the retrieved context alongside the conversation history and query to generate an answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "0c02ff0e-bb6b-4cd2-a592-6d29e1e753fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate rag_chain\n",
    "\n",
    "rag_chain = create_retrieval_chain(retriever=history_aware_retriever,combine_docs_chain=qna_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "1a821e54-94e5-4788-a303-428e9c0f23b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableBranch(branches=[(RunnableLambda(lambda x: not x.get('chat_history', False)), RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['InMemoryVectorStore', 'HuggingFaceEmbeddings'], vectorstore=<langchain_core.vectorstores.in_memory.InMemoryVectorStore object at 0x3df1e9cd0>, search_kwargs={'k': 6}))], default=ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Given a chat history and the latest user question which might reference context in the chat history, formulate a standalone question which can be understood without the chat history. Do NOT answer the question, just reformulate it if needed and otherwise return it as is.')), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])\n",
       "           | ChatOllama(model='llama3.1', temperature=0.0, _client=<ollama._client.Client object at 0x3f6f8f6d0>, _async_client=<ollama._client.AsyncClient object at 0x3f6f8fee0>)\n",
       "           | StrOutputParser()\n",
       "           | VectorStoreRetriever(tags=['InMemoryVectorStore', 'HuggingFaceEmbeddings'], vectorstore=<langchain_core.vectorstores.in_memory.InMemoryVectorStore object at 0x3df1e9cd0>, search_kwargs={'k': 6})), config={'run_name': 'retrieve_documents'})\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), config={'run_name': 'format_inputs'})\n",
       "            | ChatPromptTemplate(input_variables=['chat_history', 'context', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, say that you don't know. Use three sentences maximum and keep the answer concise.\\n\\n{context}\")), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])\n",
       "            | ChatOllama(model='llama3.1', temperature=0.0, _client=<ollama._client.Client object at 0x3f6f8f6d0>, _async_client=<ollama._client.AsyncClient object at 0x3f6f8fee0>)\n",
       "            | StrOutputParser(), config={'run_name': 'stuff_documents_chain'})\n",
       "  }), config={'run_name': 'retrieval_chain'})"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c8e18c-8824-4ced-a303-6535c9f56847",
   "metadata": {},
   "source": [
    "chain applies the history_aware_retriever and question_answer_chain in sequence, retaining intermediate outputs such as the retrieved context for convenience. It has input keys input and chat_history, and includes input, chat_history, context, and answer in its output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ab80dd-ed5c-4a69-9a70-68888af1cad0",
   "metadata": {},
   "source": [
    "rag_chain has 1. history aware retriever, 2. qna chain\n",
    "overall chain structure is \n",
    "contextualise input > use new standalone question for retrieval > use retrieved context for qna\n",
    "\n",
    "1. history aware retriever\n",
    "- contextualise input using chat_history\n",
    "    - if there is chat_history (i.e. not null), prompt and LLM will be used to generate a search query. That search query is then passed to the retriever\n",
    "    - if there is no chat_history, then the input is just passed directly to the retriever\n",
    "- use new standalone question for retrieval\n",
    "- use retrieved context for qna\n",
    "2. qna chain\n",
    "- typical rag qna chain that takes as input \"context\" from the retriever and \"input\" of the new standalone question from the history_aware_retriever's system_contextualise_input_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c810b1-baf0-48b3-9d2d-6c98c535b22d",
   "metadata": {},
   "source": [
    "setup conversation history (without persistence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "bdd2d8d8-924f-487e-893d-bc8c0eb46bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# simple conversation history store using dict - storage saved to current sess only, no persistence\n",
    "history_store = {}\n",
    "\n",
    "def get_session_history(session_id: str):\n",
    "    if session_id not in history_store:\n",
    "        history_store[session_id] = ChatMessageHistory()\n",
    "    return history_store[session_id]\n",
    "\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    runnable=rag_chain,\n",
    "    get_session_history=get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "9a64be0c-8c04-42c2-a60d-6253b9e41e1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='0bdfb511-497a-44a7-a808-15f7dc4cb02e', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 2, 'start_index': 397}, page_content='using the optimal ridge parameter in each of the three cases, the median\\nvalue of|tj|was 2.0, 0.6 and 0.2, and the average number of |tj|values\\nexceeding 2 was equal to 9.8, 1.2 and 0.0.\\nRidge regression with λ= 0.001 successfully exploits the correlation in\\nthe features when p<N, but cannot do so when p≫N. In the latter case\\nthere is not enough information in the relatively small numb er of samples\\nto eﬃciently estimate the high-dimensional covariance mat rix. In that case,'),\n",
       " Document(id='07cf95bb-ef63-4ba4-9514-02161fe5cccb', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 1, 'start_index': 760}, page_content='over the 100 simulation runs. The p= 1000 case is designed to mimic the\\nkind of data that we might see in a high-dimensional genomic o r proteomic\\ndataset, for example.\\nWe ﬁt a ridge regression to the data, with three diﬀerent valu es for the\\nregularization parameter λ: 0.001, 100, and 1000. When λ= 0.001, this\\nis nearly the same as least squares regression, with a little regularization\\njust to ensure that the problem is non-singular when p > N. Figure 18.1'),\n",
       " Document(id='985cd759-7665-47ad-8cd5-45255d6c4080', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 1, 'start_index': 1150}, page_content='just to ensure that the problem is non-singular when p > N. Figure 18.1\\nshows boxplots oftherelative testerrorachieved bythediﬀ erentestimators\\nin each scenario. The corresponding average degrees of free dom used in\\neach ridge-regression ﬁt is indicated (computed using form ula (3.50) on\\npage 682). The degrees of freedom is a more interpretable parameter t han\\nλ. We see that ridge regression with λ= 0.001 (20 df) wins when p= 20;\\nλ= 100 (35 df) wins when p= 100, and λ= 1000 (43 df) wins when'),\n",
       " Document(id='73ae4254-512b-40ff-8774-6ccf1a436ed4', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 10, 'start_index': 1944}, page_content='shown to equal\\nˆβ=V(RTR+λI)−1RTy (18.15)\\n(Exercise 18.4). Thus ˆβ=Vˆθ, where ˆθis the ridge-regression estimate\\nusing theNobservations ( ri,yi),i= 1,2,...,N. In other words, we can\\nsimply reduce the data matrix from XtoR, and work with the rows of\\nR. This trick reduces the computational cost from O(p3) toO(pN2) when\\np>N.'),\n",
       " Document(id='ae44aefa-6114-4af1-921e-20c04dfe717f', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 2, 'start_index': 800}, page_content='to eﬃciently estimate the high-dimensional covariance mat rix. In that case,\\nmore regularization leads to superior prediction performa nce.\\nThus it is not surprising that the analysis of high-dimensio nal data re-\\nquires either modiﬁcation of procedures designed for the N >pscenario, or\\nentirely new procedures. In this chapter we discuss example s of both kinds\\nofapproachesforhighdimensionalclassiﬁcationandregre ssion;thesemeth-'),\n",
       " Document(id='507f89a3-02fd-4334-9bd4-20bc4cbac8cd', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 13, 'start_index': 1190}, page_content='variables; genes tend to operate in molecular pathways. The lasso penalty\\nis somewhat indiﬀerent to the choice among a set of strong but corre-\\nlated variables (Exercise 3.28). The ridge penalty, on the o ther hand, tends\\nto shrink the coeﬃcients of correlated variables toward eac h other (Exer-\\ncise 3.29 on page 99). The elastic net penalty (Zou and Hastie, 2005) is a\\ncompromise, and has the form\\np∑\\nj=1(\\nα|βj|+(1−α)β2\\nj)\\n. (18.20)')]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_hf.invoke(sample_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "37b7e80e-6eec-460b-b7b0-3b9699c9d9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = conversational_rag_chain.invoke(\n",
    "    input={\n",
    "        'input': 'explain ridge regression in context of high dimensional problems'\n",
    "    },\n",
    "    config={\n",
    "        'configurable':{'session_id':'1'}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "c0887eaf-d238-4ef3-93ad-8dc45b60943e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'explain ridge regression in context of high dimensional problems',\n",
       " 'chat_history': [],\n",
       " 'context': [Document(id='07cf95bb-ef63-4ba4-9514-02161fe5cccb', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 1, 'start_index': 760}, page_content='over the 100 simulation runs. The p= 1000 case is designed to mimic the\\nkind of data that we might see in a high-dimensional genomic o r proteomic\\ndataset, for example.\\nWe ﬁt a ridge regression to the data, with three diﬀerent valu es for the\\nregularization parameter λ: 0.001, 100, and 1000. When λ= 0.001, this\\nis nearly the same as least squares regression, with a little regularization\\njust to ensure that the problem is non-singular when p > N. Figure 18.1'),\n",
       "  Document(id='985cd759-7665-47ad-8cd5-45255d6c4080', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 1, 'start_index': 1150}, page_content='just to ensure that the problem is non-singular when p > N. Figure 18.1\\nshows boxplots oftherelative testerrorachieved bythediﬀ erentestimators\\nin each scenario. The corresponding average degrees of free dom used in\\neach ridge-regression ﬁt is indicated (computed using form ula (3.50) on\\npage 682). The degrees of freedom is a more interpretable parameter t han\\nλ. We see that ridge regression with λ= 0.001 (20 df) wins when p= 20;\\nλ= 100 (35 df) wins when p= 100, and λ= 1000 (43 df) wins when'),\n",
       "  Document(id='8ae52bfa-978d-4d78-a0a1-460f3396239d', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 1, 'start_index': 368}, page_content='ofp, the number of features. The relative error is the test error d ivided by the\\nBayes error, σ2. From left to right, results are shown for ridge regression wit h\\nthree diﬀerent values of the regularization parameter λ:0.001,100and1000. The\\n(average) eﬀective degrees of freedom in the ﬁt is indicated below each plot.\\nvariate regression coeﬃcients1was 9, 33 and 331, respectively, averaged\\nover the 100 simulation runs. The p= 1000 case is designed to mimic the'),\n",
       "  Document(id='73ae4254-512b-40ff-8774-6ccf1a436ed4', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 10, 'start_index': 1944}, page_content='shown to equal\\nˆβ=V(RTR+λI)−1RTy (18.15)\\n(Exercise 18.4). Thus ˆβ=Vˆθ, where ˆθis the ridge-regression estimate\\nusing theNobservations ( ri,yi),i= 1,2,...,N. In other words, we can\\nsimply reduce the data matrix from XtoR, and work with the rows of\\nR. This trick reduces the computational cost from O(p3) toO(pN2) when\\np>N.'),\n",
       "  Document(id='373cf737-0049-4be6-a6a0-642c0f33f4f3', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 45, 'start_index': 1585}, page_content='how they can be resolved.\\nEx. 18.4 Derive the computational formula (18.15) for ridge regress ion.\\n[Hint: Use the ﬁrst derivative of the penalized sum-of-squares cr iterion to\\nshow that if λ>0, thenˆβ=XTsfor somes∈IRN.]\\nEx. 18.5 Prove the theorem (18.16)–(18.17) in Section 18.3.5, by dec om-\\nposingβand the rows of Xinto their projections into the column space of\\nVand its complement in IRp.\\nEx. 18.6 Show how the theorem in Section 18.3.5 can be applied to regu-'),\n",
       "  Document(id='bf56a359-4a50-4e64-96f1-114bd3e44aea', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 45, 'start_index': 1185}, page_content='k=1|µjk|\\nsj.\\uf8fc\\n\\uf8fd\\n\\uf8fe(18.55)\\nShow that the solution is equivalent to the nearest shrunken centroid es-\\ntimator (18.7), with s0set to zero, and m2\\nkequal to 1/Nkinstead of\\n1/Nk−1/Nas before.\\nEx. 18.3 Show that the ﬁtted coeﬃcients for the regularized multicla ss\\nlogistic regression problem (18.10) satisfy∑K\\nk=1ˆβkj= 0, j= 1,...,p.\\nWhat about the ˆβk0? Discuss issues with these constant parameters, and\\nhow they can be resolved.\\nEx. 18.4 Derive the computational formula (18.15) for ridge regress ion.')],\n",
       " 'answer': \"In the context of high-dimensional problems, such as genomic or proteomic datasets with thousands of features, Ridge Regression is a regularization technique used to prevent overfitting and improve model generalizability.\\n\\nRidge Regression adds a penalty term to the least squares loss function, which is proportional to the magnitude of the regression coefficients. This penalty term, controlled by the regularization parameter λ, encourages the model to produce smaller coefficients for all features, thereby reducing the impact of noise and irrelevant variables on the model's performance.\\n\\nBy doing so, Ridge Regression:\\n\\n1. Reduces overfitting: By shrinking the coefficients towards zero, Ridge Regression prevents the model from memorizing the training data and generalizes better to new, unseen data.\\n2. Improves interpretability: The regularization parameter λ provides a more interpretable measure of the model's complexity than the number of features used.\\n3. Handles high-dimensional data: In high-dimensional spaces, Ridge Regression can be particularly effective in reducing the impact of irrelevant variables and improving model performance.\\n\\nThe choice of λ is crucial, as it controls the trade-off between fitting the training data and generalizing to new data. A small value of λ (e.g., 0.001) results in a model that is nearly equivalent to least squares regression, while larger values (e.g., 100 or 1000) lead to more regularization and potentially better generalization performance.\\n\\nIn the context of high-dimensional problems, Ridge Regression can be particularly useful when:\\n\\n* The number of features (p) exceeds the number of observations (N), making it difficult for traditional least squares regression to converge.\\n* Many features are irrelevant or noisy, which can negatively impact model performance.\\n\\nBy applying Ridge Regression in these scenarios, researchers and practitioners can develop more robust and generalizable models that better capture the underlying relationships between variables.\"}"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "attachments": {
    "0a4a085c-9326-474c-a2a1-f74e3cf73ef4.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAABjEAAALnCAYAAADI0WVEAAABXmlDQ1BJQ0MgUHJvZmlsZQAAKJF1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\nI+R4AAAAAElFTkSuQmCC\n"
    }
   },
   "cell_type": "markdown",
   "id": "bc8cd749-2af1-411c-9605-9d6fd302d277",
   "metadata": {},
   "source": [
    "Conversational RAG Structure\n",
    "![conversational_rag_structure.png](attachment:0a4a085c-9326-474c-a2a1-f74e3cf73ef4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "a4480469-776a-4fe9-a209-5a39b38daebf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input', 'chat_history', 'context', 'answer'])"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "75bb7e9a-97eb-4544-8ae8-c858f02192ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'explain ridge regression in context of high dimensional problems'"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "fa3d8d67-55c3-43be-9c64-81be91fba46b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['chat_history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "a47500fd-fc1f-42cd-8f2d-4cd5a43bda73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='07cf95bb-ef63-4ba4-9514-02161fe5cccb', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 1, 'start_index': 760}, page_content='over the 100 simulation runs. The p= 1000 case is designed to mimic the\\nkind of data that we might see in a high-dimensional genomic o r proteomic\\ndataset, for example.\\nWe ﬁt a ridge regression to the data, with three diﬀerent valu es for the\\nregularization parameter λ: 0.001, 100, and 1000. When λ= 0.001, this\\nis nearly the same as least squares regression, with a little regularization\\njust to ensure that the problem is non-singular when p > N. Figure 18.1'),\n",
       " Document(id='985cd759-7665-47ad-8cd5-45255d6c4080', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 1, 'start_index': 1150}, page_content='just to ensure that the problem is non-singular when p > N. Figure 18.1\\nshows boxplots oftherelative testerrorachieved bythediﬀ erentestimators\\nin each scenario. The corresponding average degrees of free dom used in\\neach ridge-regression ﬁt is indicated (computed using form ula (3.50) on\\npage 682). The degrees of freedom is a more interpretable parameter t han\\nλ. We see that ridge regression with λ= 0.001 (20 df) wins when p= 20;\\nλ= 100 (35 df) wins when p= 100, and λ= 1000 (43 df) wins when'),\n",
       " Document(id='8ae52bfa-978d-4d78-a0a1-460f3396239d', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 1, 'start_index': 368}, page_content='ofp, the number of features. The relative error is the test error d ivided by the\\nBayes error, σ2. From left to right, results are shown for ridge regression wit h\\nthree diﬀerent values of the regularization parameter λ:0.001,100and1000. The\\n(average) eﬀective degrees of freedom in the ﬁt is indicated below each plot.\\nvariate regression coeﬃcients1was 9, 33 and 331, respectively, averaged\\nover the 100 simulation runs. The p= 1000 case is designed to mimic the'),\n",
       " Document(id='73ae4254-512b-40ff-8774-6ccf1a436ed4', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 10, 'start_index': 1944}, page_content='shown to equal\\nˆβ=V(RTR+λI)−1RTy (18.15)\\n(Exercise 18.4). Thus ˆβ=Vˆθ, where ˆθis the ridge-regression estimate\\nusing theNobservations ( ri,yi),i= 1,2,...,N. In other words, we can\\nsimply reduce the data matrix from XtoR, and work with the rows of\\nR. This trick reduces the computational cost from O(p3) toO(pN2) when\\np>N.'),\n",
       " Document(id='373cf737-0049-4be6-a6a0-642c0f33f4f3', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 45, 'start_index': 1585}, page_content='how they can be resolved.\\nEx. 18.4 Derive the computational formula (18.15) for ridge regress ion.\\n[Hint: Use the ﬁrst derivative of the penalized sum-of-squares cr iterion to\\nshow that if λ>0, thenˆβ=XTsfor somes∈IRN.]\\nEx. 18.5 Prove the theorem (18.16)–(18.17) in Section 18.3.5, by dec om-\\nposingβand the rows of Xinto their projections into the column space of\\nVand its complement in IRp.\\nEx. 18.6 Show how the theorem in Section 18.3.5 can be applied to regu-'),\n",
       " Document(id='bf56a359-4a50-4e64-96f1-114bd3e44aea', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 45, 'start_index': 1185}, page_content='k=1|µjk|\\nsj.\\uf8fc\\n\\uf8fd\\n\\uf8fe(18.55)\\nShow that the solution is equivalent to the nearest shrunken centroid es-\\ntimator (18.7), with s0set to zero, and m2\\nkequal to 1/Nkinstead of\\n1/Nk−1/Nas before.\\nEx. 18.3 Show that the ﬁtted coeﬃcients for the regularized multicla ss\\nlogistic regression problem (18.10) satisfy∑K\\nk=1ˆβkj= 0, j= 1,...,p.\\nWhat about the ˆβk0? Discuss issues with these constant parameters, and\\nhow they can be resolved.\\nEx. 18.4 Derive the computational formula (18.15) for ridge regress ion.')]"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "1b533175-6755-4ae7-96cd-71dc98fa52fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In the context of high-dimensional problems, such as genomic or proteomic datasets with thousands of features, Ridge Regression is a regularization technique used to prevent overfitting and improve model generalizability.\\n\\nRidge Regression adds a penalty term to the least squares loss function, which is proportional to the magnitude of the regression coefficients. This penalty term, controlled by the regularization parameter λ, encourages the model to produce smaller coefficients for all features, thereby reducing the impact of noise and irrelevant variables on the model's performance.\\n\\nBy doing so, Ridge Regression:\\n\\n1. Reduces overfitting: By shrinking the coefficients towards zero, Ridge Regression prevents the model from memorizing the training data and generalizes better to new, unseen data.\\n2. Improves interpretability: The regularization parameter λ provides a more interpretable measure of the model's complexity than the number of features used.\\n3. Handles high-dimensional data: In high-dimensional spaces, Ridge Regression can be particularly effective in reducing the impact of irrelevant variables and improving model performance.\\n\\nThe choice of λ is crucial, as it controls the trade-off between fitting the training data and generalizing to new data. A small value of λ (e.g., 0.001) results in a model that is nearly equivalent to least squares regression, while larger values (e.g., 100 or 1000) lead to more regularization and potentially better generalization performance.\\n\\nIn the context of high-dimensional problems, Ridge Regression can be particularly useful when:\\n\\n* The number of features (p) exceeds the number of observations (N), making it difficult for traditional least squares regression to converge.\\n* Many features are irrelevant or noisy, which can negatively impact model performance.\\n\\nBy applying Ridge Regression in these scenarios, researchers and practitioners can develop more robust and generalizable models that better capture the underlying relationships between variables.\""
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "ef5f5d88-2c19-440c-98c1-775357058a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for high-dimensional problems, with regards to p and N, in what cases can ridge regression exploit the correlation in the features of the dataset?'"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "31c233ee-5900-457b-94fc-a11fec2fef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = conversational_rag_chain.invoke(\n",
    "    input={\n",
    "        'input': f'elaborate on this and also explain {sample_query}'\n",
    "    },\n",
    "    config={\n",
    "        'configurable':{'session_id':'1'}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "dac5d8c2-6319-402d-a222-eeac7cda4279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'elaborate on this and also explain for high-dimensional problems, with regards to p and N, in what cases can ridge regression exploit the correlation in the features of the dataset?'"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2['input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "b557a85e-124c-47cc-a4bb-4dcc11cfe37f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='explain ridge regression in context of high dimensional problems'),\n",
       " AIMessage(content=\"In the context of high-dimensional problems, such as genomic or proteomic datasets with thousands of features, Ridge Regression is a regularization technique used to prevent overfitting and improve model generalizability.\\n\\nRidge Regression adds a penalty term to the least squares loss function, which is proportional to the magnitude of the regression coefficients. This penalty term, controlled by the regularization parameter λ, encourages the model to produce smaller coefficients for all features, thereby reducing the impact of noise and irrelevant variables on the model's performance.\\n\\nBy doing so, Ridge Regression:\\n\\n1. Reduces overfitting: By shrinking the coefficients towards zero, Ridge Regression prevents the model from memorizing the training data and generalizes better to new, unseen data.\\n2. Improves interpretability: The regularization parameter λ provides a more interpretable measure of the model's complexity than the number of features used.\\n3. Handles high-dimensional data: In high-dimensional spaces, Ridge Regression can be particularly effective in reducing the impact of irrelevant variables and improving model performance.\\n\\nThe choice of λ is crucial, as it controls the trade-off between fitting the training data and generalizing to new data. A small value of λ (e.g., 0.001) results in a model that is nearly equivalent to least squares regression, while larger values (e.g., 100 or 1000) lead to more regularization and potentially better generalization performance.\\n\\nIn the context of high-dimensional problems, Ridge Regression can be particularly useful when:\\n\\n* The number of features (p) exceeds the number of observations (N), making it difficult for traditional least squares regression to converge.\\n* Many features are irrelevant or noisy, which can negatively impact model performance.\\n\\nBy applying Ridge Regression in these scenarios, researchers and practitioners can develop more robust and generalizable models that better capture the underlying relationships between variables.\")]"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2['chat_history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "6ee3cbee-9548-47fd-ac6f-3621d4fca5e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='0bdfb511-497a-44a7-a808-15f7dc4cb02e', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 2, 'start_index': 397}, page_content='using the optimal ridge parameter in each of the three cases, the median\\nvalue of|tj|was 2.0, 0.6 and 0.2, and the average number of |tj|values\\nexceeding 2 was equal to 9.8, 1.2 and 0.0.\\nRidge regression with λ= 0.001 successfully exploits the correlation in\\nthe features when p<N, but cannot do so when p≫N. In the latter case\\nthere is not enough information in the relatively small numb er of samples\\nto eﬃciently estimate the high-dimensional covariance mat rix. In that case,'),\n",
       " Document(id='07cf95bb-ef63-4ba4-9514-02161fe5cccb', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 1, 'start_index': 760}, page_content='over the 100 simulation runs. The p= 1000 case is designed to mimic the\\nkind of data that we might see in a high-dimensional genomic o r proteomic\\ndataset, for example.\\nWe ﬁt a ridge regression to the data, with three diﬀerent valu es for the\\nregularization parameter λ: 0.001, 100, and 1000. When λ= 0.001, this\\nis nearly the same as least squares regression, with a little regularization\\njust to ensure that the problem is non-singular when p > N. Figure 18.1'),\n",
       " Document(id='8ae52bfa-978d-4d78-a0a1-460f3396239d', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 1, 'start_index': 368}, page_content='ofp, the number of features. The relative error is the test error d ivided by the\\nBayes error, σ2. From left to right, results are shown for ridge regression wit h\\nthree diﬀerent values of the regularization parameter λ:0.001,100and1000. The\\n(average) eﬀective degrees of freedom in the ﬁt is indicated below each plot.\\nvariate regression coeﬃcients1was 9, 33 and 331, respectively, averaged\\nover the 100 simulation runs. The p= 1000 case is designed to mimic the'),\n",
       " Document(id='985cd759-7665-47ad-8cd5-45255d6c4080', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 1, 'start_index': 1150}, page_content='just to ensure that the problem is non-singular when p > N. Figure 18.1\\nshows boxplots oftherelative testerrorachieved bythediﬀ erentestimators\\nin each scenario. The corresponding average degrees of free dom used in\\neach ridge-regression ﬁt is indicated (computed using form ula (3.50) on\\npage 682). The degrees of freedom is a more interpretable parameter t han\\nλ. We see that ridge regression with λ= 0.001 (20 df) wins when p= 20;\\nλ= 100 (35 df) wins when p= 100, and λ= 1000 (43 df) wins when'),\n",
       " Document(id='edd39061-5aef-4ef9-96f9-b698474a30c8', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 45, 'start_index': 405}, page_content='studies.\\nExercises\\nEx. 18.1 For a coeﬃcient estimate ˆβj, letˆβj/||ˆβj||2be the normalized ver-\\nsion. Show that as λ→∞, the normalized ridge-regression estimates con-\\nverge to the renormalized partial-least-squares one-comp onent estimates.\\nEx.18.2Nearest shrunken centroids and the lasso. Considera(naiveBayes)\\nGaussian model for classiﬁcation in which the features j= 1,2,...,pare\\nassumed to be independent within each class k= 1,2,...,K. With ob-'),\n",
       " Document(id='ae44aefa-6114-4af1-921e-20c04dfe717f', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 2, 'start_index': 800}, page_content='to eﬃciently estimate the high-dimensional covariance mat rix. In that case,\\nmore regularization leads to superior prediction performa nce.\\nThus it is not surprising that the analysis of high-dimensio nal data re-\\nquires either modiﬁcation of procedures designed for the N >pscenario, or\\nentirely new procedures. In this chapter we discuss example s of both kinds\\nofapproachesforhighdimensionalclassiﬁcationandregre ssion;thesemeth-')]"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "4d8ad041-2d2e-406f-8d1c-ed0f43a0d5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"**Ridge Regression in High-Dimensional Problems**\\n\\nIn high-dimensional problems, where the number of features (p) exceeds the number of observations (N), traditional least squares regression can struggle to converge. This is because the model needs to estimate a large number of coefficients, which can lead to overfitting and poor generalization performance.\\n\\nRidge Regression can be particularly effective in these scenarios by:\\n\\n1. **Reducing overfitting**: By shrinking the coefficients towards zero, Ridge Regression prevents the model from memorizing the training data and generalizes better to new, unseen data.\\n2. **Improving interpretability**: The regularization parameter λ provides a more interpretable measure of the model's complexity than the number of features used.\\n\\nHowever, for high-dimensional problems, Ridge Regression can only exploit the correlation in the features when:\\n\\n* **p < N**: When the number of features is less than or equal to the number of observations, Ridge Regression can effectively estimate the covariance matrix and capture the correlations between features.\\n* **λ = 0.001**: A small value of λ (e.g., 0.001) results in a model that is nearly equivalent to least squares regression, which allows Ridge Regression to exploit the correlation in the features.\\n\\nIn this case, Ridge Regression can successfully identify the relevant features and capture their correlations, leading to improved prediction performance.\\n\\n**When Ridge Regression Fails**\\n\\nHowever, when:\\n\\n* **p >> N**: When the number of features is much larger than the number of observations, Ridge Regression struggles to estimate the covariance matrix and capture the correlations between features.\\n* **λ > 0.001**: Larger values of λ (e.g., 100 or 1000) lead to more regularization, which can prevent Ridge Regression from exploiting the correlation in the features.\\n\\nIn these cases, Ridge Regression may not be able to effectively capture the correlations between features, and its performance may suffer as a result.\\n\\n**Example**\\n\\nThe text mentions that when p = 20, Ridge Regression with λ = 0.001 (20 df) wins; when p = 100, Ridge Regression with λ = 100 (35 df) wins; and when p = 1000, Ridge Regression with λ = 1000 (43 df) wins.\\n\\nThis suggests that as the number of features increases, a larger value of λ is needed to effectively capture the correlations between features. However, even in these cases, Ridge Regression may not be able to fully exploit the correlation in the features, and its performance may still suffer compared to other methods specifically designed for high-dimensional problems.\""
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2['answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66d0143-b113-46fc-b394-dd3ffcc58f6d",
   "metadata": {},
   "source": [
    "Note: this system is not stateful yet\n",
    "\n",
    "* Statefulness:\n",
    "Stateful typically refers to the system’s ability to persist data across sessions or restarts. In your current implementation, history is only preserved for the duration of the session (i.e., while the program is running). If you stop the program and restart it, the conversation history will be reset because the store is not persisted.\n",
    "* What is Missing:\n",
    "The missing part here is likely persistent memory, which would allow the system to retain conversation history even after a session or the program ends. This could be implemented using:\n",
    "    * A database to store conversation history (like SQLite, MongoDB, etc.).\n",
    "External memory integration, like LangChain’s memory modules that store history in more scalable, persistent ways.\n",
    "    * A file-based storage system (e.g., writing the history to a file that can be loaded again when needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "b512bee0-a8ca-4990-a20f-a2363e244638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for high-dimensional problems, with regards to p and N, in what cases can ridge regression exploit the correlation in the features of the dataset?'"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "8f9a0e39-5695-49b3-aa71-468d03d9b6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 2 of chap18.pdf\n",
      "content: using the optimal ridge parameter in each of the three cases, the median\n",
      "value of|tj|was 2.0, 0.6 and 0.2, and the average number of |tj|values\n",
      "exceeding 2 was equal to 9.8, 1.2 and 0.0.\n",
      "Ridge regression with λ= 0.001 successfully exploits the correlation in\n",
      "the features when p<N, but cannot do so when p≫N. In the latter case\n",
      "there is not enough information in the relatively small numb er of samples\n",
      "to eﬃciently estimate the high-dimensional covariance mat rix. In that case,\n",
      "\n",
      "page 1 of chap18.pdf\n",
      "content: over the 100 simulation runs. The p= 1000 case is designed to mimic the\n",
      "kind of data that we might see in a high-dimensional genomic o r proteomic\n",
      "dataset, for example.\n",
      "We ﬁt a ridge regression to the data, with three diﬀerent valu es for the\n",
      "regularization parameter λ: 0.001, 100, and 1000. When λ= 0.001, this\n",
      "is nearly the same as least squares regression, with a little regularization\n",
      "just to ensure that the problem is non-singular when p > N. Figure 18.1\n",
      "\n",
      "page 1 of chap18.pdf\n",
      "content: ofp, the number of features. The relative error is the test error d ivided by the\n",
      "Bayes error, σ2. From left to right, results are shown for ridge regression wit h\n",
      "three diﬀerent values of the regularization parameter λ:0.001,100and1000. The\n",
      "(average) eﬀective degrees of freedom in the ﬁt is indicated below each plot.\n",
      "variate regression coeﬃcients1was 9, 33 and 331, respectively, averaged\n",
      "over the 100 simulation runs. The p= 1000 case is designed to mimic the\n",
      "\n",
      "page 1 of chap18.pdf\n",
      "content: just to ensure that the problem is non-singular when p > N. Figure 18.1\n",
      "shows boxplots oftherelative testerrorachieved bythediﬀ erentestimators\n",
      "in each scenario. The corresponding average degrees of free dom used in\n",
      "each ridge-regression ﬁt is indicated (computed using form ula (3.50) on\n",
      "page 682). The degrees of freedom is a more interpretable parameter t han\n",
      "λ. We see that ridge regression with λ= 0.001 (20 df) wins when p= 20;\n",
      "λ= 100 (35 df) wins when p= 100, and λ= 1000 (43 df) wins when\n",
      "\n",
      "page 45 of chap18.pdf\n",
      "content: studies.\n",
      "Exercises\n",
      "Ex. 18.1 For a coeﬃcient estimate ˆβj, letˆβj/||ˆβj||2be the normalized ver-\n",
      "sion. Show that as λ→∞, the normalized ridge-regression estimates con-\n",
      "verge to the renormalized partial-least-squares one-comp onent estimates.\n",
      "Ex.18.2Nearest shrunken centroids and the lasso. Considera(naiveBayes)\n",
      "Gaussian model for classiﬁcation in which the features j= 1,2,...,pare\n",
      "assumed to be independent within each class k= 1,2,...,K. With ob-\n",
      "\n",
      "page 2 of chap18.pdf\n",
      "content: to eﬃciently estimate the high-dimensional covariance mat rix. In that case,\n",
      "more regularization leads to superior prediction performa nce.\n",
      "Thus it is not surprising that the analysis of high-dimensio nal data re-\n",
      "quires either modiﬁcation of procedures designed for the N >pscenario, or\n",
      "entirely new procedures. In this chapter we discuss example s of both kinds\n",
      "ofapproachesforhighdimensionalclassiﬁcationandregre ssion;thesemeth-\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for d in response2[\"context\"]:\n",
    "    print(f\"page {d.metadata['page']} of {d.metadata['source'].split('/')[-1]}\")\n",
    "    print(f\"content: {d.page_content}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "6e66c33a-a561-4401-9e4e-24a69fb9c217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jnvondsfvnidofs'"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=\"jnvondsfvnidofs\"\n",
    "p.split(\"--\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "da8611ce-af31-43f2-b2f5-e4ebb7d65eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableWithMessageHistory(bound=RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  chat_history: RunnableBinding(bound=RunnableLambda(_enter_history), config={'run_name': 'load_history'})\n",
       "}), config={'run_name': 'insert_history'})\n",
       "| RunnableBinding(bound=RunnableLambda(_call_runnable_sync), config={'run_name': 'check_sync_or_async'}), config={'run_name': 'RunnableWithMessageHistory'}), get_session_history=<function get_session_history at 0x3f76a9430>, input_messages_key='input', output_messages_key='answer', history_messages_key='chat_history', history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)])"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fa2935-bfd4-4195-8ee7-35713998747f",
   "metadata": {},
   "source": [
    "# python script setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea1bca5-c23d-404b-b2ee-b12fbc9b90ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "# from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "import warnings\n",
    "# from urllib3.exceptions import NotOpenSSLWarning\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Suppress NotOpenSSLWarning from urllib3\n",
    "warnings.filterwarnings(\"ignore\", module='urllib3')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_pdfs(file_paths):\n",
    "    \"\"\"\n",
    "    file_paths must end with .pdf\n",
    "    PyPDFLoader auto splits the pdf into pages, each page is 1 Document object split by page number\n",
    "\n",
    "    returns a dict of key: file_path and value: list of document objects\n",
    "    \"\"\"\n",
    "    documents_dict = {}   \n",
    "    for f in tqdm(file_paths):\n",
    "        loader = PyPDFLoader(file_path = f)\n",
    "        documents = loader.load()\n",
    "        documents_dict[f] = documents\n",
    "    return documents_dict\n",
    "\n",
    "def chunk_list_of_documents(documents):\n",
    "    \"\"\"\n",
    "    input a list of documents as Document objects\n",
    "\n",
    "    output a list of chunks as Document objects\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 500,\n",
    "        chunk_overlap = 100, # using 20% is a good start\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "        add_start_index=True\n",
    "    )\n",
    "\n",
    "    chunks = text_splitter.split_documents(documents)    \n",
    "    return chunks\n",
    "\n",
    "def get_session_history(session_id: str):\n",
    "    if session_id not in chat_history_store:\n",
    "        chat_history_store[session_id] = ChatMessageHistory()\n",
    "    return chat_history_store[session_id]\n",
    "\n",
    "\n",
    "def create_huggingface_retriever(folder_path,embedding_model_name):\n",
    "    files_paths = glob.glob(f\"{folder_path}/*.pdf\")\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "    # load documents from file paths\n",
    "    print(\"loading pdfs...\")\n",
    "    documents_dict = load_pdfs(file_paths=files_paths)\n",
    "\n",
    "    # chunk documents\n",
    "    print()\n",
    "    print(\"chunking documents...\")\n",
    "    all_chunks = []\n",
    "    for key in tqdm(documents_dict.keys()):\n",
    "        documents = documents_dict[key]\n",
    "        chunks = chunk_list_of_documents(documents=documents)\n",
    "        all_chunks.extend(chunks)\n",
    "    print(f\"number of chunks: {len(all_chunks)}\")\n",
    "\n",
    "    # setup embedding model\n",
    "    model_kwargs = {'device': 'cpu'}\n",
    "    encode_kwargs = {'normalize_embeddings': False}\n",
    "    hf_embedding_model = HuggingFaceEmbeddings(\n",
    "        model_name=embedding_model_name,\n",
    "        model_kwargs=model_kwargs,\n",
    "        encode_kwargs=encode_kwargs\n",
    "    )\n",
    "\n",
    "    # setup vectordb, using HF embedding model\n",
    "    start_time=time.time()\n",
    "    print()\n",
    "    print(\"start process of embedding chunks into vector database...\")\n",
    "    vectorstore_hf = InMemoryVectorStore.from_documents(\n",
    "        documents=all_chunks,\n",
    "        embedding=hf_embedding_model\n",
    "    )\n",
    "    print(\"all chunks embedded into vector database!\",f\"time taken: {round(time.time()-start_time,2)}s\")\n",
    "\n",
    "    # setup retrieval and test with a query and gt_context\n",
    "    retriever_hf = vectorstore_hf.as_retriever(\n",
    "        search_type='similarity',\n",
    "        search_kwargs = {'k':5}\n",
    "    )\n",
    "    print(\"retriever created!\")\n",
    "\n",
    "    return retriever_hf\n",
    "\n",
    "\n",
    "def create_conversational_rag_chain(retriever_hf,llm_model_name):\n",
    "\n",
    "    print(\"creating custom RAG Chat LLM...\")\n",
    "    # setup llm chat model using ollama\n",
    "    llm_model = ChatOllama(\n",
    "        model=llm_model_name,\n",
    "        temperature=0 # increase temp for more creative answers\n",
    "    ) \n",
    "\n",
    "    # setup system contextualise input prompt\n",
    "    system_contextualise_input_prompt = (\n",
    "        \"Given a chat history and the latest user question \"\n",
    "        \"which might reference context in the chat history, \"\n",
    "        \"formulate a standalone question which can be understood \"\n",
    "        \"without the chat history. Do NOT answer the question, \"\n",
    "        \"just reformulate it if needed and otherwise return it as is.\"\n",
    "    )\n",
    "    system_input_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_contextualise_input_prompt),\n",
    "            MessagesPlaceholder(\"chat_history\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # instantiate the history-aware retriever:\n",
    "    history_aware_retriever = create_history_aware_retriever(\n",
    "        llm=llm_model,\n",
    "        retriever=retriever_hf,\n",
    "        prompt=system_input_prompt\n",
    "    )\n",
    "\n",
    "    # setup system RAG QnA prompt\n",
    "    system_rag_qna_prompt = (\n",
    "        \"You are an assistant for question-answering tasks. \"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know. Use three sentences maximum and keep the \"\n",
    "        \"answer concise.\"\n",
    "        \"\\n\\n\"\n",
    "        \"{context}\"\n",
    "    )\n",
    "    system_rag_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            ('system',system_rag_qna_prompt),\n",
    "            MessagesPlaceholder(\"chat_history\"),\n",
    "            ('human',\"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # instantiate qna_chain\n",
    "    qna_chain = create_stuff_documents_chain(llm=llm_model,prompt=system_rag_prompt)\n",
    "\n",
    "    # instantiate rag_chain\n",
    "    rag_chain = create_retrieval_chain(retriever=history_aware_retriever,combine_docs_chain=qna_chain)\n",
    "\n",
    "    # create overall conversational RAG Chain\n",
    "    conversational_rag_chain = RunnableWithMessageHistory(\n",
    "        runnable=rag_chain,\n",
    "        get_session_history=get_session_history,\n",
    "        input_messages_key=\"input\",\n",
    "        history_messages_key=\"chat_history\",\n",
    "        output_messages_key=\"answer\"\n",
    "    )\n",
    "\n",
    "    print(\"RAG Chat LLM creation complete!\")\n",
    "    return conversational_rag_chain\n",
    "\n",
    "\n",
    "def main(folder_path,embedding_model_name,llm_model_name):\n",
    "    if embedding_model_name is None:\n",
    "        embedding_model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "    if llm_model_name is None:\n",
    "        llm_model_name = 'llama3.1'\n",
    "\n",
    "    # Create the Hugging Face retriever\n",
    "    retriever_hf = create_huggingface_retriever(folder_path=folder_path,embedding_model_name=embedding_model_name)\n",
    "    # Create the conversational RAG chain\n",
    "    conversational_rag_chain = create_conversational_rag_chain(retriever_hf=retriever_hf,llm_model_name=llm_model_name)\n",
    "\n",
    "    # Initialize the chat loop\n",
    "    print()\n",
    "    print()\n",
    "    print(\"You can now start chatting with the LLM.\")\n",
    "    print(\"Add '--show references' to the end of the input to view the retrieved context chunks referenced by the LLM for answer generation.\")\n",
    "    print(\"Type 'end session' to stop the conversation.\")\n",
    "\n",
    "    session_id = '1'  # Can be replaced with a unique session ID if needed\n",
    "\n",
    "    while True:\n",
    "        print()\n",
    "        print()\n",
    "        # Get user input\n",
    "        full_user_input = input(\"User input: \")\n",
    "\n",
    "        # Only take the first part of the user input if --show references is used\n",
    "        user_input = full_user_input.split(\"--\")[0]\n",
    "\n",
    "        # End session if user types 'end session'\n",
    "        if user_input.lower() == \"end session\":\n",
    "            print(\"Ending session. Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        # Invoke the conversational RAG chain with the user input\n",
    "        start_time = time.time()\n",
    "        response = conversational_rag_chain.invoke(\n",
    "            input={'input': user_input},\n",
    "            config={'configurable': {'session_id': session_id}}\n",
    "        )\n",
    "        \n",
    "        # Get the model's answer and print it\n",
    "        answer = response['answer']\n",
    "        print(f\"LLM Assistant: {answer}\")\n",
    "        print(f\"time taken: {round(time.time()-start_time,2)}s\")\n",
    "\n",
    "        # Show the references if user requests\n",
    "        if full_user_input.split(\"--\")[-1]==\"show references\":\n",
    "            print()\n",
    "            print(\"References:\")\n",
    "            for i,d in enumerate(response[\"context\"]):\n",
    "                print(f\"{i+1} From: page {d.metadata['page']} of {d.metadata['source'].split('/')[-1]}\")\n",
    "                print(f\"Content: {d.page_content}\")\n",
    "                print()\n",
    "\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    print()\n",
    "\n",
    "    parser = argparse.ArgumentParser(description=\"Directly use Conversational RAG with custom PDF documents in terminal.\")\n",
    "    # Add arguments\n",
    "    parser.add_argument(\"--folder_path\", type=str, help=\"input absolute folder path to folder of pdfs\", required=True)\n",
    "    parser.add_argument(\"--embedding_model_name\", type=str, help=\"pass the huggingface embedding model name of your choice\", required=False)\n",
    "    parser.add_argument(\"--llm_model_name\", type=str, help=\"pass the ollama llm model name of your choice\", required=False)\n",
    "\n",
    "    # Parse the arguments\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # create global variable for chat_history_store\n",
    "    chat_history_store = {}\n",
    "\n",
    "    # Run the main chat function \n",
    "    main(\n",
    "        folder_path=args.folder_path,\n",
    "        embedding_model_name=args.embedding_model_name,\n",
    "        llm_model_name=args.llm_model_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "51bc71d1-8d9f-496d-a63f-390ccce63cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky appears blue to us because of a phenomenon called Rayleigh scattering. Here's why:\n",
      "\n",
      "1. **Sunlight**: The sun emits white light, which contains all the colors of the visible spectrum (red, orange, yellow, green, blue, indigo, and violet).\n",
      "2. **Atmosphere**: When this sunlight enters Earth's atmosphere, it encounters tiny molecules of gases such as nitrogen (N2) and oxygen (O2). These molecules are much smaller than the wavelength of light.\n",
      "3. **Scattering**: The shorter wavelengths (like blue and violet) are scattered in all directions by these gas molecules. This is known as Rayleigh scattering. The longer wavelengths (like red and orange) pass through the atmosphere largely unchanged.\n",
      "4. **Visibility**: Since our eyes are more sensitive to blue light than other colors, we see the scattered blue light from all directions and perceive the sky as blue.\n",
      "\n",
      "It's worth noting that:\n",
      "\n",
      "* **Time of day**: During sunrise and sunset, the sky can take on hues of red and orange because the sun's rays have to travel through more of the atmosphere to reach us, scattering off more molecules and giving those longer wavelengths a chance to dominate our perception.\n",
      "* **Air pollution and dust**: In areas with high levels of air pollution or atmospheric particles, like dust, smoke, or water vapor, the blue color of the sky can be muted or even absent.\n",
      "\n",
      "Now you know why the sky is blue!\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model='llama3.1', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Why is the sky blue?',\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "ba0370e5-0de9-4a11-a1ea-a84152492214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky appears blue to us because of a phenomenon called scattering, which involves the interaction between sunlight and tiny molecules in the atmosphere.\n",
      "\n",
      "Here's a simplified explanation:\n",
      "\n",
      "1. **Sunlight enters Earth's atmosphere**: When the sun shines, it sends out all kinds of electromagnetic radiation, including visible light.\n",
      "2. **Molecules scatter shorter wavelengths**: As sunlight travels through the atmosphere, it encounters tiny molecules like nitrogen (N2) and oxygen (O2). These molecules are much smaller than the wavelength of light and have a similar size to the wavelength of blue and violet light. When this happens, they scatter these shorter-wavelength lights in all directions.\n",
      "3. **Blue light is scattered more**: Of all the colors in the visible spectrum, blue light has the shortest wavelength (around 450-495 nanometers). This means it gets scattered by the atmosphere's molecules more frequently than other colors, especially when compared to longer wavelengths like red and orange.\n",
      "4. **Our eyes see the scattered light**: When we look up at the sky on a sunny day, what we're seeing is actually the scattered blue light from the sun. Our eyes detect this blue light as it bounces around in all directions, giving us the impression that the sky is blue.\n",
      "\n",
      "This effect is most pronounced when the sun is overhead and directly shining down on us, like during the middle of the day. As the angle between the sun and our line of sight changes (e.g., during sunrise or sunset), the shorter wavelengths are scattered even more, and we see hues of red and orange instead!\n",
      "\n",
      "There you have it – a basic explanation for why the sky appears blue to us!\n"
     ]
    }
   ],
   "source": [
    "# import ollama\n",
    "\n",
    "response = ollama.chat(model='llama3.1', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Why is the sky blue?',\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "6a6b83d7-382c-43ff-9818-c7bf0b147dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky appears blue to us during the daytime because of a phenomenon called scattering. Scattering occurs when sunlight interacts with tiny molecules of gases in the Earth's atmosphere, such as nitrogen (N2) and oxygen (O2).\n",
      "\n",
      "Here's a simplified explanation:\n",
      "\n",
      "1. **Sunlight is made up of all colors**: When sunlight enters Earth's atmosphere, it contains all the colors of the visible spectrum, including red, orange, yellow, green, blue, indigo, and violet.\n",
      "\n",
      "2. **Scattering favored by shorter wavelengths**: The smaller molecules in the air scatter light more effectively when the light waves are shorter (i.e., have higher frequencies). Blue light has a relatively short wavelength compared to other colors of the visible spectrum.\n",
      "\n",
      "3. **Blue light is scattered more than others**: As sunlight travels through the atmosphere, the blue part of the spectrum gets scattered in all directions by the nitrogen and oxygen molecules. This scattering favors the shorter wavelengths of light, making it appear more intense and changing its apparent color from white (the original composition of sunlight) to blue.\n",
      "\n",
      "4. **Our eyes perceive the sky as blue**: The combined effect of sunlight being scattered in such a way that short wavelengths like blue become prominent makes the sky appear blue during the daytime when the sun is overhead. This is why the sky usually appears blue, though its hue can change at different times of day and under various atmospheric conditions.\n",
      "\n",
      "This phenomenon of scattering does not apply to all colors equally because shorter wavelengths (like blue light) are scattered more effectively than longer wavelengths (such as red light)."
     ]
    }
   ],
   "source": [
    "# import ollama\n",
    "\n",
    "stream = ollama.chat(\n",
    "    model='llama3.1',\n",
    "    messages=[{'role': 'user', 'content': 'Why is the sky blue?'}],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "  print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "c6ff4f76-1bab-4c1f-892f-83642f94fb13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky appears blue to us because of a phenomenon called scattering, which occurs when sunlight interacts with the tiny molecules of gases in the Earth's atmosphere. Here's a simplified explanation:\n",
      "\n",
      "1. **Sunlight enters the atmosphere**: When the sun shines, it sends out all its colors, including red, orange, yellow, green, and blue.\n",
      "2. **Scattering happens**: As these colors travel through the atmosphere, they encounter tiny molecules of gases such as nitrogen (N2) and oxygen (O2). These molecules are much smaller than the wavelength of light, so when they collide with each other, they scatter the light in all directions.\n",
      "3. **Blue light is scattered more**: The shorter wavelengths, like blue and violet, are scattered more easily than the longer wavelengths, like red and orange. This is because the smaller molecules have a greater effect on the shorter wavelengths.\n",
      "4. **Our eyes see the scattered blue light**: When we look up at the sky, our eyes see the scattered blue light that has been directed towards us from all parts of the atmosphere. The other colors, especially red and orange, are absorbed or scattered in different ways, so they don't reach our eyes as much.\n",
      "5. **The result: a blue sky**: The combination of scattering and our perception of the shorter wavelengths creates the appearance of a blue sky.\n",
      "\n",
      "It's worth noting that the exact shade of blue can vary depending on atmospheric conditions, such as:\n",
      "\n",
      "* Time of day: During sunrise and sunset, the light travels through more of the atmosphere, which scatters the shorter wavelengths even more, making the sky appear more red.\n",
      "* Atmospheric particles: Dust, water vapor, and pollutants in the air can also affect the color of the sky by scattering or absorbing light.\n",
      "* Altitude: At higher elevations, the air is thinner, and there are fewer molecules to scatter light, so the sky may appear lighter blue.\n",
      "\n",
      "Now, next time you gaze up at a bright blue sky, remember the tiny molecules of gases that made it happen!"
     ]
    }
   ],
   "source": [
    "# import ollama\n",
    "\n",
    "stream = ollama.chat(\n",
    "    model='llama3.1',\n",
    "    messages=[{'role': 'user', 'content': 'Why is the sky blue?'}],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "  print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "0b4daacf-c87f-420c-a409-9212b95dba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = \"sdvdf fvdfvdf vddfv --show references\"\n",
    "v = \"sdvdf fvdfvdf vddfv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "e24a7f2a-8f73-4a1c-a808-39e6c6c6d49a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(u.split(\"--\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "5565e0cc-534c-4290-b33c-326218f828da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(v.split(\"--\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "852f2293-9ca7-4023-a781-cede2fc69ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mtd 1 for instantiating chat ollama model - newer version\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# setup llm chat model using ollama\n",
    "llm_model1 = ChatOllama(\n",
    "    model=\"llama3.1\",\n",
    "    temperature=0 # increase temp for more creative answers\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "d0154395-cb93-4401-928d-fec57470a050",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm a large language model, I don't have real-time access to current weather conditions. However, I can suggest some ways for you to find out the weather today:\\n\\n1. **Check online weather websites**: You can visit websites like AccuWeather, Weather.com, or the National Weather Service (NWS) for up-to-date weather information.\\n2. **Use a voice assistant**: If you have a smart speaker or virtual assistant like Siri, Google Assistant, or Alexa, you can ask them to tell you the current weather.\\n3. **Check your phone's weather app**: Most smartphones come with a built-in weather app that provides current and forecasted weather conditions.\\n4. **Look out the window!**: If you're near a window, take a glance outside to see what the weather is like.\\n\\nIf you'd like, I can also suggest some general weather-related topics or questions we could chat about instead?\", response_metadata={'model': 'llama3.1', 'created_at': '2024-09-18T02:10:43.671768Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 7114817500, 'load_duration': 30152208, 'prompt_eval_count': 16, 'prompt_eval_duration': 167429000, 'eval_count': 187, 'eval_duration': 6916149000}, id='run-1dc30fe4-110e-4e5e-8137-b6032d21b123-0', usage_metadata={'input_tokens': 16, 'output_tokens': 187, 'total_tokens': 203})"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_model.invoke(\"whats the weather today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "ea951dfd-0f90-48fe-9a23-3866f2913687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mtd 2 for instantiating chat ollama model\n",
    "\n",
    "from langchain_community.chat_models.ollama import ChatOllama\n",
    "\n",
    "llm_model2 = ChatOllama(\n",
    "    model='llama3.1',\n",
    "    temperature=0,\n",
    "    disable_streaming=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "257ba033-3d8a-4477-9e9d-e56b1b6ead9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# response = await(llm_model.ainvoke(\"whats the weather today?\"))\n",
    "response = await(llm_model.abatch(\"whats the weather today?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "3fa67593-fe65-4e6b-92fc-3a67e32ee29e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# response = await(llm_model.ainvoke(\"whats the weather today?\"))\n",
    "response = llm_model.astream(\"whats the weather today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "9c4061ef-f9b3-4928-aeb3-0b4e83e8ad35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<async_generator object BaseChatModel.astream at 0x3f769fca0>"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "d18a528b-a3f3-44b1-ba0b-e34c1fb7ef72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm a large language model, I don't have real-time access to current weather conditions. However, I can suggest some ways for you to find out the weather today:\\n\\n1. **Check online weather websites**: You can visit websites like AccuWeather, Weather.com, or the National Weather Service (NWS) for up-to-date weather information.\\n2. **Use a voice assistant**: If you have a smart speaker or virtual assistant like Siri, Google Assistant, or Alexa, you can ask them to tell you the current weather.\\n3. **Check your phone's weather app**: Most smartphones come with a built-in weather app that provides current and forecasted weather conditions.\\n4. **Look out the window!**: If you're near a window, take a glance outside to see what the weather is like.\\n\\nIf you'd like, I can also suggest some general weather-related topics or questions we could chat about instead?\", response_metadata={'model': 'llama3.1', 'created_at': '2024-09-18T02:46:59.309123Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 7137924875, 'load_duration': 28208834, 'prompt_eval_count': 16, 'prompt_eval_duration': 198905000, 'eval_count': 187, 'eval_duration': 6909509000}, id='run-e53b9303-a210-43fd-b0a3-7060f0d54d38-0', usage_metadata={'input_tokens': 16, 'output_tokens': 187, 'total_tokens': 203})"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "9d6b1854-6625-4070-a1fc-dd9ec347ace8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableWithMessageHistory(bound=RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  chat_history: RunnableBinding(bound=RunnableLambda(_enter_history), config={'run_name': 'load_history'})\n",
       "}), config={'run_name': 'insert_history'})\n",
       "| RunnableBinding(bound=RunnableLambda(_call_runnable_sync), config={'run_name': 'check_sync_or_async'}), config={'run_name': 'RunnableWithMessageHistory'}), get_session_history=<function get_session_history at 0x3f76a9430>, input_messages_key='input', output_messages_key='answer', history_messages_key='chat_history', history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)])"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "838807a9-3e93-4e25-b1f6-58d75445f902",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"explain high dimensional problems in statistical learning?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "f66f09a0-2578-4b91-a2c0-3536a91ad2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputchat_historycontextanswer"
     ]
    }
   ],
   "source": [
    "# Use streaming to get the response incrementally\n",
    "response = conversational_rag_chain.invoke(\n",
    "    input={'input': user_input},\n",
    "    config={'stream': True,'configurable':{'session_id':'1'}}  # If config supports stream, add this\n",
    ")\n",
    "\n",
    "# Stream the response\n",
    "for token in response:\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "cb8c1b71-0ae0-4b1d-b0cb-57bd0e694aca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# response = await(llm_model.ainvoke(\"whats the weather today?\"))\n",
    "response = llm_model.ainvoke(\"whats the weather today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde3a586-7285-43cb-bfd1-2bd7f71245b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "a590492b-06cf-4186-9616-f47b9c8fac6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[485], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01masyncio\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/runners.py:33\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m coroutines\u001b[38;5;241m.\u001b[39miscoroutine(main):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma coroutine was expected, got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(main))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "asyncio.run(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60240fb6-e70a-40b1-9701-e979ffb94443",
   "metadata": {},
   "source": [
    "# try ollama python package directly with input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "37841cbc-69e8-46e2-a064-8562c3388e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for high-dimensional problems, with regards to p and N, in what cases can ridge regression exploit the correlation in the features of the dataset?'"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "cbdf8cb4-c7d4-4ff0-b6f2-11100c5ffd1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 2, 'start_index': 397}, page_content='using the optimal ridge parameter in each of the three cases, the median\\nvalue of|tj|was 2.0, 0.6 and 0.2, and the average number of |tj|values\\nexceeding 2 was equal to 9.8, 1.2 and 0.0.\\nRidge regression with λ= 0.001 successfully exploits the correlation in\\nthe features when p<N, but cannot do so when p≫N. In the latter case\\nthere is not enough information in the relatively small numb er of samples\\nto eﬃciently estimate the high-dimensional covariance mat rix. In that case,')"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_gt_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "b94b66e5-ded3-46de-9af2-79327c16e716",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history_store = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "7bbf993b-8ed1-4b95-9ff2-64c3891992f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='0bdfb511-497a-44a7-a808-15f7dc4cb02e', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 2, 'start_index': 397}, page_content='using the optimal ridge parameter in each of the three cases, the median\\nvalue of|tj|was 2.0, 0.6 and 0.2, and the average number of |tj|values\\nexceeding 2 was equal to 9.8, 1.2 and 0.0.\\nRidge regression with λ= 0.001 successfully exploits the correlation in\\nthe features when p<N, but cannot do so when p≫N. In the latter case\\nthere is not enough information in the relatively small numb er of samples\\nto eﬃciently estimate the high-dimensional covariance mat rix. In that case,'),\n",
       " Document(id='07cf95bb-ef63-4ba4-9514-02161fe5cccb', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 1, 'start_index': 760}, page_content='over the 100 simulation runs. The p= 1000 case is designed to mimic the\\nkind of data that we might see in a high-dimensional genomic o r proteomic\\ndataset, for example.\\nWe ﬁt a ridge regression to the data, with three diﬀerent valu es for the\\nregularization parameter λ: 0.001, 100, and 1000. When λ= 0.001, this\\nis nearly the same as least squares regression, with a little regularization\\njust to ensure that the problem is non-singular when p > N. Figure 18.1'),\n",
       " Document(id='985cd759-7665-47ad-8cd5-45255d6c4080', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 1, 'start_index': 1150}, page_content='just to ensure that the problem is non-singular when p > N. Figure 18.1\\nshows boxplots oftherelative testerrorachieved bythediﬀ erentestimators\\nin each scenario. The corresponding average degrees of free dom used in\\neach ridge-regression ﬁt is indicated (computed using form ula (3.50) on\\npage 682). The degrees of freedom is a more interpretable parameter t han\\nλ. We see that ridge regression with λ= 0.001 (20 df) wins when p= 20;\\nλ= 100 (35 df) wins when p= 100, and λ= 1000 (43 df) wins when'),\n",
       " Document(id='73ae4254-512b-40ff-8774-6ccf1a436ed4', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 10, 'start_index': 1944}, page_content='shown to equal\\nˆβ=V(RTR+λI)−1RTy (18.15)\\n(Exercise 18.4). Thus ˆβ=Vˆθ, where ˆθis the ridge-regression estimate\\nusing theNobservations ( ri,yi),i= 1,2,...,N. In other words, we can\\nsimply reduce the data matrix from XtoR, and work with the rows of\\nR. This trick reduces the computational cost from O(p3) toO(pN2) when\\np>N.'),\n",
       " Document(id='ae44aefa-6114-4af1-921e-20c04dfe717f', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 2, 'start_index': 800}, page_content='to eﬃciently estimate the high-dimensional covariance mat rix. In that case,\\nmore regularization leads to superior prediction performa nce.\\nThus it is not surprising that the analysis of high-dimensio nal data re-\\nquires either modiﬁcation of procedures designed for the N >pscenario, or\\nentirely new procedures. In this chapter we discuss example s of both kinds\\nofapproachesforhighdimensionalclassiﬁcationandregre ssion;thesemeth-'),\n",
       " Document(id='507f89a3-02fd-4334-9bd4-20bc4cbac8cd', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/elements-of-statistical-learning-book/chap18.pdf', 'page': 13, 'start_index': 1190}, page_content='variables; genes tend to operate in molecular pathways. The lasso penalty\\nis somewhat indiﬀerent to the choice among a set of strong but corre-\\nlated variables (Exercise 3.28). The ridge penalty, on the o ther hand, tends\\nto shrink the coeﬃcients of correlated variables toward eac h other (Exer-\\ncise 3.29 on page 99). The elastic net penalty (Zou and Hastie, 2005) is a\\ncompromise, and has the form\\np∑\\nj=1(\\nα|βj|+(1−α)β2\\nj)\\n. (18.20)')]"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_aware_retriever.invoke(\n",
    "    input={\n",
    "        'input':sample_query,\n",
    "        'chat_history':chat_history_store    \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "1d3bcbe1-d0f0-4916-8b12-19e56fcad3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky appears blue to us because of a phenomenon called scattering, which occurs when sunlight interacts with the tiny molecules of gases in the atmosphere. Here's a simplified explanation:\n",
      "\n",
      "1. **Sunlight**: The sun emits a broad spectrum of electromagnetic radiation, including visible light, ultraviolet (UV) rays, and other forms of energy.\n",
      "2. **Atmospheric particles**: The Earth's atmosphere is composed of various gases, such as nitrogen (N2), oxygen (O2), carbon dioxide (CO2), and others. These gases contain tiny molecules that are scattered throughout the air.\n",
      "3. **Scattering**: When sunlight enters the atmosphere, it encounters these tiny molecules. The shorter wavelengths of light, like blue and violet, are more easily scattered by these molecules than longer wavelengths, such as red and orange.\n",
      "4. **Rayleigh scattering**: This is the specific type of scattering that occurs when light interacts with small particles (like the atmospheric gases). It's named after Lord Rayleigh, who first described the phenomenon in the late 19th century.\n",
      "\n",
      "As a result of this scattering, the blue and violet light are dispersed throughout the atmosphere, making it appear blue to our eyes. This is why the sky typically appears blue during the daytime, when the sun is overhead.\n",
      "\n",
      "**What about other colors?**\n",
      "\n",
      "* During sunrise and sunset, the sky can take on hues of red, orange, and pink. This is because the sunlight has to travel through more of the Earth's atmosphere to reach our eyes at these times, scattering the shorter wavelengths (blue and violet) even more than usual.\n",
      "* At night, the sky appears dark blue or black, as there is no direct sunlight hitting the atmosphere.\n",
      "* When it's overcast or cloudy, the sky can take on a grayish hue due to the presence of water droplets in the air, which scatter light in all directions.\n",
      "\n",
      "In summary, the sky appears blue because of the scattering of sunlight by tiny molecules in the atmosphere, which favors shorter wavelengths like blue and violet."
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "stream = ollama.chat(\n",
    "    model='llama3.1',\n",
    "    messages=[{'role': 'user', 'content': 'Why is the sky blue?'}],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "  print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f61b36e-749c-4d5c-b900-b3c45b8b14df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1e842b-3232-4adb-ac72-6fa06cfbdf13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7723837a-8868-42f5-a19e-4d99a64db022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac6a6f0-cc33-44a0-98f6-cb4ee26d3029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b7fcd62-f2a3-455f-b521-4792ab825816",
   "metadata": {},
   "source": [
    "1. setup history aware retriever\n",
    "2. pass context to chat prompt\n",
    "3. use python ollama to generate response and append to chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "c6728623-b17c-43b3-8310-d75af23bd6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "53d3d96c-cc76-4b88-a1bf-b972f5be5a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_huggingface_retriever(folder_path,embedding_model_name):\n",
    "    files_paths = glob.glob(f\"{folder_path}/*.pdf\")\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "    # load documents from file paths\n",
    "    print(\"loading pdfs...\")\n",
    "    documents_dict = load_pdfs(file_paths=files_paths)\n",
    "\n",
    "    # chunk documents\n",
    "    print()\n",
    "    print(\"chunking documents...\")\n",
    "    all_chunks = []\n",
    "    for key in tqdm(documents_dict.keys()):\n",
    "        documents = documents_dict[key]\n",
    "        chunks = chunk_list_of_documents(documents=documents)\n",
    "        all_chunks.extend(chunks)\n",
    "    print(f\"number of chunks: {len(all_chunks)}\")\n",
    "\n",
    "    # setup embedding model\n",
    "    model_kwargs = {'device': 'cpu'}\n",
    "    encode_kwargs = {'normalize_embeddings': False}\n",
    "    hf_embedding_model = HuggingFaceEmbeddings(\n",
    "        model_name=embedding_model_name,\n",
    "        model_kwargs=model_kwargs,\n",
    "        encode_kwargs=encode_kwargs\n",
    "    )\n",
    "\n",
    "    # setup vectordb, using HF embedding model\n",
    "    start_time=time.time()\n",
    "    print()\n",
    "    print(\"start process of embedding chunks into vector database...\")\n",
    "    vectorstore_hf = InMemoryVectorStore.from_documents(\n",
    "        documents=all_chunks,\n",
    "        embedding=hf_embedding_model\n",
    "    )\n",
    "    print(\"all chunks embedded into vector database!\",f\"time taken: {round(time.time()-start_time,2)}s\")\n",
    "\n",
    "    # setup retrieval and test with a query and gt_context\n",
    "    retriever_hf = vectorstore_hf.as_retriever(\n",
    "        search_type='similarity',\n",
    "        search_kwargs = {'k':5}\n",
    "    )\n",
    "    print(\"retriever created!\")\n",
    "\n",
    "    return retriever_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "7fe1ab60-9bf3-4fb8-b01a-81d828ca09a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "loading pdfs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:05<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "chunking documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 443.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of chunks: 528\n",
      "\n",
      "start process of embedding chunks into vector database...\n",
      "all chunks embedded into vector database! time taken: 26.88s\n",
      "retriever created!\n"
     ]
    }
   ],
   "source": [
    "# setup history_aware_retriever\n",
    "\n",
    "folder_path = \"/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/short-elements-of-statistical-learning-book\"\n",
    "embedding_model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "retriever_hf = create_huggingface_retriever(folder_path,embedding_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "f6fde75d-a464-4a5d-8c75-2d257cac3b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "\n",
    "def instantiate_history_aware_retriever(llm_model_name):\n",
    "    \n",
    "    # setup llm model for refining the user input with conversation context\n",
    "    prompt_refiner_llm = ChatOllama(\n",
    "        model=llm_model_name,\n",
    "        temperature=0 # increase temp for more creative answers\n",
    "    ) \n",
    "    \n",
    "    # setup system contextualise input prompt\n",
    "    system_contextualise_input_prompt = (\n",
    "        \"Given a chat history and the latest user question \"\n",
    "        \"which might reference context in the chat history, \"\n",
    "        \"formulate a standalone question which can be understood \"\n",
    "        \"without the chat history. Do NOT answer the question, \"\n",
    "        \"just reformulate it if needed and otherwise return it as is.\"\n",
    "    )\n",
    "    system_input_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_contextualise_input_prompt),\n",
    "            MessagesPlaceholder(\"chat_history\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # instantiate the history-aware retriever:\n",
    "    history_aware_retriever = create_history_aware_retriever(\n",
    "        llm=prompt_refiner_llm,\n",
    "        retriever=retriever_hf,\n",
    "        prompt=system_input_prompt\n",
    "    )\n",
    "\n",
    "    return history_aware_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "530411d6-ae95-4e08-b6d4-066133cfe546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBranch(branches=[(RunnableLambda(lambda x: not x.get('chat_history', False)), RunnableLambda(lambda x: x['input'])\n",
       "| VectorStoreRetriever(tags=['InMemoryVectorStore', 'HuggingFaceEmbeddings'], vectorstore=<langchain_core.vectorstores.in_memory.InMemoryVectorStore object at 0x3f75caee0>, search_kwargs={'k': 5}))], default=ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Given a chat history and the latest user question which might reference context in the chat history, formulate a standalone question which can be understood without the chat history. Do NOT answer the question, just reformulate it if needed and otherwise return it as is.')), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])\n",
       "| ChatOllama(model='llama3.1', temperature=0.0)\n",
       "| StrOutputParser()\n",
       "| VectorStoreRetriever(tags=['InMemoryVectorStore', 'HuggingFaceEmbeddings'], vectorstore=<langchain_core.vectorstores.in_memory.InMemoryVectorStore object at 0x3f75caee0>, search_kwargs={'k': 5})), config={'run_name': 'chat_retriever_chain'})"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_aware_retriever = instantiate_history_aware_retriever(llm_model_name=\"llama3.1\")\n",
    "history_aware_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "43b5b80a-df31-417d-9a81-61471af3d242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in chat_history_store:\n",
    "        chat_history_store[session_id] = ChatMessageHistory()\n",
    "    return chat_history_store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "15c3ea52-c78f-41fc-a313-afa7224c3fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[])"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_id = \"1\"\n",
    "chat_history1 = get_session_history(session_id)\n",
    "chat_history1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "9cfa3274-ee02-4ef3-b681-1aad0f3fad64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[])"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "be9e0803-e0c6-4278-af27-ec862d25c54e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "variable chat_history should be a list of base messages, got  of type <class 'langchain_core.chat_history.InMemoryChatMessageHistory'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[569], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mhistory_aware_retriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43msample_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchat_history\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mchat_history1\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py:5093\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5087\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m   5088\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5089\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   5090\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   5091\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   5092\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 5093\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5094\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5095\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5096\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5097\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/branch.py:238\u001b[0m, in \u001b[0;36mRunnableBranch.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 238\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbranch:default\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    246\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py:2877\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2875\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m   2876\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2877\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2878\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2879\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/prompts/base.py:187\u001b[0m, in \u001b[0;36mBasePromptTemplate.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags:\n\u001b[1;32m    186\u001b[0m     config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags\n\u001b[0;32m--> 187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_prompt_with_error_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserialized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdumpd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py:1786\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1783\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m   1784\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1785\u001b[0m         Output,\n\u001b[0;32m-> 1786\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1787\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1788\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1789\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1792\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1794\u001b[0m     )\n\u001b[1;32m   1795\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1796\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/config.py:398\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    397\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/prompts/base.py:162\u001b[0m, in \u001b[0;36mBasePromptTemplate._format_prompt_with_error_handling\u001b[0;34m(self, inner_input)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_format_prompt_with_error_handling\u001b[39m(\u001b[38;5;28mself\u001b[39m, inner_input: Dict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PromptValue:\n\u001b[1;32m    161\u001b[0m     _inner_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_input(inner_input)\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_inner_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/prompts/chat.py:765\u001b[0m, in \u001b[0;36mBaseChatPromptTemplate.format_prompt\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_prompt\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PromptValue:\n\u001b[1;32m    757\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format prompt. Should return a PromptValue.\u001b[39;00m\n\u001b[1;32m    758\u001b[0m \n\u001b[1;32m    759\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;124;03m        PromptValue.\u001b[39;00m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 765\u001b[0m     messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatPromptValue(messages\u001b[38;5;241m=\u001b[39mmessages)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/prompts/chat.py:1207\u001b[0m, in \u001b[0;36mChatPromptTemplate.format_messages\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1203\u001b[0m     result\u001b[38;5;241m.\u001b[39mextend([message_template])\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   1205\u001b[0m     message_template, (BaseMessagePromptTemplate, BaseChatPromptTemplate)\n\u001b[1;32m   1206\u001b[0m ):\n\u001b[0;32m-> 1207\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[43mmessage_template\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1208\u001b[0m     result\u001b[38;5;241m.\u001b[39mextend(message)\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/prompts/chat.py:231\u001b[0m, in \u001b[0;36mMessagesPlaceholder.format_messages\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    226\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariable_name, [])\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptional\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m kwargs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariable_name]\n\u001b[1;32m    229\u001b[0m )\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m should be a list of base messages, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    234\u001b[0m     )\n\u001b[1;32m    235\u001b[0m value \u001b[38;5;241m=\u001b[39m convert_to_messages(value)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_messages:\n",
      "\u001b[0;31mValueError\u001b[0m: variable chat_history should be a list of base messages, got  of type <class 'langchain_core.chat_history.InMemoryChatMessageHistory'>"
     ]
    }
   ],
   "source": [
    "history_aware_retriever.invoke(\n",
    "    input = {\n",
    "        'input':sample_query,\n",
    "        'chat_history':chat_history1\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22af5dfa-44a6-4c55-82fa-3cb23ad422ec",
   "metadata": {},
   "source": [
    "# without using alot of the langchain stuff\n",
    "\n",
    "* without using history_aware_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "id": "6c2c0149-76f5-4173-9a87-c556735289ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "id": "a68c8923-3bfa-4251-ae31-56d1869ab755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. setup conversation history\n",
    "\n",
    "chat_history_store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "id": "d9df8735-da38-479b-836a-85e27fe303a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[])"
      ]
     },
     "execution_count": 777,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_id = \"2\"\n",
    "current_chat_history = get_session_history(session_id)\n",
    "current_chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "id": "abc07e54-c86e-4738-be43-92303555d67b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content='hi do you know what pythagoras theorem is? just say yes or no'), AIMessage(content='Yes. What would you like to know about it?')])"
      ]
     },
     "execution_count": 779,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add some messages\n",
    "\n",
    "current_chat_history.add_user_message(\"hi do you know what pythagoras theorem is? just say yes or no\")\n",
    "current_chat_history.add_ai_message(\"Yes. What would you like to know about it?\")\n",
    "current_chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "id": "3d72c481-65cb-4bae-b0b4-04ba920d90ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content='hi do you know what pythagoras theorem is? just say yes or no'), AIMessage(content='Yes. What would you like to know about it?')])"
      ]
     },
     "execution_count": 787,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_session_history(\"2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc025f9-afdd-441e-99ab-3a02cd66180c",
   "metadata": {},
   "source": [
    "history_aware_retriever\n",
    "\n",
    "* Create a chain that takes conversation history and returns documents.\n",
    "* If there is no chat_history, then the input is just passed directly to the retriever. If there is chat_history, then the prompt and LLM will be used to generate a search query. That search query is then passed to the retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "id": "c8d69d39-1a5a-4df1-b3a2-aa314871ce9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup llm model for refining the user input with conversation context\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "query_refiner_llm_model_name = \"llama3.1\"\n",
    "query_refiner_llm = ChatOllama(\n",
    "    model=query_refiner_llm_model_name,\n",
    "    temperature=0 # increase temp for more creative answers\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "id": "6179ac94-cc43-45a4-903f-e7c2a90e4e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"How's it going? Is there something I can help you with or would you like to chat?\", response_metadata={'model': 'llama3.1', 'created_at': '2024-09-18T05:46:38.621339Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 1068434333, 'load_duration': 28997833, 'prompt_eval_count': 11, 'prompt_eval_duration': 310055000, 'eval_count': 21, 'eval_duration': 728042000}, id='run-917dec4c-7b87-4d65-a426-54d0ae073f47-0', usage_metadata={'input_tokens': 11, 'output_tokens': 21, 'total_tokens': 32})"
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "query_refiner_llm.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "id": "2feafdcf-ec5c-451b-8581-703803cf6533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content='hi do you know what pythagoras theorem is? just say yes or no'), AIMessage(content='Yes. What would you like to know about it?')])"
      ]
     },
     "execution_count": 748,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "id": "9dd5d5f3-4afb-4d38-8162-0fa8990147b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_input_query_with_chat_history_context(session_id, input_query, query_refiner_llm):\n",
    "    \"\"\"\n",
    "    session_id is tyope str - the sessions_id of the chat history\n",
    "    input_query is type str - input in the terminal by the user\n",
    "    query_refiner_llm is a base chat LLM used to refine the input query with context of the chat history\n",
    "    \"\"\"\n",
    "    chat_history = get_session_history(session_id)\n",
    "\n",
    "    # Setup system contextualise input prompt\n",
    "    system_contextualize_input_prompt = (\n",
    "        \"Given a chat history and the latest user question \"\n",
    "        \"which might reference context in the chat history, \"\n",
    "        \"formulate a standalone question which can be understood \"\n",
    "        \"without the chat history. Do NOT answer the question, \"\n",
    "        \"just reformulate it if needed and otherwise return it as is.\"\n",
    "    )\n",
    "    \n",
    "    # Prepare the chat prompt template with the chat history\n",
    "    system_input_prompt_template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_contextualize_input_prompt),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),  # For history\n",
    "            (\"human\", \"{input}\"),  # User's latest input query\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Format the chat history as a list of dictionaries (required for MessagesPlaceholder)\n",
    "    formatted_chat_history = []\n",
    "    for message in chat_history.messages:\n",
    "        if isinstance(message, HumanMessage):\n",
    "            formatted_chat_history.append({\"role\": \"human\", \"content\": message.content})\n",
    "        elif isinstance(message, AIMessage):\n",
    "            formatted_chat_history.append({\"role\": \"ai\", \"content\": message.content})\n",
    "\n",
    "    # Invoke the template with chat history and input query\n",
    "    system_input_prompt_value = system_input_prompt_template.invoke(\n",
    "        {\n",
    "            'chat_history': formatted_chat_history,  # Pass the formatted history\n",
    "            'input': input_query  # User's current query\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(\"chat history:\")\n",
    "    print(system_input_prompt_value.messages)\n",
    "    \n",
    "    # Use the query_refiner_llm to get the refined_query\n",
    "    refined_query = query_refiner_llm.invoke(\n",
    "        input = system_input_prompt_value.messages\n",
    "    )\n",
    "    \n",
    "    return refined_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "id": "d4babbe8-1be0-48e6-a9c3-726e3894789a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat history:\n",
      "[SystemMessage(content='Given a chat history and the latest user question which might reference context in the chat history, formulate a standalone question which can be understood without the chat history. Do NOT answer the question, just reformulate it if needed and otherwise return it as is.'), HumanMessage(content='hi do you know what pythagoras theorem is? just say yes or no'), AIMessage(content='Yes. What would you like to know about it?'), HumanMessage(content='okay explain it.')]\n"
     ]
    }
   ],
   "source": [
    "refined_query =  refine_input_query_with_chat_history_context(\n",
    "    session_id='2',\n",
    "    input_query=\"okay explain it.\",\n",
    "    query_refiner_llm=query_refiner_llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "id": "5e8d93dd-ce68-4afd-bc6f-e43e4749b83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Given a chat history and the latest user question which might reference context in the chat history, formulate a standalone question which can be understood without the chat history. Do NOT answer the question, just reformulate it if needed and otherwise return it as is.'),\n",
       " HumanMessage(content='hi do you know what pythagoras theorem is? just say yes or no'),\n",
       " AIMessage(content='Yes. What would you like to know about it?'),\n",
       " HumanMessage(content='okay explain it.')]"
      ]
     },
     "execution_count": 756,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_input_prompt_value.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "id": "99f5b35a-cdfd-4120-98fb-84df0c70b75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Pythagorean Theorem states that in a right-angled triangle, the square of the length of the hypotenuse (the side opposite the right angle) is equal to the sum of the squares of the lengths of the other two sides.\\n\\nMathematically, this can be expressed as:\\n\\na² + b² = c²\\n\\nwhere 'a' and 'b' are the lengths of the two shorter sides, and 'c' is the length of the hypotenuse.\""
      ]
     },
     "execution_count": 762,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refined_query.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc7c2e1-ebfb-442c-8d97-5334f7db8ed7",
   "metadata": {},
   "source": [
    "issue here is that the refined_query_llm is not returning the refined query but directly answering the question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9210febd-f13e-4e8d-8d89-6acc2a2d755b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## others "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739ab857-5a70-4843-938d-82565546b76e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "5e7cb332-24e7-4d03-ab9c-3efbb1326448",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_chat_history.add_user_message(\"hi can you explain pythagoras theorem to me?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "c2f3116d-bc28-4c7c-b7eb-e90884490610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content='hi can you explain pythagoras theorem to me?')])"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "63268123-2258-478b-80e7-26c76232f83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_chat_history.add_ai_message(\"i cant find information on that in the vector db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "bb90d919-6c7c-4977-8843-ccaac75e0269",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi can you explain pythagoras theorem to me?'),\n",
       " AIMessage(content='i cant find information on that in the vector db')]"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_chat_history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d070c087-06bc-4118-b554-18ea14f03aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562bffb8-4edc-41bc-b24f-173653cb415a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "dc1bd72d-76fc-43f7-8d6c-f5c2f8ffe683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import AIMessage, HumanMessage\n",
    "\n",
    "def refine_query_with_context(input_query, session_id, query_refiner_llm):\n",
    "    \"\"\"\n",
    "    Refines the input query by considering the chat history.\n",
    "    \"\"\"\n",
    "    # Get the chat history for the session (assume you have a function to fetch it)\n",
    "    chat_history = get_session_history(session_id)\n",
    "\n",
    "    # Setup system contextualize input prompt\n",
    "    system_contextualize_input_prompt = (\n",
    "        \"Given a chat history and the latest user question \"\n",
    "        \"which might reference context in the chat history, \"\n",
    "        \"formulate a standalone question which can be understood \"\n",
    "        \"without the chat history. Do NOT answer the question, \"\n",
    "        \"just reformulate it if needed and otherwise return it as is.\"\n",
    "    )\n",
    "\n",
    "    # Prepare the chat prompt template with the chat history\n",
    "    system_input_prompt_template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_contextualize_input_prompt),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),  # For history\n",
    "            (\"human\", \"{input}\"),  # User's latest input\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Format the chat history as a list of dictionaries (required for MessagesPlaceholder)\n",
    "    formatted_history = []\n",
    "    for message in chat_history.messages:\n",
    "        if isinstance(message, HumanMessage):\n",
    "            formatted_history.append({\"role\": \"human\", \"content\": message.content})\n",
    "        elif isinstance(message, AIMessage):\n",
    "            formatted_history.append({\"role\": \"ai\", \"content\": message.content})\n",
    "\n",
    "    # Invoke the template with chat history and input query\n",
    "    refined_query = system_input_prompt_template.invoke(\n",
    "        {\n",
    "            'chat_history': formatted_history,  # Pass the formatted history\n",
    "            'input': input_query  # User's current query\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return refined_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "f8c6d017-f23c-48cd-8cc3-3e82e3592bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_query = refine_query_with_context(input_query=sample_query,session_id='1',query_refiner_llm=query_refiner_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "170cd807-2132-4108-9ad0-4a851b5f8f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Given a chat history and the latest user question which might reference context in the chat history, formulate a standalone question which can be understood without the chat history. Do NOT answer the question, just reformulate it if needed and otherwise return it as is.'),\n",
       " HumanMessage(content='hi can you explain pythagoras theorem to me?'),\n",
       " AIMessage(content='i cant find information on that in the vector db'),\n",
       " HumanMessage(content='for high-dimensional problems, with regards to p and N, in what cases can ridge regression exploit the correlation in the features of the dataset?')]"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refined_query.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "id": "f14b52e0-d395-4f66-9280-1df676e142db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What is Ridge Regression's ability to exploit feature correlations in high-dimensional spaces when considering p (number of features) and N (sample size)?\""
      ]
     },
     "execution_count": 704,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = query_refiner_llm.invoke(input=refined_query)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ae3044-caec-4bcc-8202-0b00c9c02328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deca48a6-5d67-4f81-918c-05fd69d0d62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_refiner_llm.invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "3616c639-489f-4417-95d3-f4df655d5904",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "variable chat_history should be a list of base messages, got Human: hi can you explain pythagoras theorem to me?\nAI: i cant find information on that in the vector db of type <class 'langchain_core.chat_history.InMemoryChatMessageHistory'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[681], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m system_input_prompt_temmplate \u001b[38;5;241m=\u001b[39m \u001b[43mrefine_query_with_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43msession_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mquery_refiner_llm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_refiner_llm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m system_input_prompt_temmplate\n",
      "Cell \u001b[0;32mIn[679], line 24\u001b[0m, in \u001b[0;36mrefine_query_with_context\u001b[0;34m(input_query, session_id, query_refiner_llm)\u001b[0m\n\u001b[1;32m      8\u001b[0m system_contextualise_input_prompt \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGiven a chat history and the latest user question \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhich might reference context in the chat history, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjust reformulate it if needed and otherwise return it as is.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m system_input_prompt_temmplate \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_messages(\n\u001b[1;32m     16\u001b[0m     [\n\u001b[1;32m     17\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, system_contextualise_input_prompt),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     ]\n\u001b[1;32m     22\u001b[0m )\n\u001b[0;32m---> 24\u001b[0m system_input_prompt \u001b[38;5;241m=\u001b[39m \u001b[43msystem_input_prompt_temmplate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchat_history\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mchat_history\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43minput_query\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m system_input_prompt_temmplate\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/prompts/base.py:187\u001b[0m, in \u001b[0;36mBasePromptTemplate.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags:\n\u001b[1;32m    186\u001b[0m     config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags\n\u001b[0;32m--> 187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_prompt_with_error_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserialized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdumpd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/base.py:1786\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1783\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m   1784\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1785\u001b[0m         Output,\n\u001b[0;32m-> 1786\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1787\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1788\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1789\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1792\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1794\u001b[0m     )\n\u001b[1;32m   1795\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1796\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/runnables/config.py:398\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    397\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/prompts/base.py:162\u001b[0m, in \u001b[0;36mBasePromptTemplate._format_prompt_with_error_handling\u001b[0;34m(self, inner_input)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_format_prompt_with_error_handling\u001b[39m(\u001b[38;5;28mself\u001b[39m, inner_input: Dict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PromptValue:\n\u001b[1;32m    161\u001b[0m     _inner_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_input(inner_input)\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_inner_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/prompts/chat.py:765\u001b[0m, in \u001b[0;36mBaseChatPromptTemplate.format_prompt\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_prompt\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PromptValue:\n\u001b[1;32m    757\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format prompt. Should return a PromptValue.\u001b[39;00m\n\u001b[1;32m    758\u001b[0m \n\u001b[1;32m    759\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;124;03m        PromptValue.\u001b[39;00m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 765\u001b[0m     messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatPromptValue(messages\u001b[38;5;241m=\u001b[39mmessages)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/prompts/chat.py:1207\u001b[0m, in \u001b[0;36mChatPromptTemplate.format_messages\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1203\u001b[0m     result\u001b[38;5;241m.\u001b[39mextend([message_template])\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   1205\u001b[0m     message_template, (BaseMessagePromptTemplate, BaseChatPromptTemplate)\n\u001b[1;32m   1206\u001b[0m ):\n\u001b[0;32m-> 1207\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[43mmessage_template\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1208\u001b[0m     result\u001b[38;5;241m.\u001b[39mextend(message)\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/prompts/chat.py:231\u001b[0m, in \u001b[0;36mMessagesPlaceholder.format_messages\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    226\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariable_name, [])\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptional\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m kwargs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariable_name]\n\u001b[1;32m    229\u001b[0m )\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m should be a list of base messages, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    234\u001b[0m     )\n\u001b[1;32m    235\u001b[0m value \u001b[38;5;241m=\u001b[39m convert_to_messages(value)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_messages:\n",
      "\u001b[0;31mValueError\u001b[0m: variable chat_history should be a list of base messages, got Human: hi can you explain pythagoras theorem to me?\nAI: i cant find information on that in the vector db of type <class 'langchain_core.chat_history.InMemoryChatMessageHistory'>"
     ]
    }
   ],
   "source": [
    "system_input_prompt_temmplate = refine_query_with_context(input_query=sample_query,session_id='1',query_refiner_llm=query_refiner_llm)\n",
    "system_input_prompt_temmplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc543c2-d720-4f6d-adb6-ce69d789b39f",
   "metadata": {},
   "source": [
    "build entire pipeline in order without langchain as much as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5bd984-fe11-4546-9e6b-9b13bd513a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "    # setup llm model for refining the user input with conversation context\n",
    "    prompt_refiner_llm = ChatOllama(\n",
    "        model=llm_model_name,\n",
    "        temperature=0 # increase temp for more creative answers\n",
    "    ) \n",
    "    \n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You're an assistant who's good at {ability}. Respond in 20 words or fewer\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "runnable = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "8f72ca12-8e2e-4d91-a750-b43de69d9679",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'runnable' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[571], line 15\u001b[0m\n\u001b[1;32m     10\u001b[0m         store[session_id] \u001b[38;5;241m=\u001b[39m ChatMessageHistory()\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m store[session_id]\n\u001b[1;32m     14\u001b[0m with_message_history \u001b[38;5;241m=\u001b[39m RunnableWithMessageHistory(\n\u001b[0;32m---> 15\u001b[0m     \u001b[43mrunnable\u001b[49m,\n\u001b[1;32m     16\u001b[0m     get_session_history,\n\u001b[1;32m     17\u001b[0m     input_messages_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m     history_messages_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'runnable' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    runnable,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a06208-0ebc-4716-a985-39152fa7f569",
   "metadata": {},
   "source": [
    "# use history aware retriever -> Python Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "id": "1eb9cf56-94ac-4eaa-973c-15333f90d886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "# from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "import warnings\n",
    "# from urllib3.exceptions import NotOpenSSLWarning\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Suppress NotOpenSSLWarning from urllib3\n",
    "warnings.filterwarnings(\"ignore\", module='urllib3')\n",
    "\n",
    "def load_pdfs(file_paths):\n",
    "    \"\"\"\n",
    "    file_paths must end with .pdf\n",
    "    PyPDFLoader auto splits the pdf into pages, each page is 1 Document object split by page number\n",
    "\n",
    "    returns a dict of key: file_path and value: list of document objects\n",
    "    \"\"\"\n",
    "    documents_dict = {}   \n",
    "    for f in tqdm(file_paths):\n",
    "        loader = PyPDFLoader(file_path = f)\n",
    "        documents = loader.load()\n",
    "        documents_dict[f] = documents\n",
    "    return documents_dict\n",
    "\n",
    "def chunk_list_of_documents(documents):\n",
    "    \"\"\"\n",
    "    input a list of documents as Document objects\n",
    "\n",
    "    output a list of chunks as Document objects\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 500,\n",
    "        chunk_overlap = 100, # using 20% is a good start\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "        add_start_index=True\n",
    "    )\n",
    "\n",
    "    chunks = text_splitter.split_documents(documents)    \n",
    "    return chunks\n",
    "\n",
    "def get_session_history(session_id: str):\n",
    "    if session_id not in chat_history_store:\n",
    "        chat_history_store[session_id] = ChatMessageHistory()\n",
    "    return chat_history_store[session_id]\n",
    "\n",
    "\n",
    "def create_huggingface_retriever(folder_path,embedding_model_name):\n",
    "    files_paths = glob.glob(f\"{folder_path}/*.pdf\")\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "    # load documents from file paths\n",
    "    print(\"loading pdfs...\")\n",
    "    documents_dict = load_pdfs(file_paths=files_paths)\n",
    "\n",
    "    # chunk documents\n",
    "    print()\n",
    "    print(\"chunking documents...\")\n",
    "    all_chunks = []\n",
    "    for key in tqdm(documents_dict.keys()):\n",
    "        documents = documents_dict[key]\n",
    "        chunks = chunk_list_of_documents(documents=documents)\n",
    "        all_chunks.extend(chunks)\n",
    "    print(f\"number of chunks: {len(all_chunks)}\")\n",
    "\n",
    "    # setup embedding model\n",
    "    model_kwargs = {'device': 'cpu'}\n",
    "    encode_kwargs = {'normalize_embeddings': False}\n",
    "    hf_embedding_model = HuggingFaceEmbeddings(\n",
    "        model_name=embedding_model_name,\n",
    "        model_kwargs=model_kwargs,\n",
    "        encode_kwargs=encode_kwargs\n",
    "    )\n",
    "\n",
    "    # setup vectordb, using HF embedding model\n",
    "    start_time=time.time()\n",
    "    print()\n",
    "    print(\"start process of embedding chunks into vector database...\")\n",
    "    vectorstore_hf = InMemoryVectorStore.from_documents(\n",
    "        documents=all_chunks,\n",
    "        embedding=hf_embedding_model\n",
    "    )\n",
    "    print(\"all chunks embedded into vector database!\",f\"time taken: {round(time.time()-start_time,2)}s\")\n",
    "\n",
    "    # setup retrieval and test with a query and gt_context\n",
    "    retriever_hf = vectorstore_hf.as_retriever(\n",
    "        search_type='similarity',\n",
    "        search_kwargs = {'k':5}\n",
    "    )\n",
    "    print(\"retriever created!\")\n",
    "\n",
    "    return retriever_hf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "id": "5d31d697-8803-4929-8b1d-62b868879bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_history_aware_retriever(retriever_hf,llm_model_name):\n",
    "\n",
    "    # setup llm chat model using ollama\n",
    "    llm_model = ChatOllama(\n",
    "        model=llm_model_name,\n",
    "        temperature=0 # increase temp for more creative answers\n",
    "    ) \n",
    "\n",
    "    # setup system contextualise input prompt\n",
    "    system_contextualise_input_prompt = (\n",
    "        \"Given a chat history and the latest user question \"\n",
    "        \"which might reference context in the chat history, \"\n",
    "        \"formulate a standalone question which can be understood \"\n",
    "        \"without the chat history. Do NOT answer the question, \"\n",
    "        \"just reformulate it if needed and otherwise return it as is.\"\n",
    "    )\n",
    "    system_input_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_contextualise_input_prompt),\n",
    "            MessagesPlaceholder(\"chat_history\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # instantiate the history-aware retriever:\n",
    "    history_aware_retriever = create_history_aware_retriever(\n",
    "        llm=llm_model,\n",
    "        retriever=retriever_hf,\n",
    "        prompt=system_input_prompt\n",
    "    )\n",
    "\n",
    "    return history_aware_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeb5825-e259-459a-8ad6-67c7ad9f95d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_hf = create_huggingface_retriever(folder_path,embedding_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "id": "5683f7ab-32df-41a3-8bb4-c40652cf7532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['InMemoryVectorStore', 'HuggingFaceEmbeddings'], vectorstore=<langchain_core.vectorstores.in_memory.InMemoryVectorStore object at 0x3f75caee0>, search_kwargs={'k': 5})"
      ]
     },
     "execution_count": 771,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "id": "54817c4e-4872-4f21-9a47-a640956b0f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBranch(branches=[(RunnableLambda(lambda x: not x.get('chat_history', False)), RunnableLambda(lambda x: x['input'])\n",
       "| VectorStoreRetriever(tags=['InMemoryVectorStore', 'HuggingFaceEmbeddings'], vectorstore=<langchain_core.vectorstores.in_memory.InMemoryVectorStore object at 0x3f75caee0>, search_kwargs={'k': 5}))], default=ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Given a chat history and the latest user question which might reference context in the chat history, formulate a standalone question which can be understood without the chat history. Do NOT answer the question, just reformulate it if needed and otherwise return it as is.')), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])\n",
       "| ChatOllama(model='llama3.1', temperature=0.0, _client=<ollama._client.Client object at 0x42fcae040>, _async_client=<ollama._client.AsyncClient object at 0x42fcae220>)\n",
       "| StrOutputParser()\n",
       "| VectorStoreRetriever(tags=['InMemoryVectorStore', 'HuggingFaceEmbeddings'], vectorstore=<langchain_core.vectorstores.in_memory.InMemoryVectorStore object at 0x3f75caee0>, search_kwargs={'k': 5})), config={'run_name': 'chat_retriever_chain'})"
      ]
     },
     "execution_count": 773,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_aware_retriever = instantiate_history_aware_retriever(retriever_hf,\"llama3.1\")\n",
    "history_aware_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "id": "0fa4169c-c9d4-4b74-bf83-5b224b1e9574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for high-dimensional problems, with regards to p and N, in what cases can ridge regression exploit the correlation in the features of the dataset?'"
      ]
     },
     "execution_count": 791,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "id": "1530024b-7263-40bf-8028-a12df00467c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[])"
      ]
     },
     "execution_count": 797,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new session history\n",
    "\n",
    "current_chat_history = get_session_history(\"3\")\n",
    "current_chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "id": "6ca720a3-a508-4a2b-aa50-37e455ddb683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content='hi do you know about ridge regression being used to exploit the correlation in the features of a dataset?'), AIMessage(content='Yes. What would you like to know about it?')])"
      ]
     },
     "execution_count": 799,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add some messages\n",
    "\n",
    "current_chat_history.add_user_message(\"hi do you know about ridge regression being used to exploit the correlation in the features of a dataset?\")\n",
    "current_chat_history.add_ai_message(\"Yes. What would you like to know about it?\")\n",
    "current_chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "id": "4628d4fe-87d8-450a-b70b-180d409c2378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content='hi do you know about ridge regression being used to exploit the correlation in the features of a dataset?'), AIMessage(content='Yes. What would you like to know about it?')])"
      ]
     },
     "execution_count": 821,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_session_history(\"3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "id": "e6ff815a-d265-4bd8-ad64-bde376b1e9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_chat_history(chat_history):\n",
    "\n",
    "    formatted_chat_history = [\n",
    "        {\"role\": \"human\", \"content\": message.content} if isinstance(message, HumanMessage) else\n",
    "        {\"role\": \"ai\", \"content\": message.content}\n",
    "        for message in chat_history.messages\n",
    "    ]\n",
    "\n",
    "    return formatted_chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "id": "e1524c37-4e8d-4dbc-8217-da4e7477d64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content='hi do you know about ridge regression being used to exploit the correlation in the features of a dataset?'), AIMessage(content='Yes. What would you like to know about it?')])"
      ]
     },
     "execution_count": 825,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_session_history(\"3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "id": "fa6637a8-5a40-4a52-b1e4-0a7df52eb78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_chat_history = format_chat_history(get_session_history(\"3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "id": "8306b31e-9919-410b-9672-0f6bd70a96db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[885], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m d \u001b[38;5;241m=\u001b[39m \u001b[43mretriever_hf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexplain in which cases can ridge regression do it with regards to p and N in high dimensional problems\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/retrievers.py:252\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    251\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_error(e)\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    254\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_end(\n\u001b[1;32m    255\u001b[0m         result,\n\u001b[1;32m    256\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/retrievers.py:245\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[0;32m--> 245\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    249\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/vectorstores/base.py:1042\u001b[0m, in \u001b[0;36mVectorStoreRetriever._get_relevant_documents\u001b[0;34m(self, query, run_manager)\u001b[0m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_relevant_documents\u001b[39m(\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m, run_manager: CallbackManagerForRetrieverRun\n\u001b[1;32m   1040\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1042\u001b[0m         docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1043\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity_score_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1044\u001b[0m         docs_and_similarities \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1045\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorstore\u001b[38;5;241m.\u001b[39msimilarity_search_with_relevance_scores(\n\u001b[1;32m   1046\u001b[0m                 query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_kwargs\n\u001b[1;32m   1047\u001b[0m             )\n\u001b[1;32m   1048\u001b[0m         )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/vectorstores/in_memory.py:412\u001b[0m, in \u001b[0;36mInMemoryVectorStore.similarity_search\u001b[0;34m(self, query, k, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity_search\u001b[39m(\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, k: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m    411\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[0;32m--> 412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_with_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/vectorstores/in_memory.py:372\u001b[0m, in \u001b[0;36mInMemoryVectorStore.similarity_search_with_score\u001b[0;34m(self, query, k, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity_search_with_score\u001b[39m(\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    368\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    369\u001b[0m     k: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    371\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Tuple[Document, \u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[0;32m--> 372\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimilarity_search_with_score_by_vector(\n\u001b[1;32m    374\u001b[0m         embedding,\n\u001b[1;32m    375\u001b[0m         k,\n\u001b[1;32m    376\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    377\u001b[0m     )\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m docs\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_community/embeddings/huggingface.py:120\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.embed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21membed_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    112\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute query embeddings using a HuggingFace transformer model.\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03m        Embeddings for the text.\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_community/embeddings/huggingface.py:99\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.embed_documents\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute doc embeddings using a HuggingFace transformer model.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_process:\n\u001b[1;32m    101\u001b[0m     pool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mstart_multi_process_pool()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_community/embeddings/huggingface.py:99\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.embed_documents.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute doc embeddings using a HuggingFace transformer model.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m), texts))\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_process:\n\u001b[1;32m    101\u001b[0m     pool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mstart_multi_process_pool()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "d = retriever_hf.invoke(\n",
    "    {\n",
    "        'input':\"explain in which cases can ridge regression do it with regards to p and N in high dimensional problems\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8170d76-7708-4aaa-b367-88b3ee6116c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "id": "6ff17fec-b1a9-491e-bb79-bf60003f4be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'human',\n",
       "  'content': 'hi do you know about ridge regression being used to exploit the correlation in the features of a dataset?'},\n",
       " {'role': 'ai', 'content': 'Yes. What would you like to know about it?'}]"
      ]
     },
     "execution_count": 829,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "id": "0b0abf93-ee24-4140-b6e2-b0ab23402747",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_documents = history_aware_retriever.invoke(\n",
    "    {\n",
    "        'chat_history':formatted_chat_history,\n",
    "        'input':\"explain in which cases can ridge regression do it with regards to p and N in high dimensional problems\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "id": "e485a0d1-ff2c-42c6-84fa-94b52d4c38c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='8138d844-2c06-4f04-8c21-011fc2301673', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/short-elements-of-statistical-learning-book/chap18.pdf', 'page': 2, 'start_index': 397}, page_content='using the optimal ridge parameter in each of the three cases, the median\\nvalue of|tj|was 2.0, 0.6 and 0.2, and the average number of |tj|values\\nexceeding 2 was equal to 9.8, 1.2 and 0.0.\\nRidge regression with λ= 0.001 successfully exploits the correlation in\\nthe features when p<N, but cannot do so when p≫N. In the latter case\\nthere is not enough information in the relatively small numb er of samples\\nto eﬃciently estimate the high-dimensional covariance mat rix. In that case,'),\n",
       " Document(id='0717ee14-b5bb-457b-9cde-e239d5292f2e', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/short-elements-of-statistical-learning-book/chap18.pdf', 'page': 1, 'start_index': 368}, page_content='ofp, the number of features. The relative error is the test error d ivided by the\\nBayes error, σ2. From left to right, results are shown for ridge regression wit h\\nthree diﬀerent values of the regularization parameter λ:0.001,100and1000. The\\n(average) eﬀective degrees of freedom in the ﬁt is indicated below each plot.\\nvariate regression coeﬃcients1was 9, 33 and 331, respectively, averaged\\nover the 100 simulation runs. The p= 1000 case is designed to mimic the'),\n",
       " Document(id='accd314f-88d7-4864-ad31-8f4ecb55e0a1', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/short-elements-of-statistical-learning-book/chap18.pdf', 'page': 1, 'start_index': 1150}, page_content='just to ensure that the problem is non-singular when p > N. Figure 18.1\\nshows boxplots oftherelative testerrorachieved bythediﬀ erentestimators\\nin each scenario. The corresponding average degrees of free dom used in\\neach ridge-regression ﬁt is indicated (computed using form ula (3.50) on\\npage 682). The degrees of freedom is a more interpretable parameter t han\\nλ. We see that ridge regression with λ= 0.001 (20 df) wins when p= 20;\\nλ= 100 (35 df) wins when p= 100, and λ= 1000 (43 df) wins when'),\n",
       " Document(id='33217a7b-6db9-4860-8636-442483677a1e', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/short-elements-of-statistical-learning-book/chap18.pdf', 'page': 1, 'start_index': 760}, page_content='over the 100 simulation runs. The p= 1000 case is designed to mimic the\\nkind of data that we might see in a high-dimensional genomic o r proteomic\\ndataset, for example.\\nWe ﬁt a ridge regression to the data, with three diﬀerent valu es for the\\nregularization parameter λ: 0.001, 100, and 1000. When λ= 0.001, this\\nis nearly the same as least squares regression, with a little regularization\\njust to ensure that the problem is non-singular when p > N. Figure 18.1'),\n",
       " Document(id='cf020997-d8e9-46f4-8cc3-46930d9cd496', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/short-elements-of-statistical-learning-book/chap18.pdf', 'page': 2, 'start_index': 800}, page_content='to eﬃciently estimate the high-dimensional covariance mat rix. In that case,\\nmore regularization leads to superior prediction performa nce.\\nThus it is not surprising that the analysis of high-dimensio nal data re-\\nquires either modiﬁcation of procedures designed for the N >pscenario, or\\nentirely new procedures. In this chapter we discuss example s of both kinds\\nofapproachesforhighdimensionalclassiﬁcationandregre ssion;thesemeth-')]"
      ]
     },
     "execution_count": 836,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "id": "9e1cb3d6-696f-4529-89e0-8fb5085612da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky appears blue to us because of a phenomenon called Rayleigh scattering, named after the British physicist Lord Rayleigh who first described it in the late 19th century. This process involves the interaction between sunlight and the tiny molecules of gases in the Earth's atmosphere.\n",
      "\n",
      "Here's what happens:\n",
      "\n",
      "1. **Sunlight enters the atmosphere**: When sunlight (which is white) enters the Earth's atmosphere, it encounters a huge number of tiny molecules of gases like nitrogen (N2), oxygen (O2), carbon dioxide (CO2), and others.\n",
      "2. **Scattering occurs**: These gas molecules are so small that they scatter the light in all directions, but with a preference for shorter (blue) wavelengths over longer (red) wavelengths. This scattering effect is more pronounced for blue light because it has a shorter wavelength than red light.\n",
      "3. **Blue light reaches our eyes**: As the scattered sunlight travels through the atmosphere, more of the shorter (blue) wavelengths are directed towards the Earth's surface and reach our eyes.\n",
      "\n",
      "There are several factors that contribute to the sky appearing blue:\n",
      "\n",
      "* **Scattering efficiency**: The scattering effect is more efficient for smaller molecules like nitrogen and oxygen.\n",
      "* **Atmospheric conditions**: On a clear day, with little air pollution or dust in the atmosphere, the sky tends to appear even bluer because there's less of anything else to scatter light.\n",
      "* **Time of day**: At sunrise and sunset, when the sun is lower on the horizon, the light travels through more of the Earth's atmosphere. This longer path causes more scattering, making the sky appear more red or orange due to the dominance of longer (red) wavelengths.\n",
      "\n",
      "In summary, the blue color we see in the sky is a result of Rayleigh scattering by tiny gas molecules in the atmosphere, which preferentially scatter shorter (blue) wavelengths of light towards our eyes."
     ]
    }
   ],
   "source": [
    "# sample ollama usage\n",
    "import ollama\n",
    "\n",
    "stream = ollama.chat(\n",
    "    model='llama3.1',\n",
    "    messages=[{'role': 'user', 'content': 'Why is the sky blue?'}],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "  print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "id": "6229b15c-983e-4151-a682-0bbb2539dab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'human',\n",
       "  'content': 'hi do you know about ridge regression being used to exploit the correlation in the features of a dataset?'},\n",
       " {'role': 'ai', 'content': 'Yes. What would you like to know about it?'}]"
      ]
     },
     "execution_count": 845,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "id": "c614260f-782f-43f8-b980-47edd83c7bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='8138d844-2c06-4f04-8c21-011fc2301673', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/short-elements-of-statistical-learning-book/chap18.pdf', 'page': 2, 'start_index': 397}, page_content='using the optimal ridge parameter in each of the three cases, the median\\nvalue of|tj|was 2.0, 0.6 and 0.2, and the average number of |tj|values\\nexceeding 2 was equal to 9.8, 1.2 and 0.0.\\nRidge regression with λ= 0.001 successfully exploits the correlation in\\nthe features when p<N, but cannot do so when p≫N. In the latter case\\nthere is not enough information in the relatively small numb er of samples\\nto eﬃciently estimate the high-dimensional covariance mat rix. In that case,'),\n",
       " Document(id='0717ee14-b5bb-457b-9cde-e239d5292f2e', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/short-elements-of-statistical-learning-book/chap18.pdf', 'page': 1, 'start_index': 368}, page_content='ofp, the number of features. The relative error is the test error d ivided by the\\nBayes error, σ2. From left to right, results are shown for ridge regression wit h\\nthree diﬀerent values of the regularization parameter λ:0.001,100and1000. The\\n(average) eﬀective degrees of freedom in the ﬁt is indicated below each plot.\\nvariate regression coeﬃcients1was 9, 33 and 331, respectively, averaged\\nover the 100 simulation runs. The p= 1000 case is designed to mimic the'),\n",
       " Document(id='accd314f-88d7-4864-ad31-8f4ecb55e0a1', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/short-elements-of-statistical-learning-book/chap18.pdf', 'page': 1, 'start_index': 1150}, page_content='just to ensure that the problem is non-singular when p > N. Figure 18.1\\nshows boxplots oftherelative testerrorachieved bythediﬀ erentestimators\\nin each scenario. The corresponding average degrees of free dom used in\\neach ridge-regression ﬁt is indicated (computed using form ula (3.50) on\\npage 682). The degrees of freedom is a more interpretable parameter t han\\nλ. We see that ridge regression with λ= 0.001 (20 df) wins when p= 20;\\nλ= 100 (35 df) wins when p= 100, and λ= 1000 (43 df) wins when'),\n",
       " Document(id='33217a7b-6db9-4860-8636-442483677a1e', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/short-elements-of-statistical-learning-book/chap18.pdf', 'page': 1, 'start_index': 760}, page_content='over the 100 simulation runs. The p= 1000 case is designed to mimic the\\nkind of data that we might see in a high-dimensional genomic o r proteomic\\ndataset, for example.\\nWe ﬁt a ridge regression to the data, with three diﬀerent valu es for the\\nregularization parameter λ: 0.001, 100, and 1000. When λ= 0.001, this\\nis nearly the same as least squares regression, with a little regularization\\njust to ensure that the problem is non-singular when p > N. Figure 18.1'),\n",
       " Document(id='cf020997-d8e9-46f4-8cc3-46930d9cd496', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/short-elements-of-statistical-learning-book/chap18.pdf', 'page': 2, 'start_index': 800}, page_content='to eﬃciently estimate the high-dimensional covariance mat rix. In that case,\\nmore regularization leads to superior prediction performa nce.\\nThus it is not surprising that the analysis of high-dimensio nal data re-\\nquires either modiﬁcation of procedures designed for the N >pscenario, or\\nentirely new procedures. In this chapter we discuss example s of both kinds\\nofapproachesforhighdimensionalclassiﬁcationandregre ssion;thesemeth-')]"
      ]
     },
     "execution_count": 847,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e7a8c9-f542-48da-b3bf-5e5ccf149697",
   "metadata": {},
   "source": [
    "do some prompt engineering for the system prompt to take as input the chat history and the retrieved contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "id": "adbbafd8-ccb5-4843-9760-51631f552328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ollama\n",
    "\n",
    "def manual_rag_with_ollama(retrieved_documents,formatted_chat_history,input_query, ollama_model_name=\"llama3.1\"):\n",
    "    \"\"\"\n",
    "    Manually performs RAG using retrieved documents from  history-aware-retriever and streams results from the Ollama model.\n",
    "    \n",
    "    Args:\n",
    "        session_id (str): The session ID to fetch chat history.\n",
    "        input_query (str): The user's input query.\n",
    "        history_aware_retriever: The retriever to get relevant documents.\n",
    "        ollama_model_name (str): The name of the Ollama model to use.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 2: Format the retrieved documents as context\n",
    "    retrieved_contexts = \"\\n\\n\".join([doc.page_content for doc in retrieved_documents])\n",
    "    \n",
    "    # Step 3: Create a prompt that integrates the retrieved context and input query\n",
    "    prompt = (\n",
    "        f\"You are an assistant for question-answering tasks. You must reference information from the retrieved_contexts to answer the input_query. \"\n",
    "        f\"You must also reference the formatted_chat_history to take into account conversation flow and to ensure that the response is relevant to both the current query and prior conversation. \"\n",
    "        f\"Use five sentences maximum and keep the answer concise. \"\n",
    "        \"\\n\\n\"\n",
    "        f\"retrieved_contexts: \\n{retrieved_contexts}\"\n",
    "        \"\\n\\n\"\n",
    "        f\"formatted_chat_history: \\n{formatted_chat_history}\"\n",
    "        \"\\n\\n\"\n",
    "        f\"input_query: \\n{input_query}\"\n",
    "    )\n",
    "\n",
    "    # Step 4: Pass the prompt to the Ollama LLM and stream the response\n",
    "    print(\"Streaming response from Ollama...\")\n",
    "\n",
    "    stream = ollama.chat(\n",
    "        model=ollama_model_name,\n",
    "        messages=[{'role': 'user', 'content': prompt}],\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    # Stream and display the output from Ollama as it generates\n",
    "    for chunk in stream:\n",
    "        print(chunk['message']['content'], end='', flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "id": "ab90fd06-8dce-419c-a423-46ab76aa5e70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='8138d844-2c06-4f04-8c21-011fc2301673', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/short-elements-of-statistical-learning-book/chap18.pdf', 'page': 2, 'start_index': 397}, page_content='using the optimal ridge parameter in each of the three cases, the median\\nvalue of|tj|was 2.0, 0.6 and 0.2, and the average number of |tj|values\\nexceeding 2 was equal to 9.8, 1.2 and 0.0.\\nRidge regression with λ= 0.001 successfully exploits the correlation in\\nthe features when p<N, but cannot do so when p≫N. In the latter case\\nthere is not enough information in the relatively small numb er of samples\\nto eﬃciently estimate the high-dimensional covariance mat rix. In that case,'),\n",
       " Document(id='0717ee14-b5bb-457b-9cde-e239d5292f2e', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/short-elements-of-statistical-learning-book/chap18.pdf', 'page': 1, 'start_index': 368}, page_content='ofp, the number of features. The relative error is the test error d ivided by the\\nBayes error, σ2. From left to right, results are shown for ridge regression wit h\\nthree diﬀerent values of the regularization parameter λ:0.001,100and1000. The\\n(average) eﬀective degrees of freedom in the ﬁt is indicated below each plot.\\nvariate regression coeﬃcients1was 9, 33 and 331, respectively, averaged\\nover the 100 simulation runs. The p= 1000 case is designed to mimic the'),\n",
       " Document(id='accd314f-88d7-4864-ad31-8f4ecb55e0a1', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/short-elements-of-statistical-learning-book/chap18.pdf', 'page': 1, 'start_index': 1150}, page_content='just to ensure that the problem is non-singular when p > N. Figure 18.1\\nshows boxplots oftherelative testerrorachieved bythediﬀ erentestimators\\nin each scenario. The corresponding average degrees of free dom used in\\neach ridge-regression ﬁt is indicated (computed using form ula (3.50) on\\npage 682). The degrees of freedom is a more interpretable parameter t han\\nλ. We see that ridge regression with λ= 0.001 (20 df) wins when p= 20;\\nλ= 100 (35 df) wins when p= 100, and λ= 1000 (43 df) wins when'),\n",
       " Document(id='33217a7b-6db9-4860-8636-442483677a1e', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/short-elements-of-statistical-learning-book/chap18.pdf', 'page': 1, 'start_index': 760}, page_content='over the 100 simulation runs. The p= 1000 case is designed to mimic the\\nkind of data that we might see in a high-dimensional genomic o r proteomic\\ndataset, for example.\\nWe ﬁt a ridge regression to the data, with three diﬀerent valu es for the\\nregularization parameter λ: 0.001, 100, and 1000. When λ= 0.001, this\\nis nearly the same as least squares regression, with a little regularization\\njust to ensure that the problem is non-singular when p > N. Figure 18.1'),\n",
       " Document(id='cf020997-d8e9-46f4-8cc3-46930d9cd496', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/short-elements-of-statistical-learning-book/chap18.pdf', 'page': 2, 'start_index': 800}, page_content='to eﬃciently estimate the high-dimensional covariance mat rix. In that case,\\nmore regularization leads to superior prediction performa nce.\\nThus it is not surprising that the analysis of high-dimensio nal data re-\\nquires either modiﬁcation of procedures designed for the N >pscenario, or\\nentirely new procedures. In this chapter we discuss example s of both kinds\\nofapproachesforhighdimensionalclassiﬁcationandregre ssion;thesemeth-')]"
      ]
     },
     "execution_count": 873,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "id": "05a0f26c-556a-4b98-a626-08bbe0e0e56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'human',\n",
       "  'content': 'hi do you know about ridge regression being used to exploit the correlation in the features of a dataset?'},\n",
       " {'role': 'ai', 'content': 'Yes. What would you like to know about it?'}]"
      ]
     },
     "execution_count": 875,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "id": "7181e7ea-a33a-471b-a770-a8ca21ccec4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_query = \"explain in which cases can ridge regression do it with regards to p and N in high dimensional problems\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "id": "14bc0d48-1e19-4270-91dd-265e03b645d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming response from Ollama...\n",
      "In high-dimensional problems, Ridge regression can exploit the correlation in features when `p` (number of features) is less than `N` (number of samples). However, when `p > N`, there's not enough information to estimate the high-dimensional covariance matrix efficiently. In this case, more regularization leads to superior prediction performance.\n",
      "\n",
      "(This answer references the retrieved_contexts and formatted_chat_history: the former provides the relevant information about Ridge regression in high-dimensional problems, while the latter shows that we were previously discussing the same topic.)"
     ]
    }
   ],
   "source": [
    "prompt = manual_rag_with_ollama(retrieved_documents,formatted_chat_history,input_query)\n",
    "# print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "id": "4ceef2b3-2d7b-41e3-afaf-e94ee96f1684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming response from Ollama...\n",
      "Based on our previous conversation, I recall that ridge regression successfully exploits the correlation in features when p < N, but struggles to do so when p >> N. This is because there's not enough information in the small number of samples to efficiently estimate the high-dimensional covariance matrix.\n",
      "\n",
      "In the latter case (p > N), more regularization leads to superior prediction performance. So, ridge regression can only exploit correlation effectively in low-dimensional settings where N ≥ p.\n",
      "\n",
      "Does that clarify things?"
     ]
    }
   ],
   "source": [
    "prompt = manual_rag_with_ollama(retrieved_documents,formatted_chat_history,input_query)\n",
    "# print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "id": "3cad3f61-4c10-4f9c-883e-ebc67ab2d847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content='hi do you know about ridge regression being used to exploit the correlation in the features of a dataset?'), AIMessage(content='Yes. What would you like to know about it?')])"
      ]
     },
     "execution_count": 883,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_session_history(\"3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d6a7aa-7162-402d-85f1-dc465b72e3cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1305393f-8909-4ddb-9cae-a6eeff3e875f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "id": "afac211e-5865-405b-81f8-0eab0e0952ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_chat_history(chat_history):\n",
    "    \"\"\"\n",
    "    this function assumes that chat_history is not empty \n",
    "    since empty chat_history at the start of the conversation is dealt separately in the main function.\n",
    "    \"\"\"\n",
    "\n",
    "    formatted_chat_history = [\n",
    "        {\"role\": \"human\", \"content\": message.content} if isinstance(message, HumanMessage) else\n",
    "        {\"role\": \"ai\", \"content\": message.content}\n",
    "        for message in chat_history.messages\n",
    "    ]\n",
    "\n",
    "    return formatted_chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "id": "4604c06b-21c7-48a7-9fb0-157fd2627662",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'messages'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[889], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mformat_chat_history\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[887], line 10\u001b[0m, in \u001b[0;36mformat_chat_history\u001b[0;34m(chat_history)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_chat_history\u001b[39m(chat_history):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    this function assumes that chat_history is not empty \u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    since empty chat_history at the start of the conversation is dealt separately in the main function.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     formatted_chat_history \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      8\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: message\u001b[38;5;241m.\u001b[39mcontent} \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, HumanMessage) \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mai\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: message\u001b[38;5;241m.\u001b[39mcontent}\n\u001b[0;32m---> 10\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m \u001b[43mchat_history\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m\n\u001b[1;32m     11\u001b[0m     ]\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m formatted_chat_history\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'messages'"
     ]
    }
   ],
   "source": [
    "format_chat_history([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "id": "acc07057-d349-4272-8537-4274adc738d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_documents = history_aware_retriever.invoke(\n",
    "    {\n",
    "        'chat_history':formatted_chat_history,\n",
    "        'input':\"explain in which cases can ridge regression do it with regards to p and N in high dimensional problems\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "id": "e11c8df2-96ff-46f3-9481-e569be2a43f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='8138d844-2c06-4f04-8c21-011fc2301673', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/short-elements-of-statistical-learning-book/chap18.pdf', 'page': 2, 'start_index': 397}, page_content='using the optimal ridge parameter in each of the three cases, the median\\nvalue of|tj|was 2.0, 0.6 and 0.2, and the average number of |tj|values\\nexceeding 2 was equal to 9.8, 1.2 and 0.0.\\nRidge regression with λ= 0.001 successfully exploits the correlation in\\nthe features when p<N, but cannot do so when p≫N. In the latter case\\nthere is not enough information in the relatively small numb er of samples\\nto eﬃciently estimate the high-dimensional covariance mat rix. In that case,'),\n",
       " Document(id='0717ee14-b5bb-457b-9cde-e239d5292f2e', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/short-elements-of-statistical-learning-book/chap18.pdf', 'page': 1, 'start_index': 368}, page_content='ofp, the number of features. The relative error is the test error d ivided by the\\nBayes error, σ2. From left to right, results are shown for ridge regression wit h\\nthree diﬀerent values of the regularization parameter λ:0.001,100and1000. The\\n(average) eﬀective degrees of freedom in the ﬁt is indicated below each plot.\\nvariate regression coeﬃcients1was 9, 33 and 331, respectively, averaged\\nover the 100 simulation runs. The p= 1000 case is designed to mimic the'),\n",
       " Document(id='accd314f-88d7-4864-ad31-8f4ecb55e0a1', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/short-elements-of-statistical-learning-book/chap18.pdf', 'page': 1, 'start_index': 1150}, page_content='just to ensure that the problem is non-singular when p > N. Figure 18.1\\nshows boxplots oftherelative testerrorachieved bythediﬀ erentestimators\\nin each scenario. The corresponding average degrees of free dom used in\\neach ridge-regression ﬁt is indicated (computed using form ula (3.50) on\\npage 682). The degrees of freedom is a more interpretable parameter t han\\nλ. We see that ridge regression with λ= 0.001 (20 df) wins when p= 20;\\nλ= 100 (35 df) wins when p= 100, and λ= 1000 (43 df) wins when'),\n",
       " Document(id='33217a7b-6db9-4860-8636-442483677a1e', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/short-elements-of-statistical-learning-book/chap18.pdf', 'page': 1, 'start_index': 760}, page_content='over the 100 simulation runs. The p= 1000 case is designed to mimic the\\nkind of data that we might see in a high-dimensional genomic o r proteomic\\ndataset, for example.\\nWe ﬁt a ridge regression to the data, with three diﬀerent valu es for the\\nregularization parameter λ: 0.001, 100, and 1000. When λ= 0.001, this\\nis nearly the same as least squares regression, with a little regularization\\njust to ensure that the problem is non-singular when p > N. Figure 18.1'),\n",
       " Document(id='cf020997-d8e9-46f4-8cc3-46930d9cd496', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/short-elements-of-statistical-learning-book/chap18.pdf', 'page': 2, 'start_index': 800}, page_content='to eﬃciently estimate the high-dimensional covariance mat rix. In that case,\\nmore regularization leads to superior prediction performa nce.\\nThus it is not surprising that the analysis of high-dimensio nal data re-\\nquires either modiﬁcation of procedures designed for the N >pscenario, or\\nentirely new procedures. In this chapter we discuss example s of both kinds\\nofapproachesforhighdimensionalclassiﬁcationandregre ssion;thesemeth-')]"
      ]
     },
     "execution_count": 892,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "id": "582d043b-9f87-4863-8635-09a51613fa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_documents = history_aware_retriever.invoke(\n",
    "    {\n",
    "        'chat_history':[],\n",
    "        'input':\"explain in which cases can ridge regression do it with regards to p and N in high dimensional problems\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "id": "359b1997-c8fe-4414-92f7-911eb1fa3e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='33217a7b-6db9-4860-8636-442483677a1e', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/short-elements-of-statistical-learning-book/chap18.pdf', 'page': 1, 'start_index': 760}, page_content='over the 100 simulation runs. The p= 1000 case is designed to mimic the\\nkind of data that we might see in a high-dimensional genomic o r proteomic\\ndataset, for example.\\nWe ﬁt a ridge regression to the data, with three diﬀerent valu es for the\\nregularization parameter λ: 0.001, 100, and 1000. When λ= 0.001, this\\nis nearly the same as least squares regression, with a little regularization\\njust to ensure that the problem is non-singular when p > N. Figure 18.1'),\n",
       " Document(id='accd314f-88d7-4864-ad31-8f4ecb55e0a1', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/short-elements-of-statistical-learning-book/chap18.pdf', 'page': 1, 'start_index': 1150}, page_content='just to ensure that the problem is non-singular when p > N. Figure 18.1\\nshows boxplots oftherelative testerrorachieved bythediﬀ erentestimators\\nin each scenario. The corresponding average degrees of free dom used in\\neach ridge-regression ﬁt is indicated (computed using form ula (3.50) on\\npage 682). The degrees of freedom is a more interpretable parameter t han\\nλ. We see that ridge regression with λ= 0.001 (20 df) wins when p= 20;\\nλ= 100 (35 df) wins when p= 100, and λ= 1000 (43 df) wins when'),\n",
       " Document(id='c69fa692-b60d-4d42-95c1-e56ea9011615', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/short-elements-of-statistical-learning-book/chap18.pdf', 'page': 10, 'start_index': 1944}, page_content='shown to equal\\nˆβ=V(RTR+λI)−1RTy (18.15)\\n(Exercise 18.4). Thus ˆβ=Vˆθ, where ˆθis the ridge-regression estimate\\nusing theNobservations ( ri,yi),i= 1,2,...,N. In other words, we can\\nsimply reduce the data matrix from XtoR, and work with the rows of\\nR. This trick reduces the computational cost from O(p3) toO(pN2) when\\np>N.'),\n",
       " Document(id='8138d844-2c06-4f04-8c21-011fc2301673', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/short-elements-of-statistical-learning-book/chap18.pdf', 'page': 2, 'start_index': 397}, page_content='using the optimal ridge parameter in each of the three cases, the median\\nvalue of|tj|was 2.0, 0.6 and 0.2, and the average number of |tj|values\\nexceeding 2 was equal to 9.8, 1.2 and 0.0.\\nRidge regression with λ= 0.001 successfully exploits the correlation in\\nthe features when p<N, but cannot do so when p≫N. In the latter case\\nthere is not enough information in the relatively small numb er of samples\\nto eﬃciently estimate the high-dimensional covariance mat rix. In that case,'),\n",
       " Document(id='0717ee14-b5bb-457b-9cde-e239d5292f2e', metadata={'source': '/Users/I748920/Desktop/llms-learning/pdf-chatbot-app/data/short-elements-of-statistical-learning-book/chap18.pdf', 'page': 1, 'start_index': 368}, page_content='ofp, the number of features. The relative error is the test error d ivided by the\\nBayes error, σ2. From left to right, results are shown for ridge regression wit h\\nthree diﬀerent values of the regularization parameter λ:0.001,100and1000. The\\n(average) eﬀective degrees of freedom in the ﬁt is indicated below each plot.\\nvariate regression coeﬃcients1was 9, 33 and 331, respectively, averaged\\nover the 100 simulation runs. The p= 1000 case is designed to mimic the')]"
      ]
     },
     "execution_count": 905,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "id": "797acee4-ad01-4271-8701-c0f30611857b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[])"
      ]
     },
     "execution_count": 907,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = get_session_history(\"4\")\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "id": "e23cbcfa-96ce-48f8-8b2c-86ef32f6f4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 909,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = format_chat_history(c)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "id": "f9c1a786-e1a1-42e4-891a-f196aa0bdb3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Client._stream at 0x400d61740>"
      ]
     },
     "execution_count": 911,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a27e51a-4ae2-457e-be5f-d110e54839b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d9e8892-68ef-4e37-b264-790bf2b4ddc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm a large language model, I don't have real-time access to current weather conditions. However, I can suggest some ways for you to find out the current weather:\n",
      "\n",
      "1. **Check online weather websites**: You can visit websites like AccuWeather, Weather.com, or the National Weather Service (NWS) to get the latest weather updates.\n",
      "2. **Use a mobile app**: There are many weather apps available on both iOS and Android devices that provide real-time weather information.\n",
      "3. **Tune into local news**: Watching local news channels or listening to local radio stations can also give you an idea of the current weather conditions.\n",
      "4. **Ask a voice assistant**: If you have a smart speaker or virtual assistant like Siri, Google Assistant, or Alexa, you can ask them for the current weather.\n",
      "\n",
      "If you'd like, I can also suggest some general information about different types of weather (e.g., sunny, rainy, cloudy) and how to dress accordingly!"
     ]
    }
   ],
   "source": [
    "stream = ollama.chat(\n",
    "    model=\"llama3.1\",\n",
    "    messages=[{'role': 'user', 'content': \"hows the weather\"}],\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "model_answer = ''\n",
    "# Stream and display the output from Ollama as it generates\n",
    "for chunk in stream:\n",
    "    print(chunk['message']['content'], end='', flush=True)\n",
    "    # model_answer = model_answer.join(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75222edc-7197-4d70-b5f9-85d217369047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm a large language model, I don't have real-time access to your location or current weather conditions. However, I can suggest some ways for you to find out the weather:\n",
      "\n",
      "1. **Check online weather websites**: You can visit websites like AccuWeather, Weather.com, or the National Weather Service (NWS) for the most up-to-date and accurate weather forecasts.\n",
      "2. **Use a voice assistant**: If you have a smart speaker or virtual assistant like Siri, Google Assistant, or Alexa, you can simply ask them \"What's the weather like today?\" or \"What's the forecast?\"\n",
      "3. **Check your phone's weather app**: Most smartphones come with a built-in weather app that provides current conditions and forecasts.\n",
      "4. **Look out the window**: If you're physically near a window, take a glance outside to get an idea of the current weather.\n",
      "\n",
      "If you want to chat about the weather in general or discuss specific weather-related topics, I'd be happy to engage with you!"
     ]
    }
   ],
   "source": [
    "stream = ollama.chat(\n",
    "    model=\"llama3.1\",\n",
    "    messages=[{'role': 'user', 'content': \"hows the weather\"}],\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "model_answer = ''\n",
    "# Stream and display the output from Ollama as it generates\n",
    "for chunk in stream:\n",
    "    print(chunk['message']['content'], end='', flush=True)\n",
    "    model_answer += chunk['message']['content']  # Append each chunk to the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "751a2a05-10dd-4a41-9612-37d7f8614cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full model answer: I'm a large language model, I don't have real-time access to your location or current weather conditions. However, I can suggest some ways for you to find out the weather:\n",
      "\n",
      "1. **Check online weather websites**: You can visit websites like AccuWeather, Weather.com, or the National Weather Service (NWS) for the most up-to-date and accurate weather forecasts.\n",
      "2. **Use a voice assistant**: If you have a smart speaker or virtual assistant like Siri, Google Assistant, or Alexa, you can simply ask them \"What's the weather like today?\" or \"What's the forecast?\"\n",
      "3. **Check your phone's weather app**: Most smartphones come with a built-in weather app that provides current conditions and forecasts.\n",
      "4. **Look out the window**: If you're physically near a window, take a glance outside to get an idea of the current weather.\n",
      "\n",
      "If you want to chat about the weather in general or discuss specific weather-related topics, I'd be happy to engage with you!\n"
     ]
    }
   ],
   "source": [
    "# After the loop, `model_answer` will contain the full response\n",
    "print(\"\\nFull model answer:\", model_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4067cc-da60-43d3-ab86-4cf945e55a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1992adad-4d5f-45c6-b586-59e83c9b2eac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1174dd3-998d-4219-80fc-15321aabdc62",
   "metadata": {},
   "source": [
    "hi do you know about ridge regression being used to exploit the correlation in the features of a dataset? Only answer yes or no.\n",
    "\n",
    "AIMessage(content='Yes. What would you like to know about it?'\n",
    "\n",
    "\n",
    "do you know about high dimensional problems in statistical learning? yes or no.\n",
    "\n",
    "\n",
    "explain in which cases can ridge regression do it with regards to p and N in high dimensional?  --show references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cb34e0-d64f-434d-945c-2b82a2027485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a88a467-1b34-456b-8dc7-8a747e0105e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
